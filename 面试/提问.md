# :calendar:进度

| 基础知识 | [<font color=green>设计模式</font>](#设计模式) | [<font color=green>JVM</font>](#JVM) | [<font color=green>并发编程</font>]() | [<font color=green>线程池</font>]() |       锁       | [<font color=green>网络编程</font>]() | 项目管理 |   缓存   | redis |
| :------: | :--------------------------------------------: | :----------------------------------: | :-----------------------------------: | :---------------------------------: | :------------: | :-----------------------------------: | :------: | :------: | ----- |
|          |                    UML类图                     |               内存结构               |               进程/线程               |              属性解释               |   多种锁解释   |                TCP/UDP                |  gradle  | jetcache |       |
|          |                  常用设计模式                  |                  GC                  |                多线程                 |                分类                 | 字节码层面分析 |               粘包/拆包               |  maven   | j2cache  |       |
|          |                 使用及案例描述                 |                字节码                |               内存模型                |                原理                 |                |               滑动窗口                |          |          |       |
|          |                                                |                类加载                |              多线程通信               |                配置                 |                |               三次握手                |          |          |       |
|          |                                                |             JVM性能调优              |                原子类                 |              拒绝策略               |                |               四次挥手                |          |          |       |
|          |                                                |               双亲委派               |                并发包                 |                                     |                |               七层模型                |          |          |       |
|          |                                                |                                      |               并发队列                |                                     |                |               多路复用                |          |          |       |
|          |                                                |                                      |               volatile                |                                     |                |                零拷贝                 |          |          |       |
|          |                                                |                                      |              ThreadLocal              |                                     |                |                                       |          |          |       |

|   技术框架   |      分布式      |               中间件                |               数据库               | [<font color=green>微服务</font>]() | [<font color=green>消息队列</font>]() | [<font color=green>DDD</font>]() |  前端   |             容器编排             | linux    |
| :----------: | :--------------: | :---------------------------------: | :--------------------------------: | :---------------------------------: | :-----------------------------------: | :------------------------------: | :-----: | :------------------------------: | -------- |
|    spring    |     分布式锁     |              [nginx]()              | [<font color=green>mysql</font>]() |              注册中心               |               ActiveMQ                |           领域驱动理解           |   vue   |              docker              | shell    |
|  springboot  |     分布式ID     | [<font color=green>tomcat</font>]() |                 es                 |                熔断                 |               RabbitMQ                |             角色职权             | node.js | [<font color=green>k8s</font>]() | 常用命令 |
| springCloud  |    分布式事务    | [<font color=green>redis</font>]()  |              mongodb               |              请求/负载              |               RocketMQ                |             工程样例             |         |                                  |          |
|    dubbo     |    分布式缓存    |              zookeeper              |             memcached              |                配置                 |    <font color =green>Kafka</font>    |                                  |         |                                  |          |
|   mybatis    |  分布式session   |                gRpc                 |           sharding-jdbc            |                网关                 |                                       |                                  |         |                                  |          |
| mybatis-plus |  分布式任务调度  |                etcd                 |               mycat                |                限流                 |                                       |                                  |         |                                  |          |
|    netty     | 分布式协议和算法 |                canal                |                                    |         springcloud Alibaba         |                                       |                                  |         |                                  |          |
|              |                  |                 ELK                 |                                    |                                     |                                       |                                  |         |                                  |          |
|              |                  |                solr                 |                                    |                                     |                                       |                                  |         |                                  |          |
|              |                  |              Activity               |                                    |                                     |                                       |                                  |         |                                  |          |

| 算法和数据结构 | 理论 | 日志         | 其他     | 大数据     | java版本特性                       | 其他编程语言 | [软件测试]() |      |      |
| -------------- | ---- | ------------ | -------- | ---------- | ---------------------------------- | ------------ | ------------ | ---- | ---- |
|                | 架构 | log4j        | 认证     | [python]() | [<font color=green>java8</font>]() |              | [jmeter]()   |      |      |
|                |      | Resilience4j | 性能优化 |            |                                    |              |              |      |      |
|                |      |              | 服务网格 |            |                                    |              |              |      |      |
|                |      |              | 跨域     |            |                                    |              |              |      |      |
|                |      |              | 幂等方案 |            |                                    |              |              |      |      |



# :question:提问

## 简历篇

> **技术能力**
>
> - 技术技能不能模板化，需要细化，描述细节点
> - 提炼职业生涯遇到的组件和使用场景、提炼主要项目和经验积累
>
> **项目经验**
>
> - 主要在于个人职责上，需要细化职责
> - 落实技术细节，结合业务场景，解决了什么问题、技术亮点和难点。项目本身不具备的话，可以移花接木，掌握这块的技术就可以移植过来
> - 如果本身项目是CRUD，完全可以将自己手写的高并发、分布式项目写上

## 项目介绍篇

> **主要职责**
>
> 负责galaxy国际化多语言的后端改造工作以及境外雪球业务功能、11号牌申请业务功能的开发工作
>
> **项目介绍**
>
> galaxy运营业务平台是运营使用，主要帮助客户处理境内外场外衍生品簿记、清算、结算、估值一体化工作。
>
> 我在这期间主要处理的是场外衍生品的簿记模块功能。包含
>
> 境外雪球业务功能的开发工作，包括现金流、交易流水以及合约的接收处理、计算、复核以及确认书的生成等。数据来源上游通过kafka消息推送或者通过dubbo接口推送，galaxy这边接收，执行后续的处理流程，包括数据的校验以及数据的计算、组装、入库。自动或者手动复核数据，生成确认书文件等。
>
> 11号牌申请业务主要是针对原有境内功能，进行EQD、EST部门及业务品种的扩张，这里使用境外数据源。包括一些行情资讯、CA流水、对账、新品种监控等功能
>
> **难点**
> 1、针对境内外数据的隔离以及接口的隔离2、针对扩展部门及品种代码结构臃肿的问题3、针对部分业务表数据量过大的问题
> **解决**
>
> 1、数据源的隔离，针对韩国雪球业务，数据方案采用的是境内外独立schema存储数据的方案，针对境内外不同的业务实现动态切换数据源，实现数据在业务层面的隔离。主要包含三类场景
>
> web接口：通过拦截器方式，在请求进入阶段，获取用户权限或者指定url方式比如/hk/，判断用户境内还是境外数据权限
>
> 定时任务或者dubbo接口：通过部门标识判断数据源配置
>
> kafka消息：通过消息体中的部门或者subbook（境外的业务属性）来判断数据源配置
>
> 技术上 ：
>
> galaxy使用的技术栈是springboot，spring自身提供了AbstractRoutingDataSourcec能够解决多数据源场景。新建动态数据源类继承AbstractRoutingDataSource，同时采用TransmittableThreadLocal来存储当前数据源信息,方便子线程获取父线程的值。
>
> 2、业务部门以及品种的，多使用策略模式进行解耦，相同的业务操作流程采用模板模式进行步骤共用，以及一些复杂的流程进行拆分使用观察者者模式进行一些通用功能的接口，比如spring event在接收处理一系列处理后，生成报表的操作。
>
> 3、数据量过大的问题
>
> - 首先数据库的库表建立要增加必要的索引以支撑搜索查询
> - 大表的话采用月表的形式，针对历史数据进行归档。
> - 导出以及查询方面，陷定条数以及数据范围。支持异步导出,同步返回文件的名称，记录数等，异步下载记录redis标识，前端通过指定频率来检测后端是否下载完毕，下载完再通过浏览器进行文件下载
> - 还有些日常全量跑批的场景，通过分部门进行多线程跑批，同时针对个别单个部分体量较大的数据，对接并行计算平台进行分片处理，计算平台通过数据切片，进行多实例分发，回调galaxy系统进行业务数据。
> - 针对必要的计算公式以及固定配置，采用redis进行缓存，避免数据库的直接访问。 （db CPU过高问题）
>
> **实际的技术问题**
>
> 1、大表同步导出问题，多次点击导出，导致OOM.
>
> 解决：
>
> - 限制导出记录数 50000
> - 使用SXSSFWorkBook解决数据放在内存导致的oom问题（支持内容放在磁盘里）
> - 异步导出，返回最大允许的导出数量以及文件名、总数
> - 前端通过轮询接口查询是否完成excel写入，文件完成，前端下载
>
> 2、系统不定时假死问题
>
> 某一次上线后，半小时或者一小时系统http访问不通，页面请求无响应。
>
> 分析：
>
> - 查看系统日志看看有没有error，OOM或者GC overhead limit exceeded类似的日志。历史有过这种大数据量导出导致的。
> - 查看系统资源情况 top命令查看cpu和内存的情况  结合jstack查看异常线程的运行情况 看看有没有死锁之类的，使用jmap命令导出dump文件分析，是否存在大对象之类
> - 查看nginx日志看看是否有异常
> - 根据nginx轮询接口日志异常 怀疑系统轮询菜单计数接口问题。显示nginx屏蔽该接口调用，直接返回200.系统正常。
> - 分析代码，确认代码存在线程嵌套，导致线程数多倍使用，超过线程池最大线程数。进入等待。此时，用户多次点击或者前端轮询就会导致线程池无线程可用，达到tomcat线程数200时，线程耗尽，后续相关http请求来了，就会无响应。
> - 业务空闲时，取一台生产虚机进行验证，打开nginx限制，通过jmeter模拟并发请求，出现现象。通过jstack查看日志，发现total接口线程出现大量wait日志，确认原因。
> - 修复后不再出现。
>
> 
>
> <springframework.version>5.3.20</springframework.version>
>
> <spring.boot.version>2.21.RELEASE</spring.boot.version>

> **主要职责**
>
> 分布式调度平台的深度定制，基于源码级别以及项目提出的个性需求进行功能定制。
>
> **项目介绍**
>
> 批量任务调度平台
> 基于xxLjob开源组件做深度定制
> 实现单任务、流程类任务调度，以及任务生命周期的监控、管理.
> 定制和扩展体现在:
> 调度架构上，由调度服务和执行服务的交互，扩展一级调度服务、二级调度服务、执行服务的交互。(应对行内单元化的变革)
>
> 调度模式上，由简单任务调用、父子任务调用。扩展为流程任务调用。类似工作流的方式，形成任务流。支持对任务节点的控制，比如定时、循环(本质上是对任务定义的扩展，但是是基于每次流程版才而言，不是固定的)流程的控制(比如暂停、终止、恢复、重试等)
>
> 任务自身属性的丰富，比如对任务设置虚拟资源分、并行度，还有实际资源分等，本质上是一种资源的限制操作。
> 生命周期的监控，调度、回调环节的成功与否，通过日志状态的记录、事件的通知，告警(通知到统监控平台)，未名状态的补偿机制，比如服务下线、执行结果丢失等。。 执行器资源的动态启停等。
> **难点**
> 深度定制和原有的简单调度模式耦合过大，随着版本的迭代，功能之间互相影响,不稳定因素增加
> **解决**
> 进行定制功能的剥离，重构，比如资源分、cpass资源、运行态、单元化，单独构建模块。
> 对调度、回调环节中进行步骤的抽象，各个定制功能进行顶层接口的实现。通过一些设计模式，将固有功能和定制功能进行整合。
> 比如责任链，对于调度前置，存在默认实现和定时的实现比如pod启用，资源分消耗，根据依赖引入和配置开关决定是否状态。更细化的对于部分环节细分吗，根据不同的场景细分链条。
> 比如借助spring的事件通知机制，也就是观察者模式，实现一些业务逻辑的解摆，比如告警、pod资源的释放等
> 比如装饰器模式，对一些默认功能的增强，比如注册支持资源分的增强、
> 比如中介者模式 对于默认实现和定制实现的调用逻辑统一通过功能中介来进行逻辑选择
> **实际的技术问题**
> 比如流程调用并行节点的后置重复调度的问题。解决方式: 防重表
> 比如执行器服务有一个使用阻寨队列，批量回调方式，调度端同步接收回调处理超时问题。批量数据多了，整体超时。arthas检测，最后进行异步处理。
>
> <springframework.version>5.3.12</springframework.version>
>
> <spring.boot.version>2.5.6</spring.boot.version>
>
> <spring.cloud.version>2020.0.4</spring.cloud.version>

## 基础篇

### HashMap

#### HashMap和ConcurrentHashMap区别？

> 主要区别在多线程下线程安全上
>
> 1、hashMap在hash值存在冲突的情况下，采用拉链法。形成链表，**jdk1.7 采用头插法**，多线程下存在**死链**问题。**jdk1.8 多线程下存在值覆盖问题**。
>
> 2、多线程下put remove操作修改结构时，**hashMap会抛出ConcurrentModificationException异常，而ConcurrentHashMap不会**。
>
> 使用建议：
>
> HashMap 单线程运行环境使用
>
> 多线程下使用同步或加锁  Collections 提供线程安全方法synchronizedMap
>
> 使用ConcurrentHashMap

#### ConcurrentHashMap数据结构？

> jdk1.7 
>
> ConcurrentHashMap维护了一个**Segment数组**，Segment这个类**继承了重入锁ReentrantLock**。
>
> 该类里面维护了一个 HashEntry<K,V>[] table数组，在写操作**put，remove，扩容的时候，会对Segment加锁**
>
> 所以解决了**线程的安全**问题，同时又采用了**分段锁也提升了并发的效率**
>
> jdk1.8
>
> **Node数组+链表+[红黑树](https://so.csdn.net/so/search?q=红黑树&spm=1001.2101.3001.7020)的数据结构来实现**，并发控制使用Synchronized和CAS

#### 死链问题

> **多线程下，扩容的同一个链表**。
>
> 当线程一执行到e.next = new table[i] 的时候，由于线程二之前数据迁移的原因导致此时new table[i] 上就有ertry存在，所以线程一执行的时候，会将next节点，设置为自己，导致**自己互相使用next引用对方**，因此产生链表，导致死循环。
>
> 
>
> 解决
>
> - 使用synchronize
> - 使用collection.synchronizeXXX方法
> - 使用concurrentHashmap来解决。

#### HashMap jdk1.7 jdk1.8区别？

> 1、数据结构上   
>
> JDK1.7的时候使用的是**数组+ 单链表**的数据结构。**数组和链表节点的实现类是Entry类**
>
> JDK1.8及之后时，使用的是**数组+链表+红黑树**的数据结构（当**链表的深度达到8**的时候，也就是默认阈值，就会**自动扩容把**链表转成红黑树的数据结构来把时间复杂度从O（n）变成O（logN）提高了效率）。**数组和链表节点的实现类是Node类**
>
> 2、Hash值计算上 
>
> jdk1.7  9次扰动处理
>
> jdk1.8  2次扰动处理=1次位运算+1次异或
>
> 3、链表数据插入方法上
>
> jdk1.7 头插法
>
> jdk.1.8 尾插法
>
> 4、内部Entry类的实现
>
> jDK1.7数组和链表节点的实现类是**Entry类**，实现了Map.entry接口。
>
> JDK1.8数组和链表节点的实现类是**Node类**，但是**还是实现了Map.entry接口**

#### hash实现

(h = key.hashCode())^ (h >>> 16);
hash取值 = key的hashcode 与 hashcode右位移 16位进行一个异或。
==定位下标==
(n - 1) & hash 这是一个与的操作。
如果不进行右移异或，直接用hashcode进行与，当数组很小时，参与 与操作的只是低位，如果hashcode低位变化小，容易产生冲突。右移16位其实就是讲hashcode高位和低位进行异或，加大低位的随机性，混合后的低位具有高位的特性，不易产生冲突)。效率也高。

#### 为什么大小是2的幂

(n - 1) & hash 和这个下标定位方式有关，n=2的n次幕时，n-1的二进制数据，呈现111111***111，就是高低位普遍都是1的形式，这样和hashcode与时，能够充分的散列)，每一位都能进行位运算，减少hash碰撞，元素够均匀散列在每个位置上。

#### put实现

1.调用hash函数计算key的hash值，然后计算下标(与数组长度-1进行与的运算)

2。如果没有出现hash冲突，则直接放入数组，如果出现冲突，则以链表形式放在链表的后面

3.如果链表长度超多闻值8，则链表转为红黑树，链表长度低于6，则转回链表。

4.如果key已经存在，则替换value
5。如果集合中的键值对大于12了(数组长度*负载因子0.75)，进行resize扩容。

#### 扩容

1.hashmap中元素个数超过数组大小*负载因子时，进行扩容，2倍扩容。
2，如果链表对象达到8个时，Node的数量没有到64，先进行扩容，如果到达64转为红黑树，节点Node类型变为treeNode类型，如果map元素被移除，导致树的节点数低于6，则再转回链表。

3，扩容的同时，伴随着rehash分配，但是(n-1)&hash 结果，只是多了一个Bit位，所以节点位置要么就在先位置，要么原位置+旧容量。

#### 为什么选用红黑树而不是二又查找树

二叉查找树在特殊情况下会变成线性结构，跟原来的链表一样，遍历查找会比较慢。而红黑树在插入数据后，进行左旋、右旋、变色，保证平衡，查找比较快。

#### 底层数据结构

1.8前数组+链表
1.8后数组+链表+红黑树
==concurrentHashMap==
JDK 1.8 之前是采用分段锁来现实的 Segment + HashEntry， Segment 数组大小默认是 16，2的 n次节
JDK 1.8 之后，采用 Node + CAS + Synchronized 来保证并发安全进行实现。

### semaphore

> 信号量，**用来限制同一时刻访问共享资源的线程上限**。
> 设置许可3个，5个线程来竞争。三个获取到许可进行处理。另外两个进入AQS队列park阻塞。thread0释放许可，thread4竞争成功，再次设置许可permits=0，同时unpark剩余线程进行竞争，由于许可为日，继续阻塞等待。

### countdownLatch

> 计数器，**允许多个线程阻塞在一个地方，直到所有线程执行完毕，再一起向下执行**。
> 用来协调线程同步协作 。 其中构造参数用来初始化等待计数值，await() 用 来等待计数归零，countDown()用来让计数减一。
> 人都走了，关门。
>
> ==共享锁的实现。==
> 默认构造AQS的state值为count,线程使用countDown方法时，本质是去调用tryReleaseShared去减少state的值，state=0代表所有线程都调用了countDown方法
>
> 当调用await方法时，发现state不为0，代表有线程未执行countDown方法，那么已经调用过countDown方法的线程会被放在阻塞队列里park，并自旋CAS判断是否state=0，直至最后的线程调用countDown方法state=0，则阻塞的线程判断成功，全部往下调用.

### cyclicsBarrier

> 循环栅栏，初始化时规定一个数目，每个线程执行到 某个需要”同步”的时刻,调用了CyclicBarrier.await()进入等待。当等待的线程数满足了初始计数个数]时，所有进入等待状 态的线程被唤醒并继续。人齐了出发的概念

### juc

> Abstract Queued Synchronized，AQS 抽象队列同步器是JUC包同步机制的基础设施，更是JUC锁框架的基础

> 内置锁和显式锁比较
>
> 限时抢锁 
>
> 可中断抢锁
>
> 多个等待队列：为锁维持多个等待队列，以便提高锁的效率
>
> Java对象锁还存在性能问题。在竞争稍微激烈的情况下，Java对象锁会膨胀为重量级锁（基于操作系统的Mutex Lock实现）

>  LockSupport.park()和 Thread.sleep()的区别
>
>  1）**Thread.sleep()没法从外部唤醒**，只能自己醒过来；而被LockSupport.park()方法阻塞的线程,可以通过调用LockSupport.unpark()方法去唤醒。
>  2）Thread.sleep()方法声明了InterruptedException中断异常，这是一个受检异常，调用者需要捕获这个异常或者再抛出；而使用LockSupport.park()方法时不需要捕获中断异常。
>  3）当被阻塞线程的**Thread.interrupt()方法调用时，LockSupport.park()方法不会抛出InterruptedException异常，仅仅设置了线程的中断标志**；而**Thread.sleep()方法还会抛出InterruptedException**异常。
>  4）与Thread.sleep()相比，调用LockSupport.park()能更精准、更加灵活地阻塞、唤醒指定线程。
>  5）Thread.sleep()本身就是一个原生（native）方法；LockSupport.park()并不是一个原生方法，只是调用了一个Unsafe类的原生方法（名字也叫park）去实现。
>
>  6)**LockSupport.park()方法还允许设置一个Blocker对象，主要用来供监视工具或诊断工具确定线程受阻塞的原因**

>  LockSupport.park()与 Object.wait()的区别
>
>  1)Object.wait()方法需要在synchronized块中执行，而LockSupport.park()可以在任意地方执行
>
>  2)当被阻塞线程中断时，Object.wait()方法抛出了中断异常，调用者需要捕获或者再抛出；当被阻塞线程中断时，LockSupport.park()不会抛出异常，调用时不需要处理中断异常。

> CLH锁其实就是一种是基于队列（具体为单向链表）排队的自旋锁，由于是Craig、Landin和Hagersten三人一起发明的，因此被命名为CLH锁，也叫CLH队列锁
>
> 简单的CLH锁可以基于单向链表实现，申请加锁的线程首先**会通过CAS操作在单向链表的尾部增加一个节点**，之后该线程只需要在其前驱节点上进行普通自旋，等待前驱节点释放锁即可.(`有没有点类似zookeeper的加锁watch机制 监听前一个小的节点，这里普通自旋也是看前驱节点有没有释放锁`)
>
> 加锁表示前驱节点lock 状态为false  可以加锁，解锁就是设置自身锁状态为false，后置节点就可以自旋获取到锁

> 非公平锁是指多个线程获取锁的顺序并不一定是其申请锁的顺序，**有可能后申请的线程比先申请的线程优先获取锁**，**抢锁成功的次序不一定体现为FIFO（先进先出）顺序**。非公平锁的优点在于**吞吐量比公平锁大**，其缺点是有可能会导致线程优先级反转或者线程饥饿现象。

> 死锁是指**两个或以上线程因抢占锁而造成的互相等待**的现象
>
> 线程X先后按照先后次序去抢占锁A与锁B，线程Y先后按照先后次序去抢占锁B与锁A

> **JVM管理工厂ManagementFactory类提供静态方法，返回各种获取JVM信息的Bean实例**。我们
> 通过这些Bean实例能获取大量的**JVM运行时信息，比如JVM堆的使用情况、GC情况、线程信息**、`死锁监测`等

> 共享锁就是在**同一时刻允许多个线程持有的锁**。当然，**获得共享锁的线程只能读取临界区数据，不能修改临界区的数据**。
>
> Semaphore（信号量）、ReadLock（读写锁）中的读锁、CountDownLatch倒数闩

> ReentrantReadWriteLock更适合于读多写少的场景（两把锁），可以提高并发读的效率；而ReentrantLock更适合于读写比例相差不大或写比读多的场景。

> StampedLock（印戳锁）是对ReentrantReadWriteLock读写锁的一种改进
>
> 主要的改进为：**在没有写只有读的场景下，StampedLock支持不用加读锁而是直接进行读操作**，最大程度提升读的效率，
> **只有在发生过写操作之后，再加读锁才能进行读操作**。

### AQS

> AbstractQuevedSynchronizer，是阻塞式锁和相关的同步器工具的框架。
>
> 用 state 属性来表示资源的状态(分独占模式和共享模式)，子类需要定义如何维护这个状态， 控制如何获取锁和释放锁
> getState  获取 state 状态 setstate -
> 设置 state 状态 compareAndSetState - cas 机制设置 state 状态

> AQS是CLH队列的一个变种   **模板模式**
>
> AQS队列`内部维护的是一个FIFO的双向链表`,**每个节点其实是由线程封装的**，当线程争抢锁失败后会封装成Node加入到AQS队列中去,释放锁以后，会从队列中唤醒一个阻塞的节点（线程)

> 1、AQS中维持了一个单一的volatile修饰的状态信息state
>
> 2、AbstractQueuedSynchronizer继承了AbstractOwnableSynchronizer，这个基类只有一个变量叫exclusiveOwnerThread，表示当前占用该锁的线程。（`是不是有点类似monitor的owner`）`其实就是java层面实现类jvm的monitor锁相关操作`
>
> 3、AQS的内部队列是CLH队列的变种，每当**线程通过AQS获取锁失败时，线程将被封装成一个Node节点，通过CAS原子操作插入队列尾部**。当有线程**释放锁时，AQS会尝试让队首的后驱节点占用锁**

> 显式锁与AQS之间是一种强依赖的聚合关系，如果显式锁的实例销毁，其聚合的AQS子类实例也被销毁，因此显式锁与AQS之间是组合关系
>
> ReentrantLock的显式锁操作是委托（或委派）给一个Sync内部类的实例完成的。
>
> 而**Sync内部类只是AQS的一个子类，**
>
> 所以**本质上ReentrantLock的显式锁操作是委托（或委派）给AQS完成的**。一个ReentrantLock对象的内部一定有一个AQS类型的组合实例，二
> 者之间是组合关系。

> **AQS抢占锁**
>
> 1、CAS操作state字段，成功获取到锁
>
> 2、失败，以当前线程构造Node节点，CAS自旋将节点添加到队列尾部。
>
> 3、当前Node节点在死循环中不断获取同步状态，并且不断在前驱节点上自旋，只有**当前驱节点是队首节点才能尝试获取锁**（队首节点的线程释放了同步状态以后，将会唤醒其后驱节点）（`自旋过程中会阻塞线程，等待前驱节点唤醒后才启动循环`）
>
> 4、**前驱节点是队首节点**并且**当前线程使用钩子方法tryAcquire(arg)获得了锁**，则移除队首节点，将当前节点设置为队首节点
>
> **AQS释放锁**
>
> 1、队首节点的状态变成初始状态，设置Owner为Null
>
> 2、唤醒后驱节点

> 非公平同步器ReentrantLock.NonfairSync的核心思想就是当前进程尝试获取锁的时候，**如果发现锁的状态位是0（也就是占用锁的节点释放锁了），就直接尝试将锁拿过来，然后执行setExclusiveOwnerThread()，根本不管同步队列中的排队节点**

> 公平抢占的钩子方法中，**首先判断是否有后驱节点，如果有后驱节点，并且当前线程不是锁的占有线程**，钩子方法就返回false，模板方法会**进入排队的执行流程**

> **await()方法的整体流程如下：**
>
> 1）执行await()时，会新**创建一个节点并放入到Condition队列尾部**。
> 2）然后**释放锁，并唤醒AQS同步队列中的队首节点的后一个节点**。
> 3）然后执行while循环，将该节点的线程阻塞，直到该节点离开等待队列，重新回到同步队列成为同步节点后，线程才退出while循环。
> 4）退出循环后，开始调用acquireQueued()不断尝试拿锁。
> 5）拿到锁后，会清空Condition队列中被取消的节点。

> **signal()方法的整体流程如下：**
> 1）通过enq()方法自旋，**将条件队列中的队首节点放入到AQS同步队列尾部**，**并获取它在AQS队列中的前驱节点**。
> 2）如果前驱节点的状态是取消状态，或者设置前驱节点为Signal状态失败，就唤醒当前节点的线程；否则节点在同步队列的尾部，参与排队。
> 3）同步队列中的线==程被唤醒==后，表示重新获取了显式锁，然后继续执行condition.await()语句后面的临界区代码。

> **节点入队的时机**
>
> 1、**调用tryAcquire(arg)尝试，如果不成功，则开始将线程加入等待队列**（加到尾部，存在竞争就CAS）
>
> 2、**Condition等待队列上的节点被signal()唤醒**，会通过enq(final Node node)**自旋入队，插入AQS的尾部**。

### monitor

> 监视器或者叫管程。thread0进入，synchronized 给对象上锁(重量级)，该对象与monitar对象关联，对象头的 Mark Word中就被设置为指向 Monitor 对象的指针。monitor此时owner为线程0，其余进入entryList阻塞

### 对象头

Mark Word  指向类的指针  数组长度

### mark word

> 无锁标记(hashcode、分代年龄、偏向锁标志)
>
> 偏向标记(偏向线程 id)
> 轻量级
> 重量级锁标记 (Monitor)
> GC标记

### 锁升级过程

> **偏向锁**:针对一个线程来说的，主要作用是优化(同一个线程多次获取一个锁的) 情况。当一个线程 执行了一个 synchronized 方法的时候，肯定能得到对象的 monitor ，加锁(**对象会在 Mark Wor处设为偏向锁标记**，同时(一个字段指向拥有锁的这个线程的线程 ID。当这个线程再 次访问同一个 synconized 方法的时候，会检查这个对象的 Mark word 的偏向锁标记，再判断下这个字段记录的线程 ID 是不是跟第二个线程的 ID 是否相同的，如果相同，就无需再获取 monitor 了，直接入方法体中
>
> 1）线程抢锁时，JVM**首先检测内置锁对象Mark Word中biased_lock（偏向锁标识）**是否设置成1，lock（锁标志位）是否为01，如果都满足，确认内置锁对象为可偏向状态。
> 2）在内置锁对象确认为可偏向状态之后，JVM检查Mark Word中线程ID是否为抢锁线程ID，**如果是，就表示抢锁线程处于偏向锁状态**，抢锁线程快速**获得锁，开始执行临界区代码**。
> 3）如果Mark Word中**线程ID并未指向抢锁线程，就通过CAS操作竞争锁**。如果**竞争成功，就将Mark Word中线程ID设置为抢锁线程**，偏向标志位设置为1，锁标志位设置为01，然后执行临界区代码，此时内置锁对象处于偏向锁状态。
> 4）如果CAS操作**竞争失败**，就说明发生了竞争，撤销偏向锁，进而**升级为轻量级锁**。
> 5）JVM使用**CAS将锁对象的Mark Word替换为抢锁线程的锁记录lockrecord指针**，如果**成功，抢锁线程就获得锁**。如果替**换失败**，就表示其他线程竞争锁，JVM**尝试使用CAS`自旋`替换抢锁线程的锁记录**指针，如果自旋成功（抢锁成功），那么锁对象依然处于轻量级锁状态。
> 6）如果JVM的CAS替换锁记录指针**自旋失败，轻量级锁膨胀为重量级锁**，后面等待锁的线程也要进入阻塞状态，**进入EntryList等待执行**

### 线程池

> 1，线程池中刚开始没有线程，当一个任务提交给线程池后，线程池会创建一个新线程来执行任 务。
>
> 2，当线程数达到 corePoolSize 并没有线程空闲，这时再加入任务，新加的任务会被加入 workQueue 队列排 队，直到有空闲的线程。
> 3.如果队列选择了有界队列，那么任务超过了队列大小时，会创建 maximumPoolSize - corePooLSize 数目的线 程来救急。
>
> 4，如果线程到达 maximumPoolSize 仍然有新任务这时会执行拒绝策略

> 什么是进程呢?简单来说，进程是程序的一次启动执行。
> 什么是程序呢?程序是存放在硬盘中的可执行文件，主要包括代码指令和数据。
> 一个进程是一个程序的一次启动和执行，是操作系统将程序装入内存，给程序分配必要的系统资源，并且开始运行程序的指令。
>
> 进程与程序是什么关系呢?同一个程序可以多次启动，对应多个进程。比如，多次打开Chrome浏览器程序，在Process Explorer中可以看到多个Chrome浏览器进程。
>
> Java编写的程序都运行在Java虚拟机 (JVM)中，**每当使用Java命令启动一个Java应用程序时，就会启动一个JVM进程**。在这个JVM进程内部，所有Java程序代码都是以线程来运行的。JVM找到程序的入口点main()方然后运行main()方法，这样就产生了一个线程，这个线程称为主线程。当main()方法结束后，主线程运行完JVM进程也随即退出

> **BLOCKED 状态**
> (1)线程等待获取一个锁，而该锁被其他线程持有，则该线程进入阻塞状态。当其他线程释放了该锁，并且线程调度器允许该线程持有该锁时，该线程退出阻塞状
>
> (2) I0阻线程发起了一个阻式I0作后，如果不备操作的条件，线程就会进入阻塞状态。I0包括磁盘I0、网络I0等。I0阻塞的一个简单例子: 线程等待用户输入内容后继续执行
>
> **WAITING 状态**
> 0bject.wait()方法，对应的唤醒方式为: 0bject.notify() / 0bject,notifyAll()。
> Thread.join()方法，对应的唤醒方式为: 被合入的线程执行完毕。
> LockSupport.park()方法，对应的唤醒方式为: LockSupport.unpark(Thread)。
>
> **进入BLOCKED状态、WAITING状态、TIMED_WAITING状态的线程都会让出CPU的使用权**

> 线程池任务被拒绝
>
> 1) 线程池已经被关闭。
> 2) 工作队列已满且maximumPoolSize已满。

> **线程池状态**
>
> 1)RUNNING: 线程池创建之后的初始状态，这种状态下可以执行任务。
> 2)SHUTDOVIN: 该状态下线程池不再接受新任务，但是会将工作队列中的任务执行完毕。
> 3)STOP:该状态下线程池不再接受新任务，也不会处理工作队列中的剩余任务，并且将会中断所有工作线程
> 4)TIDYING: 该状态下所有任务都已终止或者处理完成，将会执行terminated()钩子方法。
> 5)TERMINATED: 执行完terminated()钩子方法之后的状态。

> **线程池的状态转换规则为:**
> 1)线程池创建之后状态为RUNNING。
> 2)执行线程池的shutdown实例方法，会使线程池状态从RUNNING转变为SHUTDOWN。此方法会**等待当前工队列中的剩余任务全部执行完成之后才会执行关闭**，但是此方法被调用之后线程池的状态转变为SHUTDOWN，线池不会再接收新的任务
> 3)执行线程池的shutdownNow()实例方法，会使线程池状态从RUNNING转变为STOP。此方法会打断正在执行的工作线程，并且会清空当前工作队列中的剩余任务，**返回的是尚未执行的任务**。
> 4)当线程池处于SHUTDOVN状态，执行其shutdownNow()方法会将其状态转变为STOP。
> 5)等待线程池的所有工作线程停止，工作队列清空之后，线程池状态会从STOP转变为TIDYING。
> 6)执行完terminated()钩子方法之后，线程池状态从TIDYING转变为TERMINATED。

> **awaitTermination**
>
> 等待线程池完成关闭。在调用线程池的shutdown()与shutdownNow()方法时，当前线程会立即返回，不会一直等待直到线程池完成关闭。如果需要等到线程池关闭完成，可以调用awaitTermination()方法

> (1)FixedThreadPool和SingleThreadPooL 这两个工厂方法所创建的线程池，**工作队列(任务排队的队列)长度都为Integer,MAX_VALUE，可能会堆积大量的任务，从而导致00M (即耗尽内存资源)**。
>
> (2) CachedThreadPoo 和ScheduledThreadPool 这两个工厂方法所创建的**线程池允许创建的线程数量为Integer.MAX_VALUE，可能会导致创建大量的线程**，从而导致00M问题。

> 最佳线程数目 = (线程等时间与线程CPU时间之比 + 1) *CPU核数
>
> 通过公式可以看出: 
>
> **等待时间所占比例越高，需要的线程就越多**
>
> **CPU耗时所占比例越高，需要的线程就越少。**
>
> 下面举一个例子:比如在Web服务器处理HTTP请求时，假设平均线程CPU运行时间为100毫秒，而线程等待时间(比如包括DB操作、RPC操作、缓存操作等)为900毫秒，如果CPU核数为8，那么根据上面这个公式，估算如下(900ms+100ms) /100ms 8= 10 8 = 80

#### 核心属性介绍下？

> **corePoolSize：** 核心池的大小。 当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中
> **maximumPoolSize：** 线程池最大线程数，它表示在线程池中最多能创建多少个线程；
> **keepAliveTime：** 表示线程没有任务执行时最多保持多久时间会终止。
> **unit：** 参数keepAliveTime的时间单位，有7种取值，在TimeUnit类中有7种静态属性：
>
> **ThreadFactory:线**程工厂，用户生产线程执行任务。默认线程工厂创建的线程属于同一线程组，优先级一样，非守护线程。也可以自定义线程工厂，定制不同线程名。
>
> **workQueue和handle：**阻塞队列和任务拒绝策略

#### 拒绝策略有哪些？

> **AbortPolicy**：丢弃任务并抛出RejectedExecutionException异常。用户可以感知然后自己处理。
>
> **DiscardPolicy：**丢弃任务，静默丢弃，不通知。容易数据丢失。
>
> **DiscardOldestPolicy**：丢弃队列头节点，通常是存活时间最长的，这样可以腾出空间给新的任务。也存在数据丢失风险。
>
> **CallerRunsPolicy：**任务交与提交任务的线程执行。谁提交任务，谁来执行。<u>这样新提交的任务不会丢失，不会造成业务丢失。二是</u>
>
> <u>提交任务执行时，是比较耗时的，此线程被占用之后，后续不会有新的线程提交。然后线程池中任务也可以趁机消耗，相当于给了线程池缓冲。</u>

#### 工作原理

> 提交一个任务到线程池中，线程池的处理流程如下：
>
> 1、判断线程池里的核心线程是否都在执行任务，如果不是（核心线程空闲或者还有核心线程没有被创建）则创建一个新的工作线程来执行任务。如果核心线程都在执行任务，则进入下个流程。
>
> 2、线程池判断工作队列是否已满，如果工作队列没有满，则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。
>
> 3、判断线程池里的线程是否都处于工作状态，如果没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。
>
> ![image-20241211092809817](img/image-20241211092809817.png)

#### 如何配置线程池？

通过构造ThreadPoolTaskExecutor对象，分别配置相关的属性值。

主要关注核心线程数，一般情况下

CPU密集型：核心线程数 = CPU核数 + 1      大概是机器的cpu核数1~2倍
IO密集型：核心线程数 = CPU核数 * 2      （**<u>推荐计算方法 线程数 = CPU核心数 * (1+平均等待时间/平均工作时间)）</u>**

`某些进程花费了绝大多数时间在计算上、压缩、解密、加密等称为CPU密集型，而其他则在等待I/O上花费了大多是时间，如数据库、文件读写、网络通信成为IO密集型`

#### 线程池复用原理？

从源码层面

当线程池调用execute方法时 - > 内部执行addworker方法 -> 进而调用worker.runWorker(这里不是一味的新建任务，而是通过while循环来不断获取任务实现任务的复用)

### ThreadLocal

> **ThreadLocal使用场景**
>
> 1、ThreadLocal的主要价值在于**线程隔离，提升了并发性的性能**。数据库连接独享、Session数据管理等
>
> 2、**跨函数传递数据**。同一个线程内，跨类、跨方法传递数据时，如果不用ThreadLocaL，那么相互之间的数据传递势必要靠返回值和参数，这样无形之中增加了这些类或者方法之间的耦合度。 (可以为每个线程绑定一个Session(用户会话)信息，这样一个线程所有调用到的代码都可以非常方便地访问这个本地会话，而不需要通过参数传递)

> 与早期版本的ThreadLocalMap实现相比，**新版本的主要变化**为:
> 1)拥有者发生了变化: **新版本的ThreadLocaMap拥有者为Thread(优势2)**，早期版本的ThreadLocalMap拥有者为ThreadLocal。
>
> 2)Key发生了变化: **新版本的Key为ThreadLocal实例(优势1)**，早期版本的Key为Thread实例。与早期版本的ThreadLocalMap实现相比,
> **新版本的主要优势为**
>
> 1)每个ThreadLocalMap存储的“Key-Value对"数量变少。早期版本的“KeyValue对”数量与线程个数强关联，若线程数量多，则ThreadLocalMap存储”Key-Value对”数量也多，**新版本的ThreadLocalMap的Key为ThreadLocal实例，多线程情况下ThreadLocal实例比线程数少。**
>
> 2)早期版本ThreadLocalMap的拥有者为ThreadLocal，在Thread (线程)实例被销毁后ThreadLocalMap还是存在的; **新版本的ThreadLocalMap的拥有者为Thread，现在当Thread实例被销毁后ThreadLocaLMap也会随之被销毁，在一定程度上能减少内存的消耗**

> ThreadLocalMap发生hash冲突，使用开放定址法找后面空的位置

> 由于ThreadLocalMap中Entry的Key使用了弱引用，在下次**GC发生时，就可以使那些没有被其他强引用指向、仅被Entry的Key所指向的ThreadLocal实例能被顺利回收**，并且，在Entry的Key引用被回收之后，其Entry的Key值变为null。后续**当ThreadLocal的get()、set()或remove()被调用时，ThreadLocalMap的内部代会清除这些Key为null的Entry，从而完成相应的内存释放**
>
> **如果是强引用的话，如果方法栈桢使用ThreadLocal，执行结束，ThreadLocal理应被释放，但是由于内部ThreadLocaLMap的key强引用ThreadLocal导致，无法被释放，容易造成内**存泄漏。

### cas&juc

> public final native boolean compareAndSwapObject(Object o, long offset,Objectexpected,0bject update);
>
> Unsafe提供的CAS方法包含4个操作数-一字段所处的对象、字段内存位置、预期原值及新值。
>
> 在执行Unsafe的CAS方法时，这些方法首先**将内存位置的值与预期值(旧的值)比较**，如果相匹配，那么处理器会自动将该内存置的值更新为新值，并返回true; 如果不匹配，处理器不做任何操作，并返回false。
>
> **Unsafe的CAS操作会将第一个参数(对象的指针、地址) 与第二个参数(字段偏移量,这个是相对偏移量，从对象头markworld+kclass后算)组合在一起，计算出最终的内存操作地址**

> **引用原子类 引用原子类主要包括以下三个**
> AtomicReference: 引用类型原子类。
> AtomicMarkableReference: 带有更新标记位的原子引用类型。 类似 数据库更新加了版本号的概念
>
> AtomicStampedReference: 带有更新版本号的原子引用类型。 类似状态位概念 只有 true false
>
> AtomicMarkableReference类将boolean标记与引用关联起来，可以解决使用AtomicBoolean进行原子方式的更新时可能出现的ABA问题
> AtomicstampedReference类将整数值与引用关联起来，可以解决使用AtomicInteger进行原子方式的更新时可能出现的ABA问题。

> **LongAdder**
>
> 基本思路就是**分散热点，将value值分散到一个数组中，不同线程会命中到数组的不同槽(元素)中，各个线程只对自己槽中的那个值进行CAS操作**
>
> LongAdder继承于Striped64类，Striped64内部包含一个base和一个CelL[]类型的ceLLs数组，ceLLs数组又叫哈希表。在**没有竞争的情况**下，要累加的数通过**CAS累加到base**上; 如果**有竞争的话，会将要累加的数累加到CelLs数组中的某个ceLL元素里面**。所以striped64的整体值value =base+∑[0~n]cells

> **Copy0nWirite(写时复制)**
> 就是在修改器对一块内存进行修改时，不直接在原有内存块上进行写操作，而是将内存复制一份，在新的内存中进行写操作，写完之后，**再将原来的指针(或者引用)指向新的内存**，原来的内存被回收
>
> 读取操作没有任何同步控制和锁操作，读取的是操作内存
> add()方法在执行时加了独占锁，底层都是重新复制了一份数组，再往新的数组中添加新元素，待添加完了，再将新的array引用指向新的数组。
> Copy0nyriteArrayList和ReentrantReadWriteLock读写锁的思想非常类似，即读读共享、写写互斥、读互斥、写读互斥。但是前者相比后者更进一步: 为了将读取的性能发挥到极致，Copy0nWriteArrayList**读取是完全不用加锁的，而且写入也不会阻塞读取操**作，只有写入和写入之间需要进行同步等待，于是读操作的性能得至大幅度提升

> //初始化单例 instance = new Singleton();
> 这行初始化单例代码转换成了汇编指令 (具有原子性的指令)后，大致会细分成三个:
> 1)分配一块内存M。
> 2)在内存M上初始化singleton对象。
> 3)M的地址赋值给instance变量。
>
> 编译器、CPU都可能对没有内存屏障、数据依赖关系的操作进行重排序，上述的三个指令优化后可能就变成了这
> 1)分配一块内存M
> 2)将M的地址赋值给instance变量。
> 3)在内存M上初始化Singleton对象。
> **静态内部类实例懒汉单例模式**只有在getInstance()被调用时才去加载内部类并且初始化单例，该方式既解决了线程安全问题，又解决了写法烦琐问题。**线程安全主要是静态内部类加载时，jvm虚拟机会保证线程安全，只加载一次，cinit方法**

> **ForkJoin框架的核心原理**:
>
> 1) ForkJoin框架的线程池ForkJoinPool的任务分为“外部任务”和“内部任务”。
>    2)“外部任务”是放在ForkJonPool的全局队列中。
>
> 2) ForkJoinPool池中的每个线程都维护着一个任务队列用于存放”内部任务”，线程切割任务得到的子任务就会作为“内部任务”放到内部队列中。
>
> 4)当工作线程想要拿到子任务的计算结果时，先判断子任务有没有完成，如果没有完成，再判断子任务有没有被其他线程“窃取”，如果子任务没有被窃取，就由本线程来完成;一旦子任务被窃取了，就去执行本线程“内部队列的其他任务，或者去扫描其他的任务队列并窃取任务。
>
> 5)当工作线程完成其“内部任务”，处于空闲的状态时，就会扫描其他的任务队列窃取任务，尽可能不会阻塞等
>
> **窃取算法: 简单来说，获取自己队列的任务时从头开始，窃取其他队列的任务时从尾开始**

### CAS

> CAS 有三个操作数：内存值 V、预期值 A、要修改的值 B。CAS 最核心的思路就是，**仅当预期值 A 和当前的内存值 V 相同时，才将内存值修改为 B**。
>
> **弊端和规避措施**
>
> 1、ABA问题: 从 A 变成了 B，再由 B 变回了 A，CAS 会认为变量的值在此期间没有发生过变化。使用版本号 JDK提供了两个类AtomicStampedReference(印戳方式，类似数据库更新version)和AtomicMarkableReference（状态位方式 true false ）来解决ABA问题
>
> 2、只能保证一个共享变量之间的原子性操作 ：对多个共享变量操作时，**CAS无法保证操作的原子性  把多个共享变量合并成一个共享变量来操作** 比如AtomicReference
>
> 3、无效CAS会带来开销问题.**自旋时间过长。**单次 CAS 不一定能执行成功，所以 **CAS 往往是配合着循环来实现的**，有的时候甚至是死循环，不停地进行重试，直到线程竞争不激烈的时候，才能修改成功。在高并发的场景下，通常 CAS 的效率是不高的。
>
> 4、部分CPU平台上存在“总线风暴”问题
>
> CAS操作和volatile一样也需要CPU进行通过**MESI协议各个内核的“Cache一致性”**，**会通过**
> **CPU的BUS（总线）发送大量MESI协议相关的消息，产生“Cache一致性流量”**。因为总线被设计
> 为固定的“通信能力”，如果Cache一致性流量过大，总线将成为瓶颈，这就是所谓的“总线风暴”
>
> **提升 CAS 性能**
>
> `方式一：以空间换时间，分散竞争热点`
>
> 1、**分散操作热点**，使用LongAdder替代基础原子类AtomicLong，LongAdder将单个CAS热点（value值）分散到一个cells数组中
>
> 2、使用**队列削峰**，将发生CAS争用的线程加入一个队列中排队
>
> `方式二是使用线程本地变量，从根本上避免竞争`

### 可见性与有序性原理

> **原子性**
>
> 指不会被线程调度机制打断的操作，中间不会有任何线程的切换。
>
> sum++
>
> ① 获取当前sum变量的值，并且放入栈顶。
> ② 将常量1放入栈顶。
> ③ 将当前栈顶中两个值（sum的值和1）相加，并把结果放入栈顶。
> ④ 把栈顶的结果再赋值给sum变量。



> **可见性**
>
> 一个线程对**共享变量的修改**，另一个线程能够立刻可见，我们称为**该共享变量具备内存可见性**
>
> 由于每个线程可能会运行在不同的CPU内核中，因此**每个线程拥有自己的高速缓存**。**同一份数据可能会被缓存到多个CPU内核中，在不同CPU内核中运行的线程看到同一个变量的缓存值就会不一样，就会存在内存的可见性问题**
>
> 为了解决内存的可见性问题，CPU主要提供了两种解决办法：`总线锁和缓存锁`。
>
> **`总线锁**
>
> 前端总线（也叫CPU总线）是**所有CPU与芯片组连接的主干道**，负责CPU与外界所有部件的通信，包括高速缓存、内存、北桥，其控制总线向各个部件发送
> 控制信号、通过地址总线发送地址信号指定其要访问的部件、通过数据总线双向传输。
>
> **某一个CPU访问主存时，总线锁把CPU和主存的通信给锁住了，其他CPU不能操作其他内存地址的数据**
>
> **缓存锁**
>
> 每个CPU通过嗅探在总线上传播的数据来检查自己高速缓存中的值是否过期，**当CPU发现自己缓存行对应的内存地址被修改时，就会将当前CPU的缓存行设置成无效状态**，当CPU对这个数据进行修改操作时，会**重新从系统主存中把数据读到CPU的高速缓存中**
>
> CPU对高速缓存副本如何与主存内容保持一致有几种写入方式供选择，主要的写入方式有以下两种：
>
> Write-Through（直写）模式  数据修改之后需要同时写入低一级的高速缓存和主存
>
> Write-Back（回写）模式  只写入高速缓存。只在**数据被替换出高速缓存或者变成共享（S）状态时**，如果发现数据有变动，才会将最新的数据更
> 新到主存。

> 缓存一致性协议为**MESI写入失效协议**
>
> Modified、Exclusive、Share、Invalid
>
> M 处于Modified状态的缓存行数据，只有在本CPU中有缓存，且其**数据与主存中的数据不一致，数据被修改过**
>
> E 处于Exclusive状态的缓存行数据**只在本CPU中有缓存，且其数据与主存中一致**，**没有被修改过。**
>
> S 处于Shared状态的缓存行的数据在**多个CPU中都有缓存，且与主存一致**。
>
> I 该缓存行是无效的，可能有其他CPU修改了该缓存行。

> Store Buffer 
>
> 用于临时存放没有收到失效Ack（确认）的写入结果
>
> **本地内核将不再需要等待其他内核的响应结果**，只需要把修改的数据临时**写入到Store Buffer**，然后给其他CPU内核发送失效请求；接下来本地内核即可去执行其他指令。**当收到其他内核的失效Ack（响应结果）后，本地内核再把Store Buffer中的数据写入本地缓存行****，并
> 把缓存行状态修改为Modified。
>
> Invalidate Queue
>
> **用于临时存放接收到的失效请求（Invalidate Request**），一旦失效请求进入队列之后，缓存失效方立即进行Ack回复，而不是在执行完成缓存失效操作才进行回复
>
> `Store Buffer是属于缓存写入方（修改数据方）的异步优化措施，而Invalidate Queue可以理解为缓存失效方（失效请求的接收方）的异步优化措施`

> **JMM**
> 将所有的变量都存放在公共主内存中，当线程使用变量时会把主存中的变量复制到自己的工作空间（或者叫作私有内存）中，线程对变量的读写操作，是自己工作内存中的变量副本。
>
> **有序性**
>
> 所谓的程序的有序性，是指程序执行的顺序按照代码的先后顺序执行。如果**程序执行的顺序与代码的先后顺序不同，并导致了错误的结果，即发生了有序性问题**
>
> 

> volatile汇编指令
>
> 汇编指令中，volatile var之前多出一个lock前缀指令`lock addl`
>
> 这个lock的作用就是上面说的总线锁和缓存锁，新版CPU（如IA-32、Intel 64）通过**缓存锁实现对共享内存的独占性访问**，缓存锁（缓存一致性协议）**会阻止两个CPU同时修改共享内存的数据**
>
> 1、**将当前CPU缓存行的数据立即写回系统主存**
>
> 2、lock前缀指令会引起在**其他CPU中缓存了该内存地址的数据无效**  **以上缓存锁的描述**
>
> 3、lock前缀指令的最后一个作用是作为**内存屏障（Memory Barrier）使用，可以禁止指令重排序**，  `硬件层面`
>
> 编译器层面就是保证从主存读取最新值覆盖副本值，每次对变量的改变都会立即同步到主存中

> As-if-Serial规则的具体内容为：不管如何重排序，都必须保证代码在单线程下运行正确。**只能保障单内核指令重排序之后的执行结果正确**，不能保障多内核以及跨CPU指令重排序之后的执行结果正确

> Happens-Before（先行发生）规则，并且确保**只要两个Java语句之间必须存在Happens-Before关系**，JMM尽量确保这两个Java语句之间的内存可见性和指令有序性
>
> 1）程序顺序执行规则（as-if-serial规则）
>
> 2）volatile变量规则   对volatile（修饰的）变量的写操作必须先行发生于对volatile变量的读操作
>
> 3）传递性规则 如果A操作先行发生于B操作，而B操作又先行发生于C操作，那么A操作先行发生于C操作
>
> 4）监视锁规则（Monitor Lock Rule） 对一个监视锁的解锁操作先行发生于后续对这个监视锁的加锁操作
>
> 5）start规则 如果线程A执行 B.start()启动线程B，那么线程A的B.start()操作先行发生于线程B中的任意操作。
>
> 6）join规则   如果线程A执行了B.join()操作并成功返回 B中的任意操作肯定已经发生了

### 红黑树相关

> BST 二叉查找树
>
> 1. 左子树上所有结点的值均小于或等于它的根结点的值.
> 2. 右子树上所有结点的值均大于或等于它的根结点的值.
> 3. 左、右子树也分别为二叉排序树。
> 4. 退化为链表后，时间复度O(n)

> AVL 平衡二树
>
> 1、对于任何一颗子树的root根结点而言，它的左子树任何节点的key一定比root小，而右子树任何节点的key一定比root大 (和BST一致，本身就是一棵BST)
> 2、对于AVL树而言，其中任何子树仍然是AVL树
> 3、**每个节点的左右子节点的高度之差的绝对值最多为1** (插入删除的时候，会自平衡)
> AVL树，**本质上是带了平衡功能的二叉查找树**(二叉排序树，二叉搜索树)。

> **RBTree 红黑树**
> -红黑树也是一种自平衡二叉查找树，与AVL树相比，红黑树牲了部分平衡性，以换取插入/删除操作时较少的旋转操作，整体来说性能要优 于AVL树。
> -在0(logn)时间内做查找,插入和删除
> (颜色属性) 性质1: 节点非黑即红 
>
> (根属性)性质2: **根节点一定是黑色**
> (叶子属性) 性质3: **叶子节点《NIL) 一定是黑色**
> (红色属性)性质4:**每个红色节点的两个子节点，都为黑色**。(从每个叶子到根的所有路径上不能 有两个连续的红色节点)
> (黑色属性)性质5: **从任一节点到其每个叶子的所有路径，都包含相同数目的黑色节点**。

> **红黑树与AVL树区别**
> 1、调整平衡的实现机制不同
> 红黑树根据路径上黑色节点数目一致，来确定是否失衡，如果失衡，就通过变色和旋转来恢复
> AVL根据树的平衡因子(所有节点的左右子树高度差的绝对值不超过1)，来确定是否失衡，如果失衡，就 通过旋转来恢复
> 2、红黑树的插入效率更高
> 红黑树并不追求”完全平衡”，它只要求部分地达到平衡要求，降低了对旋转的要求
> 红黑树能够以0(log n) 的时间复度进行查询、插入、删除操作
> 3、红黑树统计性能比AVL树更高
> AVL树查找、插入和删除在平均和最坏情况下都是0(n)。
> 4、适用性: AVL查找效率高

### [java8](../java8/Java8.md)

## 设计模式

### 设计原则有哪几个？

> 1. 单一职责原则：类的职责需要单一
> 2. 开放封闭原则：对扩展开放，对修改关闭。软件实体支持扩展，不支持修改
> 3. 依赖倒转原则：针对接口编程，而不是实现类编程。高层模块不应该依赖于底层模块，而应该依赖于抽象
> 4. 里式代换原则：子类必须能够完全替换它们的父类型，`简单来说就是子类替换掉父类后，软件功能不受影响，父类才算真正的被复用。而子类也可以在父类的基础上增加新的行为`
> 5. 迪米特法则：如果两个类不必彼此直接通信，那么就不应该发生直接的相互作用。如果其中的一个类需要需要调用另一个类的方法时，可以通过第三者转发这个调用。`强调类之间的松耦合`

### 项目中应用了哪些设计模式，展开说说?

> 1、华泰这边galaxy项目日结跑批时，
>
> 针对多业务部门以及多品种的，多使用策略模式进行解耦，
>
> 相同的业务操作流程采用模板模式进行步骤共用，不同的逻辑延申到子类实现，以及一些复杂的流程进行拆分，
>
> 使用观察者者模式进行一些通用功能的通知，比如借助spring event在接收处理一系列处理后，生成报表的操作，
>
> 或者在接收kafka消息流水时，通过observable，setchanged,通知所有的observer进行消息的处理
>
> 还有些比如，相对环节多的业务流程，比如接收到流水之后，校验、入库、生成确认书、客户信息，这种多环节的，使用责任链模式进行处理

## [JVM]()

> ==即时编译==
> 将一些字节码编译为机器码，并存入 Code Cache，下次遇到相同的代码，直接执行，无需 再编译

> ==类加载过程==
> 加载-连接-初始化-使用-销毁
> 1，将类的(字节码文件装载进方法区)，1.8后也就是元空间，并且内存中生成一个 class对象和方法区的class文件互相保存了各自的地址用于访问。
>
> 2.**连接分为验证、准备、解析**
>
> 验证就是验证类是否符合ivm规范
>
> 准备就是对静态变量分配空间和赋值(如果是final 基本类型 直接赋值) 不是final的或者是final 但是是引用类型的，初始化的赋值
>
> 解析就是将常量池中的符号引用 替换为直接引用
> 3.初始化 是执行初始化方法 cinit()方法的过程
> main 方法所在的类，总会被首先初始化
> 首次访问这个类的静态变量或静态方法时
> 子类初始化，如果父类还没初始化，会引发
> 子类访问父类的静态变量，只会触发父类的初始化
> Class.forName
> new 会导致初始化
> 4.卸载自定义的加载器可能被卸载，jdk自带的不会
> 该类的所有的实例对象都已被GC，也就是说堆不存在该类的实例对象。
> 该类没有在其他任何地方被引用。
> 该类的类加载器的实例已被GC

> ==完整的对象分配流程==
>
> 1、首先Eden 区，满了， 触发一次 Minor GC 存活下来的对象，则会转移到 Survivor**区**
>
> 2、**大对象**（需要**大量连续内存空间的Java对象**，如那种很长的字符串）**直接进入老年代**
>
> 3、Survivor中长期存活的对象进入老年代(年龄超过一定限制（15))
>
> 4、老年代满了而无法容纳更多的对象，Minor GC 之后通常就会进行Full GC，Full GC 清理整个内存堆 – 包括年轻代和年老代。

> ==JVM调优方案==
>
> 1. 调优时机： 
>    a. **heap内存（老年代）持续上涨**，达到设置的最大内存值； 
>    b. **Full GC 次数频繁**； 
>    c. **GC 停顿时间过长（超过1秒**）； 
>    d. **应用出现OutOfMemory 等内存异常**； 
>    e. 应用中有使用本地缓存，且**占用大量内存空间**； 
>    f. 系统吞吐量与响应性能不高或下降。
> 2. 调优原则：
>    a. 多数的Java应用不需要在服务器上进行JVM优化； 
>    b. 多数导致GC问题的Java应用，都不是因为我们参数设置错误，而是代码问题； 
>    c. 在**应用上线之前，先考虑将机器的JVM参数设置到最优**（最适合）； 
>    d. ==**减少创建对象的数量**==； 
>    e. **减少使用全局变量和大对象**； 
>    f. JVM优化，是到最后不得已才采用的⼿段； 
>    g. 在实际使用中，**分析GC情况优化代码**比优化JVM参数更好；
> 3. 调优目标： 
>    a. GC低停顿； 
>    b. GC低频率； 
>    c. 低内存占用； 
>    d. 高吞吐量；
>
>
> 4. 调优步骤： 
>    a. **分析GC⽇志及dump⽂件，判断是否需要优化**，确定瓶颈问题点； 
>    b. 确定jvm调优量化目标； 
>    c. **确定jvm调优参数**（根据历史jvm参数来调整）； 
>    d. **调优⼀台服务器，对比观察调优前后的差异**； 
>    e. 不断的分析和调整，知道找到合适的jvm参数配置； 
>    f. 找到最合适的参数，将这些参数应用到所有服务器，并进行后续跟踪

> ==如何排查JVM问题==
>
> **对于还在正常运行的系统：**
>
> 1. 可以使用**jmap来查看JVM中各个区域的使用情况**
> 2. 可以通过**jstack来查看线程的运行情况**，比如哪些线程阻塞、 是否出现了死锁
> 3. 可以通过**jstat命令来查看垃圾回收的情况**，特别是fullgc，如果发现fullgc比较频繁，那么就得进行
>    调优了
> 4. 通过各个命令的结果，或者jvisualvm等⼯具来进行分析
> 5. ⾸先，初步猜测频繁发送fullgc的原因，如果**频繁发⽣fullgc但是⼜⼀直没有出现内存溢出**，那么**表**
>    **示 fullgc实际上是回收了很多对象**了，所以这些对象最好能在younggc过程中就直接回收掉，避免这些对象进⼊到老年代，对于这种情况，就要考虑这些存活时间不⻓的对象是不是比较大，导致年轻代放不下，直接进⼊到了老年代，**尝试加大年轻代的大⼩，如果改完之后，fullgc减少，则证明**
>    **修改有效**
> 6. 同时，还可以**找到占用CPU最多的线程，定位到具体的方法，优化这个方法的执行**，看是否能避免某些对象的创建，从而节省内存
>
> **对于已经发⽣了OOM的系统：**
>
> 1. ⼀般⽣产系统中都会设置当系统发⽣了OOM时，⽣成当时的dump⽂件（- 
>    **XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/base**）
> 2. 我们可以利用jsisualvm等⼯具来**分析dump⽂件**
> 3. 根据dump⽂件找到异常的实例

> ==GCR0TS==
> 虚拟机栈(栈帧中的本地变量表》 中引用的对象。
> 方法区中类静态属性引用的对象
> 方法区中常量引用的对象
> 本地方法栈中 JNI (即一般说的Native方法) 引用的对象

### JVM虚拟机组成包括哪些？

![image-20241210162235308](img/image-20241210162235308.png)

> - 类加载子系统：核心组件类加载器，**负责将字节码文件中的内容加载到内存中**。
> - 运行时数据区：JVM管理的内存，创建出来的对象、类的信息等等内容都会放在这块区域中。
> - 执行引擎：包含了即时编译器、解释器、垃圾回收器，执行引擎**使用解释器将字节码指令解释成机器码**，使用即时编译器优化性能，使用垃圾回收器回收不再使用的对象。
> - 本地接口：调用本地使用C/C++编译好的方法，本地方法在Java中声明时，都会带上native关键字，如下图所示。

==运行时数据区域==

![image-20241210162820612](img/image-20241210162820612.png)

> ==**程序计数器==：当前线程所执行的字节码的行号指示器，不会发生内存溢出。每个线程只存储一个固定长度的内存地址。**
>
> ------
>
> ==**虚拟机栈==：****线程运行时分配的内存区域**，用于**存储局部变量表、操作数栈、帧数据(动态链接、方法出口)**等信息。先进后出，每个方法的调用使用一个栈帧来保存  `存储方法的` 语法：-Xss栈大小 调整栈大小
>
> `局部变量表:的作用是在方法执行过程中存放所有的局部变量。局部变量表分为两种，一种是字节码文件中的，另外一种是栈帧中的也就是保存在内存中。栈帧中的局部变量表是根据字节码文件中的内容生成的。`
>
> `操作数栈:是栈帧中虚拟机在执行指令过程中用来存放中间数据的一块区域。他是一种栈式的数据结构，如果一条指令将一个值压入操作数栈，则后面的指令可以弹出并使用该值。`
>
> `帧数据主要包含动态链接、方法出口、异常表的引用。`
>
> `动态链接：当前类的字节码指令引用了其他类的属性或者方法时,需要将符号引用（编号）转换成对应的运行时常量池中的内存地址。动态链接就保存了编号到运行时常量池的内存地址的映射关系。`
>
> `方法出口:指的是方法在正确或者异常结束时，当前栈帧会被弹出，同时程序计数器应该指向上一个栈帧中的下一条指令的地址。所以在当前栈帧中，需要存储此方法出口的地址。`
>
> `异常表:存放的是代码中异常的处理信息，包含了异常捕获的生效范围以及异常发生后跳转到的字节码指令位置。`
>
> ------
>
> ==**本地方法栈**==：虚拟机调用 Native 方法服务
>
> ------
>
> ==堆==：线程共享，几乎所有的对象实例都在这里分配内存
>
> `堆空间有三个需要关注的值，used、total、max。used指的是当前已使用的堆内存，total是java虚拟机已经分配的可用堆内存，max是java虚拟机可以分配的最大堆内存。`
>
> 可以通过arthas 查看 dashboard –i  刷新频率(毫秒)  
>
> 要修改堆的大小，可以使用虚拟机参数 –Xmx（max最大值）和-Xms (初始的total)。 建议将-Xmx和-Xms设置为相同的值，，这样在程序启动之后可使用的总内存就是最大内存，而无需向java虚拟机再次申请，减少了申请并分配内存时间上的开销，同时也不会出现内存过剩之后堆收缩的情况。
>
> ------
>
> ==方法区==：存储已被虚拟机加载的**类信息、常量、静态变量、即时编译后的代码**等数据。  `存储类的`
>
> 包含：
>
> - 类的元信息，保存了所有类的基本信息
> - 运行时常量池，保存了字节码文件中的常量池内容
> - 字符串常量池，保存了字符串常量
>
> JDK7及之前的版本将方法区存放在堆区域中的永久代空间，堆的大小由虚拟机参数来控制。
>
> JDK8及之后的版本将方法区存放在元空间中，元空间位于操作系统维护的直接内存中，默认情况下只要不超过操作系统承受的上限，可以一直分配。
>
> ![image-20241210163335038](img/image-20241210163335038-17338196172801.png)
>
> **类的元信息**
>
> 方法区是用来存储每个类的基本信息（元信息），一般称之为InstanceKlass对象。在类的加载阶段完成。其中就包含了类的字段、方法等字节码文件中的内容，同时还保存了运行过程中需要使用的虚方法表（实现多态的基础）等信息。
>
> ![image-20241210204217690](img/image-20241210204217690.png)
>
> **运行时常量池**
>
> 字节码文件中通过编号查表的方式找到常量，这种常量池称为静态常量池。当常量池加载到内存中之后，可以通过内存地址快速的定位到常量池中的内容，这种常量池称为运行时常量池。
>
> ![image-20241210204321482](img/image-20241210204321482.png)
>
> **字符串常量池**
>
> 字符串常量池存储在代码中定义的常量字符串内容。比如“abc” 这个abc就会被放入字符串常量池。
>
> 在堆上创建String对象，并通过局部变量s1引用堆上的对象。
>
> ![image-20241210204502129](img/image-20241210204502129.png)
>
> **字符串常量池和运行时常量池关系？**
>
> ![image-20241210204705546](img/image-20241210204705546.png)

### 直接内存？

并不在《Java虚拟机规范》中存在，所以并不属于Java运行时的内存区域。

直接内存解决

1、Java堆中的对象如果不再使用要回收，回收时会影响对象的创建和使用。

2、IO操作比如读文件，需要先把文件读入直接内存（缓冲区）再把数据复制到Java堆中。

### StackOverFlowError的原因？

> 无限**递归**循环调用（最常见）。   线程请求的栈深度大于虚拟机栈所允许的最大深度
>
> - **执行了大量方法，导致线程栈空间耗尽**。
> - 或者方法内声明了**海量的局部变量**。 无法申请到足够的内存去完成扩展

### JIT即时编辑？

> JIT（即时编译）
>
> 当JVM发现某个方法或代码块运行特别频繁的时候，就会认为这是“热点代码”（Hot Spot Code)。然后JIT会把部分“热点代码”翻译成本地机器相关的机器码，并进行优化，然后再把翻译后的机器码缓存起来，以备下次使用。

### 字节码文件的组成？

> - **基础信息**：魔数、字节码文件对应的Java版本号、访问标识(public final等等)、父类和接口信息
> - **常量池****：** 保存了字符串常量、类或接口名、字段名，主要在字节码指令中使用
> - **字段：** 当前类或接口声明的字段信息
> - **方法：** 当前类或接口声明的方法信息，核心内容为方法的字节码指令
> - **属性：** 类的属性，比如源码的文件名、内部类的列表等

### int i = 0; i = i++; 最终i的值是多少？

> 答案是0，我通过分析字节码指令发现，i++先把0取出来放入临时的操作数栈中，
>
> 接下来对i进行加1，i变成了1，最后再将之前保存的临时值0放入i，最后i就变成了0

### 字节码查看工具？

> `javap -v` 字节码文件名称 查看具体的字节码信息。如果jar包需要先使用 `jar –xvf` 命令解压。
>
> jclasslib 查看
>
> arthas dump命令可以将字节码文件保存到本地  dump -d /tmp/output java.lang.String  #将`java.lang.String` 的字节码文件保存到了/tmp/output目录下：

### 类的生命周期

![image-20241210165214331](img/image-20241210165214331-17338207357193.png)

### 类的生命周期-加载分析?

1、加载(Loading)阶段第一步是**类加载器根据类的全限定名通过不同的渠道以二进制流的方式获取字节码信息**，程序员可以使用Java代码拓展的不同的渠道。

- 从本地磁盘上获取文件
- 运行时通过动态代理生成，比如Spring框架
- Applet技术通过网络获取字节码文件

2、**类加载器在加载完类之后，Java虚拟机会将字节码中的信息保存到方法区中，方法区中生成一个InstanceKlass对象，保存类的所有信息，里边还包含实现特定功能比如多态的信息。**

![img](img/17338209720956.png)

4、Java虚拟机**同时会在堆上生成与方法区中数据类似的java.lang.Class对象，作用是在Java代码中去获取类的信息以及存储静态字段的数据（JDK8及之后）**（作为方法区这些数据的访问入口）。

![img](img/17338209720955.png)

### 类的生命周期-连接分析？

![image-20241210170125107](img/image-20241210170125107-173382128691117.png)

- 验证，验证内容是否满足《Java虚拟机规范》。
- 准备，给静态变量赋初值。  final修饰的基本数据类型的静态变量，准备阶段直接会将代码中的值进行赋值
- 解析，将常量池中的符号引用替换成指向内存的直接引用。

### 类的生命周期-初始化？

初始化阶段是执行初始化方法 `<clinit> ()`方法的过程。包含了静态代码块中的代码，并为静态变量赋值。

1.访问一个类的静态变量或者静态方法会初始化。注意变量是final修饰的并且等号右边是常量不会触发初始化。

2.调用Class.forName(String className)。

3.new一个该类的对象时。

4.执行Main方法的当前类。

5.初始化一个类，如果其父类还未初始化，则先触发该父类的初始化。

添加-XX:+TraceClassLoading 参数可以打印出加载并初始化的类

### 类加载器是什么作用？

类加载器（ClassLoader）是Java虚拟机提供给应用程序去实现获取类和接口字节码数据的技术，

类加载器会通过二进制流的方式获取到字节码文件的内容，接下来将获取到的数据交给Java虚拟机，虚拟机会在方法区和堆上生成对应的对象保存字节码信息。

### 类加载器的分类

Arthas中可以通过`sc -d 类名`的方式查看加载这个类的类加载器详细的信息

classloader  -l 查看当前有哪些类加载器

类加载器的加载路径可以通过classloader –c hash值 查看

> ==启动类加载器==
>
> - 启动类加载器（Bootstrap ClassLoader）是由Hotspot虚拟机提供的、使用C++编写的类加载器。
> - 默认**加载Java安装目录/jre/lib下的类文件**，比如rt.jar，tools.jar，resources.jar等
> - 启动类加载器在JDK8中是由C++语言来编写的，在Java代码中去获取既不适合也不安全，所以获取String.**class**.getClassLoader()才返回`null`
> - 如果用户想扩展一些比较基础的jar包，尽可能不在/jre/lib下扩展 。使用参数进行扩展。推荐，使用-Xbootclasspath/a:jar包目录/jar包名 进行扩展，参数中的/a代表新增。
>
> ==扩展类加载器==
>
> 默认加载Java安装目录/jre/lib/ext下的类文件。
>
> - 如果用户想扩展一些比较基础的jar包，尽可能不在/jre/lib/ext下扩展，使用参数进行扩展使用参数进行扩展。推荐，使用-Djava.ext.dirs=jar包目录 进行扩展,这种方式会覆盖掉原始目录，可以用;(windows):(macos/linux)追加上原始目录
>
> ==应用程序加载器==
>
> 应用程序类加载器会加载classpath下的类文件，默认加载的是项目中的类以及通过maven引入的第三方jar包中的类
>
> ==扩展类加载器和应用程序类加载器==
>
> - 扩展类加载器和应用程序类加载器都是JDK中提供的、使用Java编写的类加载器。
> - 它们的源码都位于sun.misc.Launcher中，是一个静态内部类。继承自URLClassLoader。具备通过目录或者指定jar包将字节码文件加载到内存中。
>
> ![image-20241210172623284](img/image-20241210172623284-173382278479619.png)
>
> - ClassLoader类定义了具体的行为模式，简单来说就是先从本地或者网络获得字节码信息，然后调用虚拟机底层的方法创建方法区和堆上的对象。这样的好处就是让子类只需要去实现如何获取字节码信息这部分代码。
> - SecureClassLoader提供了证书机制，提升了安全性。
> - URLClassLoader提供了根据URL获取目录下或者指定jar包进行加载，获取字节码的数据。
> - 扩展类加载器和应用程序类加载器继承自URLClassLoader，获得了上述的三种能力。

### 双亲委派机制？

> 双亲委派模型是描述类加载器之间的层次关系
>
> 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是**把这个请求委派给父类加载器去完成**，每一个层次的类加载器都是如此，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，**只有当父加载器反馈自己无法完成这个加载请求（找不到所需的类）时，子加载器才会尝试自己去加载
>
> 1.保证类加载的安全性。通过双亲委派机制避免恶意代码替换JDK中的核心类库，比如java.lang.String，确保核心类库的完整性和安全性。
>
> 2.避免重复加载。双亲委派机制可以避免同一个类被多次加载。

### 在Java中如何使用代码的方式去主动加载一个类呢？

方式1：使用Class.forName方法，使用当前类的类加载器去加载指定的类。

方式2：获取到类加载器，通过类加载器的loadClass方法指定某个类加载器加载。

### 打破双亲委派机制

- **自定义类加载器并且重写loadClass方法**。Tomcat通过这种方式实现应用之间类隔离，（自定义类加载器的父类加载器是应用程序类加载器)。
- 线程上下文类加载器。**利用上下文类加载器加载类，比如JDBC和JNDI等**。![image-20241210173942233](img/image-20241210173942233.png)
- Osgi框架的类加载器。历史上Osgi框架实现了一套新的类加载器机制，允许同级之间委托进行类的加载，目前很少使用。

### 两个自定义类加载器加载相同限定名的类，不会冲突吗？

不会冲突，在同一个Java虚拟机中，只有相同类加载器+相同的类限定名才会被认为是同一个类。

在Arthas中使用sc –d 类名的方式查看具体的情况。

### 使用阿里arthas不停机解决线上问题?

> 1. 在出问题的服务器上部署一个 arthas，并启动。
> 2. jad --source-only 类全限定名 > 目录/文件名.java      jad 命令反编译，然后可以用其它编译器，比如 vim 来修改源码
> 3. mc –c 类加载器的hashcode 目录/文件名.java -d 输出目录
>
> ​      mc 命令用来编译修改过的代码
>
> 1.  retransform class文件所在目录/xxx.class
>
> ​      用 retransform 命令加载新的字节码
>
> 程序重启之后，字节码文件会恢复，除非将class文件放入jar包中进行更新。
>
> 使用retransform**不能添加方法或者字段**，**也不能更新正在执行中的方法**

### JDK9类加载器的变化？

由于JDK9引入了module的概念，类加载器在设计上发生了很多变化。

1.启动类加载器使用Java编写，位于jdk.internal.loader.ClassLoaders类中。

   Java中的BootClassLoader继承自BuiltinClassLoader实现从模块中找到要加载的字节码资源文件。

   启动类加载器依然无法通过java代码获取到，返回的仍然是null，保持了统一。

2、扩展类加载器被替换成了平台类加载器（Platform Class Loader）。

​     平台类加载器遵循模块化方式加载字节码文件，所以继承关系从URLClassLoader变成了BuiltinClassLoader，BuiltinClassLoader实现了从模块中加载字节码文件。平台类加载器的存在更多的是为了与老版本的设计方案兼容，自身没有特殊的逻辑。

### 如何判断一个类是否可以被回收？

1、此类所有实例对象都已经被回收，在堆中不存在任何该类的实例对象以及子类对象。

2、加载该类的类加载器已经被回收。

3、该类对应的 java.lang.Class 对象没有在任何地方被引用。

### 判断对象是否可以被回收？

> ==引用计数法==
>
> 引用计数法会为每个对象维护一个引用计数器，当对象被引用时加1，取消引用时减1。
>
> 缺点：
>
> 1.每次引用和取消引用都需要维护计数器，对系统性能会有一定的影响
>
> 2.存在循环引用问题，所谓循环引用就是当A引用B，B同时引用A时会出现对象无法回收的问题。
>
> ==可达性分析法==
>
> Java使用的是可达性分析算法来判断对象是否可以被回收。`可达性分析将对象分为两类：垃圾回收的根对象（GC Root）和普通对象，对象与对象之间存在引用关系`。
>
> 可达性分析算法指的是如果从某个到GC Root对象是可达的，对象就不可被回收。
>
> **GCROOTS包括**
>
> - 线程Thread对象，引用线程栈帧中的方法参数、局部变量等。
> - 系统类加载器加载的java.lang.Class对象，引用类中的静态变量。
> - 监视器对象，用来保存同步锁synchronized关键字持有的对象。
> - 本地方法调用时使用的全局对象。
>
> 查看方式
>
> 通过arthas和eclipse Memory Analyzer (MAT) 工具可以查看GC Root，MAT工具是eclipse推出的Java堆内存检测工具。具体操作步骤如下：
>
> 1、使用arthas的heapdump命令将堆内存快照保存到本地磁盘中。  heapdump 目录/test2.hprof
>
> 2、使用MAT工具打开堆内存快照文件。
>
> 3、选择GC Roots功能查看所有的GC Root。
>
> ![image-20241210205855721](img/image-20241210205855721.png)

### 常见的引用对象？

> ==强引用==
>
> 可达性算法中描述的对象引用，一般指的是强引用，即是GCRoot对象对普通对象有引用关系，只要这层关系存在，普通对象就不会被回收
>
> ### ==软引用==
>
> 如果一个对象只有软引用关联到它，当程序内存不足时，就会将软引用中的数据进行回收。
>
> 在JDK 1.2版之后提供了SoftReference类来实现软引用，软引用常用于缓存中。
>
> 使用方式
>
> 1.将对象使用软引用包装起来，new SoftReference<对象类型>(对象)。
>
> 2.内存不足时，虚拟机尝试进行垃圾回收。
>
> 3.如果垃圾回收仍不能解决内存不足的问题，回收软引用中的对象。
>
> 4.如果依然内存不足，抛出OutOfMemory异常。
>
> `软引用对象本身怎么回收呢？`
>
> 1、软引用创建时，通过构造器传入引用队列
>
> 2、在软引用中包含的对象被回收时，该软引用对象会被放入引用队列
>
> 3、通过代码遍历引用队列，将SoftReference的强引用删除
>
> ==弱引用==
>
> 弱引用的整体机制和软引用基本一致，区别在于弱引用包含的对象在垃圾回收时，不管内存够不够都会直接被回收。在JDK 1.2版之后提供了WeakReference类来实现弱引用，弱引用主要在ThreadLocal中使用。
>
> 弱引用对象本身也可以使用引用队列进行回收
>
> ### ==虚引用和终结器引用==
>
> 虚引用也叫幽灵引用/幻影引用，不能通过虚引用对象获取到包含的对象。`虚引用唯一的用途是当对象被垃圾回收器回收时可以接收到对应的通知`。Java中使用PhantomReference实现了虚引用，直接内存中为了及时知道直接内存对象不再使用，从而回收内存，使用了虚引用来实现
>
> 终结器引用指的是在对象需要被回收时，`终结器引用会关联对象并放置在Finalizer类中的引用队列中`，在稍后由一条由FinalizerThread线程从队列中获取对象，然后执行对象的finalize方法，在对象第二次被回收时，该对象才真正的被回收。在这个过程中可以在finalize方法中再将自身对象使用强引用关联上，但是不建议这样做

### 吞吐量？

吞吐量指的是 CPU 用于执行用户代码的时间与 CPU 总执行时间的比值，即吞吐量 = 执行用户代码时间 /（执行用户代码时间 + GC时间）。吞吐量数值越高，垃圾回收的效率就越高。

### 最大暂停时间

最大暂停时间指的是所有在垃圾回收过程中的STW时间最大值

### 垃圾回收算法？

> ### ==标记清除算法==
>
> 1.标记阶段，将所有存活的对象进行标记。Java中使用可达性分析算法，从GC Root开始通过引用链遍历出所有存活对象。
>
> 2.清除阶段，从内存中删除没有被标记也就是非存活对象。
>
> 优点：实现简单，只需要在第一阶段给每个对象维护标志位，第二阶段删除对象即可。
>
> 缺点：
>
> 1.碎片化问题 
>
> 2.分配速度慢。由于内存碎片的存在，需要维护一个空闲链表，极有可能发生每次需要遍历到链表的最后才能获得合适的内存空间.`我们需要用一个链表来维护，哪些空间可以分配对象，很有可能需要遍历这个链表到最后，才能发现这块空间足够我们去创建一个对象`
>
> ==复制算法==
>
> 1.准备两块空间From空间和To空间，每次在对象分配阶段，只能使用其中一块空间（From空间）。
>
> 2.在垃圾回收GC阶段，将From中存活对象复制到To空间。
>
> 3.将两块空间的From和To名字互换。
>
> 优点：
>
> - 吞吐量高，复制算法只需要遍历一次存活对象复制到To空间即可，比标记-整理算法少了一次遍历的过程，因而性能较好，但是不如标记-清除算法，因为标记清除算法不需要进行对象的移动
> - 不会发生碎片化，复制算法在复制之后就会将对象按顺序放入To空间中，所以对象以外的区域都是可用空间，不存在碎片化内存空间。
>
> 缺点：
>
> 内存使用效率低，每次只能让一半的内存空间来为创建对象使用。
>
> ==标记整理算法==（标记压缩算法）
>
> 1.标记阶段，将所有存活的对象进行标记。Java中使用可达性分析算法，从GC Root开始通过引用链遍历出所有存活对象。
>
> 2.整理阶段，将存活对象移动到堆的一端。清理掉存活对象的内存空间
>
> 优点：
>
> - 内存使用效率高，整个堆内存都可以使用，不会像复制算法只能使用半个堆内存
> - 不会发生碎片化，在整理阶段可以将对象往内存的一侧进行移动，剩下的空间都是可以分配对象的有效空间
>
> 缺点：
>
> 整理阶段的效率不高，整理算法有很多种，比如Lisp2整理算法需要对整个堆中的对象搜索3次，整体性能不佳。可以通过Two-Finger、表格算法、ImmixGC等高效的整理算法优化此阶段的性能
>
> ==分代垃圾回收算法(Generational GC)。==
>
> 1、分代回收时，创建出来的对象，首先会被放入Eden伊甸园区。
>
> 2、随着对象在Eden区越来越多，如果Eden区满，新创建的对象已经无法放入，就会触发年轻代的GC，称为Minor GC或者Young GC。
>
> Minor GC会把需要eden中和From需要回收的对象回收，把没有回收的对象放入To区。
>
> 3、接下来，S0会变成To区，S1变成From区。当eden区满时再往里放入对象，依然会发生Minor GC。
>
> 此时会回收eden区和S1(from)中的对象，并把eden和from区中剩余的对象放入S0
>
> 每次Minor GC中都会为对象记录他的年龄，初始值为0，每次GC完加1。
>
> 4、如果Minor GC后对象的年龄达到阈值（最大15，默认值和垃圾回收器有关），对象就会被晋升至老年代
>
> 5、当老年代中空间不足，无法放入新的对象时，先尝试minor gc如果还是不足，就会触发Full GC，Full GC会对整个堆进行垃圾回收。
>
> 如果Full GC依然无法回收掉老年代的对象，那么当对象继续放入老年代时，就会抛出Out Of Memory异常
>
> ![image-20241210211322540](img/image-20241210211322540.png)
>
> ![image-20241210211418431](img/image-20241210211418431.png)
>
> 

### 为什么分代GC算法要把堆分成年轻代和老年代？

首先我们要知道堆内存中对象的特性：

- 系统中的大部分对象，都是创建出来之后很快就不再使用可以被回收，比如用户获取订单数据，订单数据返回给用户之后就可以释放了。
- 老年代中会存放长期存活的对象，比如Spring的大部分bean对象，在程序启动之后就不会被回收了。
- 在虚拟机的默认设置中，新生代大小要远小于老年代的大小。

分代GC算法将堆分成年轻代和老年代主要原因有：

1、`可以通过调整年轻代和老年代的比例来适应不同类型的应用程序，提高内存的利用率和性能`。

2、`新生代和老年代使用不同的垃圾回收算法`，`新生代一般选择复制算法，老年代可以选择标记-清除和标记-整理算法`，由程序员来选择灵活度较高。

3、`分代的设计中允许只回收新生代（minor gc），如果能满足对象分配的要求就不需要对整个堆进行回收(full gc),STW时间就会减少`。

### 垃圾回收器

比较好的组合选择如下：

JDK8及之前：

ParNew + CMS（关注暂停时间）、Parallel Scavenge + Parallel Old (关注吞吐量)、 G1（JDK8之前不建议，较大堆并且关注暂停时间）

JDK9之后:

G1（默认）

![image-20241210211919701](img/image-20241210211919701.png)

#### 年轻代-Serial垃圾回收器

![image-20241210211953888](img/image-20241210211953888.png)

**回收年代和算法：**

年轻代

复制算法

**优点**

单CPU处理器下吞吐量非常出色

**缺点**

多CPU下吞吐量不如其他垃圾回收器，堆如果偏大会让用户线程处于长时间的等待

**适用场景**

Java编写的客户端程序或者硬件配置有限的场景

#### 老年代-SerialOld垃圾回收器

SerialOld是Serial垃圾回收器的老年代版本，采用单线程串行回收

-XX:+UseSerialGC 新生代、老年代都使用串行回收器。

![image-20241210212028804](img/image-20241210212028804.png)

**回收年代和算法：**

老年代

标记-整理算法

**优点**

单CPU处理器下吞吐量非常出色

**缺点**

多CPU下吞吐量不如其他垃圾回收器，堆如果偏大会让用户线程处于长时间的等待

**适用场景**

与Serial垃圾回收器搭配使用，或者在CMS特殊情况下使用

#### 年轻代-ParNew垃圾回收器

ParNew垃圾回收器本质上是对Serial在多CPU下的优化，使用多线程进行垃圾回收

-XX:+UseParNewGC 新生代使用ParNew回收器， 老年代使用串行回收器

![image-20241210212106844](img/image-20241210212106844.png)

**回收年代和算法：**

年轻代

复制算法

**优点**

多CPU处理器下停顿时间较短

**缺点**

吞吐量和停顿时间不如G1，所以在JDK9之后不建议使用

**适用场景**

 JDK8及之前的版本中，与CMS老年代垃圾回收器搭配使用

#### 老年代- CMS(Concurrent Mark Sweep)垃圾回收器

CMS垃圾回收器关注的是系统的暂停时间，允许用户线程和垃圾回收线程在某些步骤中同时执行，减少了用户线程的等待时间。

参数：XX:+UseConcMarkSweepGC

![image-20241210212137446](img/image-20241210212137446.png)

**回收年代和算法：**

老年代

标记清除算法

**优点**

系统由于垃圾回收出现的停顿时间较短，用户体验好

**缺点**

1、内存碎片问题

2、退化问题

3、浮动垃圾问题

**适用场景**

 大型的互联网系统中用户请求数据量大、频率高的场景，比如订单接口、商品接口等

CMS执行步骤：

![image-20241210212334605](img/image-20241210212334605.png)

1.初始标记，用极短的时间标记出GC Roots能直接关联到的对象。

2.并发标记,   标记所有的对象，用户线程不需要暂停。

3.重新标记，由于并发标记阶段有些对象会发生了变化，存在错标、漏标等情况，需要重新标记。

4.并发清理，清理死亡的对象，用户线程不需要暂停。

缺点：

1、CMS使用了标记-清除算法，在垃圾收集结束之后会出现大量的内存碎片，CMS会在Full GC时进行碎片的整理。这样会导致用户线程暂停，可以使用-XX:CMSFullGCsBeforeCompaction=N 参数（默认0）调整N次Full GC之后再整理。

2.、无法处理在并发清理过程中产生的“浮动垃圾”，不能做到完全的垃圾回收。

3、如果老年代内存不足无法分配对象，CMS就会退化成Serial Old单线程回收老年代。

#### 年轻代-Parallel Scavenge垃圾回收器

Parallel Scavenge是JDK8默认的年轻代垃圾回收器，多线程并行回收，关注的是系统的吞吐量。具备自动调整堆内存大小的特点。

![image-20241210212357971](img/image-20241210212357971.png)

**回收年代和算法：**

年轻代

复制算法

**优点**

吞吐量高，而且手动可控。为了提高吞吐量，虚拟机会动态调整堆的参数

**缺点**

不能保证单次的停顿时间

**适用场景**

后台任务，不需要与用户交互，并且容易产生大量的对象。比如：大数据的处理，大文件导出

**常用参数：**

Parallel Scavenge允许手动设置最大暂停时间和吞吐量。Oracle官方建议在使用这个组合时，不要设置堆内存的最大值，垃圾回收器会根据最大暂停时间和吞吐量自动调整内存大小。

- 最大暂停时间，`-XX:MaxGCPauseMillis=n` 设置每次垃圾回收时的最大停顿毫秒数
- 吞吐量，`-XX:GCTimeRatio=n` 设置吞吐量为n（用户线程执行时间 = n/n + 1）
- 自动调整内存大小, `-XX:+UseAdaptiveSizePolicy`设置可以让垃圾回收器根据吞吐量和最大停顿的毫秒数自动调整内存大小

#### 老年代-Parallel Old垃圾回收器

Parallel Old是为Parallel Scavenge收集器设计的老年代版本，利用多线程并发收集。

参数： -XX:+UseParallelGC  或

​           -XX:+UseParallelOldGC可以使用Parallel Scavenge + Parallel Old这种组合。

**回收年代和算法：**

老年代

标记-整理算法

**优点**

并发收集，在多核CPU下效率较高

**缺点**

暂停时间会比较长

**适用场景**

与Parallel Scavenge配套使用

#### G1垃圾回收器

JDK9之后默认的垃圾回收器是G1（Garbage First）垃圾回收器。Parallel Scavenge关注吞吐量，允许用户设置最大暂停时间 ，但是会减少年轻代可用空间的大小。CMS关注暂停时间，但是吞吐量方面会下降。

而G1设计目标就是将上述两种垃圾回收器的优点融合：

1.支持巨大的堆空间回收，并有较高的吞吐量。

2.支持多CPU并行垃圾回收。

3.允许用户设置最大暂停时间。

JDK9之后强烈建议使用G1垃圾回收器。



G1出现之前的垃圾回收器，年轻代和老年代一般是连续的

G1的整个堆会被划分成多个大小相等的区域，称之为区Region，区域不要求是连续的。分为Eden、Survivor、Old区。Region的大小通过堆空间大小/2048计算得到，也可以通过参数-XX:G1HeapRegionSize=32m指定(其中32m指定region大小为32M)，Region size必须是2的指数幂，取值范围从1M到32M。

![image-20241210212604251](img/image-20241210212604251.png)

G1垃圾回收有两种方式：

1、年轻代回收（Young GC）

2、混合回收（Mixed GC）

==年轻代回收==

年轻代回收（Young GC），回收Eden区和Survivor区中不用的对象。会导致STW，G1中可以通过参数

-XX:MaxGCPauseMillis=n（默认200）  设置每次垃圾回收时的最大暂停时间毫秒数，G1垃圾回收器会尽可能地保证暂停时间。

1、新创建的对象会存放在Eden区。当G1判断年轻代区不足（max默认60%），无法分配对象时需要回收时会执行Young GC。

2、标记出Eden和Survivor区域中的存活对象，

3、根据配置的最大暂停时间选择某些区域将存活对象复制到一个新的Survivor区中（年龄+1），清空这些区域

![image-20241210212720260](img/image-20241210212720260.png)

G1在进行Young GC的过程中会去记录每次垃圾回收时每个Eden区和Survivor区的平均耗时，以作为下次回收时的参考依据。这样就可以根据配置的最大暂停时间计算出本次回收时最多能回收多少个Region区域了。比如 -XX:MaxGCPauseMillis=n（默认200），每个Region回收耗时40ms，那么这次回收最多只能回收4个Region。

4、后续Young GC时与之前相同，只不过Survivor区中存活对象会被搬运到另一个Survivor区。

5、当某个存活对象的年龄到达阈值（默认15），将被放入老年代

6、部分对象如果大小超过Region的一半，会直接放入老年代，这类老年代被称为Humongous区。比如堆内存是4G，每个Region是2M，只要一个大对象超过了1M就被放入Humongous区，如果对象过大会横跨多个Region

7、多次回收之后，会出现很多Old老年代区，此时总堆占有率达到阈值时

（-XX:InitiatingHeapOccupancyPercent默认45%）会触发混合回收MixedGC。回收所有年轻代和部分老年代的对象以及大对象区。采用复制算法来完成。

![image-20241210212857446](img/image-20241210212857446.png)

==混合回收==

混合回收分为：初始标记（initial mark）、并发标记（concurrent mark）、最终标记（remark或者Finalize Marking）、并发清理（cleanup）

G1对老年代的清理会选择存活度最低的区域来进行回收，这样可以保证回收效率最高，这也是G1（Garbage first）名称的由来

注意：如果清理过程中发现没有足够的空Region存放转移的对象，会出现Full GC。单线程执行标记-整理算法，此时会导致用户线程的暂停。所以尽量保证应该用的堆内存有一定多余的空间。

![image-20241210213011600](img/image-20241210213011600.png)

![image-20241210213028153](img/image-20241210213028153.png)

参数1： `-XX:+UseG1GC`  打开G1的开关，JDK9之后默认不需要打开

参数2：`-XX:MaxGCPauseMillis=毫秒值` 最大暂停的时

**回收年代和算法：**

年轻代+老年代

复制算法

**优点**

对比较大的堆如超过6G的堆回收时，延迟可控

不会产生内存碎片

并发标记的SATB算法效率高

**缺点**

JDK8之前还不够成熟

**适用场景**

JDK8最新版本、JDK9之后建议默认使用

### 内存泄漏

内存泄漏（memory leak）：在Java中如果不再使用一个对象，但是该对象依然在GC ROOT的引用链上，这个对象就不会被垃圾回收器回收，这种情况就称之为内存泄漏

场景：

- 在处理用户的请求之后，没有及时将用户的数据删除。随着用户请求数量越来越多，内存泄漏的对象占满了堆内存最终导致内存溢出
- 任务调度时，被调度的Java应用在调度任务结束中出现了内存泄漏，最终导致多次调度之后内存溢出。

### 内存泄漏的监控工具

top命令是linux下用来查看系统信息的一个命令，它提供给我们去实时地去查看系统的资源，比如执行时的进程、线程和系统参数等信息。进程使用的内存为RES（常驻内存）- SHR（共享内存）

**优点：**

- 操作简单
- 无额外的软件安装

**缺点：**

只能查看最基础的进程信息，无法查看到每个部分的内存占用（堆、方法区、堆外） 

![img](img/asynccode)

VisualVM

**优点：**

- 功能丰富，实时监控CPU、内存、线程等详细信息
- 支持Idea插件，开发过程中也可以使用

**缺点：**

对大量集群化部署的Java进程需要手动进行管理

如果需要进行远程监控，可以通过jmx方式进行连接。在启动java程序时添加如下参数：

```Java
-Djava.rmi.server.hostname=服务器ip地址
-Dcom.sun.management.jmxremote
-Dcom.sun.management.jmxremote.port=9122
-Dcom.sun.management.jmxremote.ssl=false
-Dcom.sun.management.jmxremote.authenticate=false
```

Arthas

**优点：**

- 功能强大，不止于监控基础的信息，还能监控单个方法的执行耗时等细节内容。
- 支持应用的集群管理

**缺点：**

部分高级功能使用门槛较高

**arthas tunnel**管理所有需要监控的程序

### 内存溢出的原因

> ==代码中的内存泄露==
>
> 总结了6种产生内存泄漏的原因，均来自于java代码的不当处理：
>
> - equals()和hashCode()，不正确的equals()和hashCode()实现导致内存泄漏
>
> `在定义新类时没有重写正确的equals()和hashCode()方法。在使用HashMap的场景下，如果使用这个类对象作为key，HashMap在判断key是否已经存在时会使用这些方法，如果重写方式不正确，会导致相同的数据被保存多份。`
>
> 解决方案：
>
> 1、在定义新实体时，始终重写equals()和hashCode()方法。
>
> 2、重写时一定要确定使用了唯一标识去区分不同的对象，比如用户的id等。
>
> 3、hashmap使用时尽量使用编号id等数据作为key，不要将整个实体类对象作为key存放。
>
> ------
>
> 
>
> - ThreadLocal的使用，由于线程池中的线程不被回收导致的ThreadLocal内存泄漏
>
> `如果仅仅使用手动创建的线程，就算没有调用ThreadLocal的remove方法清理数据，也不会产生内存泄漏。因为当线程被回收时，ThreadLocal也同样被回收。但是如果使用线程池就不一定了`
>
> 解决方案：
>
> 线程方法执行完，一定要调用ThreadLocal中的remove方法清理对象。
>
> ------
>
> 
>
> - 内部类引用外部类，非静态的内部类和匿名内部类的错误使用导致内存泄漏
>
> `1、非静态的内部类默认会持有外部类，尽管代码上不再使用外部类，所以如果有地方引用了这个非静态内部类，会导致外部类也被引用，垃圾回收时无法回收这个外部类。`
>
> `2、匿名内部类对象如果在非静态方法中被创建，会持有调用者对象，垃圾回收时无法回收调用者。`
>
> 1、这个案例中，使用内部类的原因是可以直接获取到外部类中的成员变量值，简化开发。如果不想持有外部类对象，应该使用静态内部类。
>
> 2、使用静态方法，可以避免匿名内部类持有调用者对象。
>
> ------
>
> 
>
> - String的intern方法，由于JDK6中的字符串常量池位于永久代，intern被大量调用并保存产生的内存泄漏
>
> `JDK6中字符串常量池位于堆内存中的Perm Gen永久代中，如果不同字符串的intern方法被大量调用，字符串常量池会不停的变大超过永久代内存上限之后就会产生内存溢出问题`
>
> 解决方案：
>
> 1、注意代码中的逻辑，尽量不要将随机生成的字符串加入字符串常量池
>
> 2、增大永久代空间的大小，根据实际的测试/估算结果进行设置-XX:MaxPermSize=256M
>
> ------
>
> 
>
> - 通过静态字段保存对象，大量的数据在静态变量中被引用，但是不再使用，成为了内存泄漏
>
> `如果大量的数据在静态变量中被长期引用，数据就不会被释放，如果这些数据不再使用，就成为了内存泄漏。`
>
> 解决方案：
>
> 1、尽量减少将对象长时间的保存在静态变量中，如果不再使用，必须将对象删除（比如在集合中）或者将静态变量设置为null。
>
> 2、使用单例模式时，尽量使用懒加载，而不是立即加载。
>
> ------
>
> 
>
> - 资源没有正常关闭，由于资源没有调用close方法正常关闭，导致的内存溢出
>
> `连接和流这些资源会占用内存，如果使用完之后没有关闭，这部分内存不一定会出现内存泄漏，但是会导致close方法不被执行。`
>
> 解决方案：
>
> 1、为了防止出现这类的资源对象泄漏问题，必须在finally块中关闭不再使用的资源。
>
> 2、从 Java 7 开始，使用try-with-resources语法可以用于自动关闭资源。
>
> ------
>
> ==并发请求问题==
>
> 并发请求问题指的是由于用户的并发请求量有可能很大，同时处理数据的时间很长，导致大量的数据存在于内存中，最终超过了内存的上限，导致内存溢出。
>



## 方案篇

> ==高并发设计方向？==
>
> 1、系统拆分   微服务解耦，每个系统连一个数据库。
> 2、缓存          读多写少场景，保证db与cache的一致性就ok
> 3、MQ           写高并发的场景，必须得用 MQ
> 4、分库分表
> 5、读写分离    读从库，写主库，能容忍解决数据的同步延迟的问题
> 6、ElasticSearch   全文搜索类

> ==幂等性==
>
> 场景: 表单重复提交、接口非法调用、失败重试、重复消息
>
> 前端解决
>
> 1、按钮置灰
>
> 2、提交后重定向新的提示页面，避免刷新，回退，用户需要再进行录入
> 后端解决
> 1.唯-KEY方案 redis set key nx px 成功 代表已经第一次 失败，不操作
> 2 防重表方案 唯一索引 单独的防重表
> 3.状态机表增加状态字 有一个 变换 1 2 3  更新某一次的时候，状态 是前一个 update set status =2 where status =1
> 4、数据库乐观锁 加version或者表字段唯一索引限制
>
> 5.token方案进入表单，去后端申请token，放入redis,同时返回给前端存储cookie 或者变量中
>
> 表单提交时，header携带token，后端先尝试删除，删除成功则代表第一次，否则代表之前已经制除过，属于重复请求
>
> 6、分布式锁

## 算法&协议篇

> ==限流算法==
> **计数器限流**
> 比如规定10分钟内，调用接口的频率不允许超过3次
> redis.incr命令 结合 同时redis的key比如“INTERFACE_用户ID "就是操作标识+用户ID   key设置过期时间10分钟
> <u>解决不了临界问题，10分钟前后都调用3次，超过上限</u>
> **时间窗口限流方案**
> 解决临界问题，计数器其实是一种固定窗口方案。将时间窗划分出来多个时间窗口，每个窗口有独立的计数器。并且每个窗口被分为多个单位，比如600s一个窗口窗口分为200s一个单位，每过200向后滑动。 当在窗口后调用时，其实已经滑动了一个小的单位，这个窗口范围就变化了。
> 时间单位格子划分的越小，滑动越平缓，统计越精确。
> **令牌桶方案**
> 1。初始化令牌桶，设置最大令牌数，当桶内的令牌达到阈值时，拒绝新加的令牌或者丢弃。
> 2.根据限流大小，启动一个线程，按一定速率向令牌桶中不断增加新的令牌。
> 3。任何处于限流访问的请求，都需要获取到一个可用令牌，再处理。
> 4。获取到令牌时，执行，执行完成，从桶内移除令牌。
> 5，桶也会设置最小阈值。桶内令牌数低于最小阈值时，不会移除，会还给桶。
> **漏桶方案**
> 请求进入的速率大于漏桶下方的处理速率时，多出来的请求放入桶中等待，当阻塞超过最大限制时，丢弃或拒绝.
>
> 宽进严出

## 理论篇

> ==微服务理解？==
>
> 微服务把各个模块 拆分成不同的项目，每个模块都只关注一个特定的业务功能，发布时每一个项目都是一个独立的包，运行在独立的进程上。
> 优点:
> 解耦大的业务板块，可维护性高。
> 服务可以独立部署，风险降低
> 服务自身，易于扩展，技术栈也不受限制，通过轻量通信机制通信
> 缺点:
> 服务增多，运维要求高
> 分布式固有的复杂性，比如容错，存在服务调用了、数据一致性、通信成本、监控
> 接口修改成本高，需要排查影响范围
> 重复代码，功能

> ==微服务设计原则==
> **AKF划分原则** ，旨在提供一个系统化的扩展思路
> X轴:直接水平复制应用进程来扩展系统。(无状态服务，集群) 无法解决数据增长带来的压力
> Y 轴: 将功能拆分出来扩展系统(分库分表、引入缓存)。
> z 轴: 基于用户信息扩展系统(比如分地域，本质是拆分用户数据，用户路由至不同的数据库中)。
> **前后端分离**
> **高内聚、低糊合**
> **服务自身符合开闭原则，更改只影响自身**

> ==负载均衡的意义==
> 负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一 资源的过载.

> ==微服务之间如何通信?==
> 同步进行远程过程调用，(RPC REST,服务注册和发现，直接调用远程服务)
> 使用异步消息来做服务间通信。服务间通过消息管道来交换消息，从而通信(消息队列)

## spring篇

> IOC/DI

> AOP 静态代理 动态代理 cglib jdk

> 循环循赖
> setter注入 入 三级缓存实现 singtonobjects earlysingtonobjects singtonFactories

> @trancsactional实现细节

> 事务传播级别

> ==(BeanFactory 和 ApplicationContext有什么区别?==
>
> 从依赖关系看
> BeanFactory: 是Spring里面最底层的接口，包含了各种Bean的定义，读取bean配置文档，管理bean的加载、实例化，控制bean的生命周期，维护bean之间的依赖关系。ApplicationContext接口作为BeanFactory的派生，除了提供BeanFactory所具有的功能外，还提供了 更完整的框架功能:
> 继承MessageSource，因此支持国际化
>
> 统一的资源文件访问方式。
> 提供在监听器中注册bean的事件。
> 同时加载多个配置文件。 载入多个 (有继承关系)上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web 层。
>
> 从加载方式看
> BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才 对该Bean进行加载实例化。
> ApplicationContext，它是在容器启动时，一次性创建了所有的Bean
>
> ==ApplicationContext通常的实现是什么?==
> FileSystemXmlApplicationContext : 此容器从一个XML文件中加载beans的定义，XML Bean 配置 文件的全路径名必须提供给它的构造函数
> ClassPathXmLApplicationContext: 此容器也从一个XML文件中加载beans的定义，这里，你需要正确设置classpath因为这个容器将在classpath里找bean配置WebXmLApplicationContext: 此容器加载一个XML文件，此文件定义了一个WEB应用的所有bean.
> ==@Autowired注解自动装配的过程是怎样的?==
> 在启动spring IoC时，容器自动装载了一个AutowiredAnnotationBeanPostProcessor后置处
> 当 容器扫描到@Autowied、 @Resource或@Inject时，就会在IoC容器自动查找需要的bean，并装配给该对象的属性。
> 在使用@Autowired时，首先在容器中查询对应类型的bean:
> 如果查询结果刚好为一个，就将该bean装配给@Autowired指定的数据
> 如果查询的结果不止一个，那么@Autowired会根据名称来查找;
> 如果上述查找的结果为空，那么会抛出异常。解决方法时，使用required=false。

> ==AbstractRoutingDataSource动态数据源实现==
>
> 1、AbstractRoutingDataSource类持有多数据源map，默认数据源key。
>
> 2、web项目启动，bean初始化时会从配置文件中读取并转换获取数据源map，以及配置文件中读取的默认数据源key。
>
> 3、线程执行时，`使用本地线程栈，通过拦截器或手动的方式存入数据源key`，在后续sql执行时获取业务需要数据源key。
>
> 4、`在运行sql时会调用父类getConnection()方法，此方法中会通过子类重写的determineCurrentLookupKey方法决定业务需要数据源key，再从数据源map中获取需要的数据源`

## springboot篇

> ==优势&介绍==
>
> springboot 使用“习惯优于配置”的理念让项目快速运行起来，
> 独立运行spring项目，springboot可以以jar包的形式独立运行,
>
> 内嵌servLet容器，可以内嵌tomcat，接天jetty，或者undertow，这样我们就可以不用war包形式部署项目
>
> 提供starter简化maven配置，spring提供了一系列starter pom 来简 化maven的依赖加载， 当使用了spring-boot-starter-web时，会自动加载所需要的依赖包
>
> 自动配置spring sprintboot 会根据在类路径的jar包，类，为jar包中的类自动配置bean，这样会极大的减少使用的配置，会根据启动类所在的目录，自动配置bean

> ==springboot 和spring区别?==
>
> 编码风格 restful 
>
> 配置 xml一 java config propertites xml -yml默认starter支持
>
> 部署 内嵌tomcat
>
> 监控 actuator restful接口获取

> ==自动装配==
> 启动类的@SpringBootApplication注解由@SpringBootConfiguration，@EnableAutoConfiguration，@ComponentScan三个注解组成，三个注解共同完成自动装配;
>
> @SpringBootConfiguration 注解标记启动类为配置类
>
> @ComponentScan 注解实现启动时扫描启动类所在的包以及子包下所有标记为bean的类由IOC容器注册为bea
>
> @EnableAutoConfiguration通过 @Import 注解导入 AutoConfigurationImportSelector类，然后过AutoConfigurationImportSelector 类的 selectImports 方法去读取需要被自动装配的组件依赖下spring.factories文件配置的组件的类全名，并按照一定的规则过滤掉不符合要求的组件的类全名，将剩余读取到的各个组件的类全名集合返回给IOC容器，并将这些组件注册为bean

> SpringBoot专注于快速、方便的开发单个微服务个体，Springcloud关注全局的服务治理框架



## springcloud篇

> ==项目使用版本==
>
> <springframework.version>5.3.12</springframework.version>
>
> <spring.boot.version>2.5.6</spring.boot.version>
>
> <spring.cloud.version>2020.0.4</spring.cloud.version>

> ==springcloud和dubbo区别==
> (1) 服务调用方式: dubbo是RPC，Spring cloud是Rest Api。
> (2) 注册中心: dubbo 是zookeeper，spring cloud可以是zookeeper或其他。
> (3)服务网关: dubbo本身没有实现，只能通过其他第三方技术整合，springcloud有Zuul路由网关 作为路由服务器，进行消费者的请求分发,springcloud支持断路器，与git完美集成配置文件，支持版本控 制，事物总线实现配置文件的更新与服务自动装配等等一系列的微服务架构要素。
> (4) 架构完整度: Spring CLoud包含诸多微服务组件要素，完整度上比Dubbo高

> ==Feign Ribbon Hystrix 三者关系==
> 1介绍三个的定义和功能
> 2、如果微服务项目加上了spring-cloud-starter-netflix-hystrix依赖，那么，feign会通过代理模式自动 将所有的方法用 hystrix 进行包装
>
> 3、一方面，微服务之间的互相调用可以通过Feign进行声明式调用，在这个过程中Feign会通过Ribbon从服务册中心获取目标微服务的服务器地址列表，进行负债均衡调用。
>
> 另一方面微服务在互相调用的过程中，为了防止某个微服务的故障消耗掉整个系统所有微服务的连接资源，调用方会针对被调用微服务设置调用超时时间，一旦超就会进入熔断逻辑，而这个故障指标信息也会 返回给Hystrix组件，Hystrx组件会根据熔断情况判断被调微务的故障情况从而打开熔断器，之后所有针对该微服务的请求就会直接进入熔断逻辑，直到被调微服务故障恢复Hystrix断路器关闭为止。
>
> 
>
> 如果不启用Hystrix，Feign的超时时间则是Ribbon的超时时间，Feign自身的配置也会被覆 盖。如果启用，ribbon的超时时间需要小于hystrix配置的超时时间(由于ribbon需要重试)

### 服务注册和管理

#### [apollo](../apollo/apollo.md)

保证的是CP

#### eureka

> 保证了AP(可用性（A vailability）\分区容错性（Partition tolerance）),无法保证C一致性（C onsistency）
>
> ==工作过程==
>
> 1、Eureka Server 启动成功，等待服务端注册。在启动过程中如果配置了集群，集群之间定时通过 Replicate（复制） 同步注册表，**每个 Eureka Server 都存在独立完整的服务注册表信息** 
>
> 2、**Eureka Client 启动时根据配置的 Eureka Server 地址去注册中心注册服务** 
>
> 3、Eureka Client 会每 **30s 向 Eureka Server 发送一次心跳请求**，证明客户端服务正常 
>
> 4、当 Eureka Server **90s 内没有收到 Eureka Client 的心跳，注册中心则认为该节点失效，会注销该实例** 
>
> 5、单位时间内 Eureka Server **统计到有大量的 Eureka Client 没有上送心跳，则认为可能为网络异常，进入自我保护机制，不再剔除**没有发送心跳的客户 端 
>
> 6、当 Eureka **Client 心跳请求恢复正常之后，Eureka Server 自动退出自我保护模式** 
>
> 7、Eureka Client **定时全量或者增量从注册中心获取服务注册表，并且将获取到的信息缓存到本地** 
>
> 8、服务调用时，Eureka **Client 会先从本地缓存找寻调取的服务。如果获取不到，先从注册中心刷新注册表，再同步到本地缓存** 
>
> 9、Eureka Client 获取到目标服务器信息，发起服务调用 
>
> 10、Eureka Client **程序关闭时向 Eureka Server 发送取消请求，Eureka Server 将实例从注册表中删除**

> **eureka与zookeeper服务拉取方式**
>
> eureka 服务主动拉取策略，每隔30s去eureka拉取服务缓存在本地
> zk中服务首次启动去zk订阅自己需要的服务信息，缓存在本地，然后监听服务列表的变化，变化后zk会推送给消费者
>
> AP 模式
>
> - 服务注册：服务启动检查是否注册属性，为true，**携带自身元数据信息，向eureka server发送rest请求**，eureka保存数据Map<服务名称，服务实例ID>
> - 服务消费：服务启动检查是否拉取服务信息，为true，从rureka server**拉取数据缓存在本地**，30s拉取一次
> - 无效剔除：**eureka server开启定时任务扫描那些心跳过期的服务**，90s没有更新认为失效，进行剔除
> - 自我保护：Eureka会统计最近15分钟心跳失败的服务实例的比例是否超过了85%，超过进入**自我保护机制，不再剔除实例**。`基于所有服务的。`
> - 连接方式：基于短链接和注册中心联系
>
> 存储机制：
>
> 多级缓存机制
> 	1、拉取服务的时候首先从**readOnlycacheMap**中找，其次是**readWriteCacheMap**,最后是**注册表regisstry**
>     2、二级缓存也就是读写缓存数据来源于数据启动从注册表中加载
>     3、三级缓存可用开关开启，关闭则直接从读写缓存取，开启的化，会有一个定时任务从读写缓存到只读缓存的同步。
>     4、只**读缓存ConcurrentHashMap**    **读写缓存guava cache**
> 	**过期策略**
> 		主动过期，服务下线故障的时候，读写缓存过期
> 		**定时过期，读写缓存构建的时候就是180s默认过期**
> 		被动过期，定时30s比对读写缓存和只读缓存的数据，不一致的化，读写覆盖只读
>
> 通过过期的机制，可以发现一个问题，就是如果ReadwriteCacheMap发生了主动过期或定时过期， 此时里面缓存就被清空或部分被过期了， 但是在此之前 readnlyCacheMap刚执行了被动 过期，发现两个缓存是一致的，就会接着使用里面的缓存数据 所以可能会存在30秒的时间，read0nlyCacheMap和ReadWriteCacheMal的据不一致
>
> **eureka和zookeeper比较**
> 1.ZooKeeper保证的是CP,Eureka保证的是AP
> ZooKeeper在选举期间注册服务瘫痪,虽然服务最终会恢复,但是选举期间不可用的 Eureka各个节点是平等关系只要有一台Eureka就可以保证服务可用，而查询到的数据并不是最新的
>
> 自我保护机制会导致 Eureka不再从注册列表移除因长时间没收到心跳而应该过期的服务 ,Eureka仍然能够接受服务的注册和查询请求,但是不会被同步到其他节点(高可用) ,当网络稳定时，当前实例新的注册信息会被同步到其他节点中(最终一致性)
> Eureka可以很好的应对因网络故障导致部分节点失去联系的情况,而不会像ZooKeeper一样使得整 个注册系统瘫痪
> 2.ZooKeeper有Leader和Follower角色,Eureka各个节点平等
> 3.ZooKeeper采用过半数存活原 则,Eureka采用自我保护机制解决分区问题
> 4.Eureka本质上是一个工程,而ZooKeeper只是一个进程

#### nacos

> 临时节点 AP      永久节点CP   Spring Cloud注册中心 + Spring Cloud配置中心
>
> - 临时实例：临时实例会与注册中心保持心跳，不健康会被剔除。
>
> - 永久实例：不会主动向注册中心上报心跳，**注册中心主动探测的方式。**
>
> - 服务注册：也是openAPI方式，调用 Http 接口对服务进行注册
>
> - 连接方式：基于netty长连接方式与注册中心联系
>
> - 自我保护：当**基于某个service的**健康实例 (Instance) 占总服务实例(Instance) 的比例小于阈值时，无论实例 (Instance) 是否健康，都会将这个实例 (Instance) 返回给客户端。**基于某个service的**
>
> - 服务发现：
>
>   **主动拉取模式**，消费者定期主动从Nacos拉取服务列表并缓存起来，在服务调用时优先读取本地缓存中的服务列表。
>
>   订阅模式，消费者订阅Nacos中的服务列表，并基于UDP协议来接收服务变更通知。当Nacos中的服务列表发生更新时，会发送UDP广播给所有订阅者。
>
> 存储模型
>
> Nacos采用了数据的分级存储模型，最外层是**Namespace**，用来隔离环境。然后是**Group**，用来对服务分组。接下来就是**服务(Service)**了，一个服
> 务包含多个实例，但是可能处于不同机房，因此**Service下有多个集群(luster)**，**Cluster下是不同的实例(Instance)**，`对应java代码采用了多层的Map表示`
>
> Nacos = Spring CLoud注册中心 + Spring cloud配置中心，(可以做配置中心，，Nacos采用Netty保持TCP长连接实时推送)
>
> **配置功能**
> 引入 spring-cloud-starter-alibaba-nacos-config
>
> 读取顺序 --本地bootstrap.xml 一远程nacos配置文件 =》 本地application.yml = 》合并然后加载
>
> 配置热更新 @Value注入的变量所在类上添加注解@RefreshScop / @ConfigurationProperties注解代替@Value注解
>
> 配置共享优先级 [spring.application,name].yaml 不包含环境，因此可以被多个环境共享.
>
> 配置共享的优先级nacos中服务名-profile.yaml>nacos中 服务名yaml >本地配置
>
> **Nacos如何保证并发写的安全性?**
> 答: 首先，在注册实例时，会对service加锁，不同service之间本身就不存在并发写问题，互不影响。(相同service时通过锁来互斥)。并且，在更 新实例列表时，是基于异步的线程池来完成，而线程池的线程数量为
> **Nacos如何避免并发读写的冲突?**
> 答: Nacos在更新实例列表时，(会采用Copyonlirite技术)，首先将0Ld实例列表拷贝一份，然后更新拷贝的实例列表，再用更新后的实例列表来 覆盖旧的实例列表。
> **Nacos如何应对阿里内部数十万服务的并发写请求**?
> 答: Nacos内部会将服务注册的任务放入阻塞队列，采用线程池异步来完成实例更新，从而提高并发写能力。

#### consul

> CP模式
>
> Leader挂掉时重新选举期间整个consul不可用

#### zookeeper

> CP 模式

#### apollo

> ==架构理解==
>
> ![image-20241212171230276](img/image-20241212171230276.png)
>
> - ==Config Service提供配置的读取、推送==等功能，服务对象是==Apollo客户端==
> - ==Admin Service提供配置的修改、发布==等功能，服务对象是==Apollo Portal（管理界面）==
> - Config Service和Admin Service都是多实例、无状态部署，所以需要将自己注册到Eureka中并保持心跳
> - Eureka之上我们架了一层Meta Server用于封装Eureka的服务发现接口
> - Client通过域名访问Meta Server获取Config Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Client侧会做load balance、错误重试
> - Portal通过域名访问Meta Server获取Admin Service服务列表（IP+Port），而后直接通过IP+Port访问服务，同时在Portal侧会做load balance、错误重试
> - 为了简化部署，我们实际上会把==Config Service、Eureka和Meta Server三个逻辑角色部署在同一个JVM进程中==
>
> ------
>
> ==实时推送设计==
>
> ![image-20241212171410793](img/image-20241212171410793.png)
>
> - 用户在Portal中进行配置的编辑和发布
> - Portal会调用Admin Service提供的接口进行发布操作
> - Admin Service收到请求后，发送ReleaseMessage给各个Config Service，通知Config Service配置发生变化
> - Config Service收到ReleaseMessage后，通知对应的客户端，基于Http长连接实现
>
> ------
>
> ==发送ReleaseMessage设计==
>
> - Admin Service在配置发布后会往ReleaseMessage表插入一条消息记录
> - ==Config Service会启动一个线程定时扫描ReleaseMessage表，去查看是否有新的消息记录==
> - Config Service发现有新的消息记录，那么就会通知到所有的消息监听器
> - 消息监听器得到配置发布的信息后，则会通知对应的客户端
>
> ------
>
> ==ConfigService通知客户端的设计==
>
> 通知是采用基于Http长连接实现，主要分为下面几个步骤：
>
> - ==客户端会发起一个Http请求到Config Service的notifications/v2接口==
> - ==v2接口通过Spring DeferredResult把请求挂起，不会立即返回==
> - 如果在60秒内没有该客户端关心的配置发布，那么会返回Http状态码304给客户端
> - 如果==发现配置有修改，则会调用DeferredResult的setResult方法，传入有配置变化的namespace信息==，同时该请求会立即返回
> - **客户端从返回的结果中获取到配置变化的namespace后，会立即请求Config Service获取该namespace的最新配置**
>
> ------
>
> ==客户端设计==
>
> 1. 客户端和服务端保持了一个长连接，从而能第一时间获得配置更新的推送。（通过Http Long Polling实现）
> 2. 客户端还会==定时从Apollo配置中心服务端拉取应用的最新配置==。
>    - 这是一个fallback机制，为了防止推送机制失效导致配置不更新
>    - 客户端定时拉取会上报本地版本，所以一般情况下，对于定时拉取的操作，服务端都会返回304 - Not Modified
>    - 定时频率默认为==每5分钟拉取一次==，客户端也可以通过在运行时指定System Property: `apollo.refreshInterval`来覆盖，单位为分钟。
> 3. ==客户端从Apollo配置中心服务端获取到应用的最新配置后，会保存在内存中==
> 4. 客户端会把从服务端获取到的配置在本地文件系统缓存一份
>    - 在遇到服务不可用，或网络不通的时候，依然==能从本地恢复配置==
> 5. 应用程序可以从Apollo客户端获取最新的配置、订阅配置更新通知
>
> ------
>
> ==DeferredResult理解==
>
> 是spring MVC 提供的一种异步处理机制
>
> 1. 浏览器发起异步请求
> 2. 请求到达服务端被挂起
> 3. 向浏览器进行响应，分为两种情况：
>    3.1 调用`DeferredResult.setResult()`，请求被唤醒，返回结果
>    3.2 超时，返回一个你设定的结果
> 4. 浏览得到响应，再次重复1，处理此次响应结果
>
> ==原理==
>
> 1、如果控制器中定义方法返回值为`DeferredResult`，会立即释放`Tomcat`线程，使用业务线程处理业务
>
> 2、由`DeferredResultMethodReturnValueHandler`处理返回结果，开启异步处理并设置`DeferredResultHandler`（ tomcat 每秒扫描等待的异步请求是否超时来触发是否返回默认值，或者应用线程手动塞值到 DeferredResult  触发返回）
>
> 3、业务执行完成后调用`setResult()`方法，紧接着回调`DeferredResultHandler`的`handleResult()`
>
> 4、设置结果并调度请求
>
> 5、创建`Callable`对象并设置调用方法为`call()`
>
> 6、通过**反射方式调用`call()`得到返回值**
>
> 7、使用返回值处理器处理返回值
>
> ![image-20241212171812370](img/image-20241212171812370.png)

### zuul

> Zuul是spring cloud中的微服务网关。
>
> 网关: 是一个网络整体系统中的前置门户入口。请求首先通过网 关，进行路径的路由，定位到具体的服务节点上。
> **使用策略**
> 使用Zuul，一般在微服务数量较多(多于10个)的时候推荐使用
>
> 对服务的管理有严格要求的时候推荐 使用
>
> 当微服务权限要求严格的时候推荐使用。
> 统一入口:为全部为服务提供一个唯一的入口，网关起到外部和内部隔离的作用，保障了后台服务 的安全性。
> 鉴权校验:识别每个请求的权限，拒绝不符合要求的请求。
> 动态路由: 动态的将请求路由到不同的后端集群中。
> 减少客户端与服务端的耦合: 服务可以独立发展，通过网关层来做映射。

> 过滤器
> 继承父类ZuulFilter，过滤器类型包括;
> pre - 前置过滤器，在请求被路由前执行，通常用于处理身份认证，日志记录等;
> route --在路由执行后，服务调用前被调用;
> error  任意一个filter发生异常的时候执行或远程服务调用没有反馈的时候执行(超时)，通常用 于处理异常
> post - 在route或error执行后被调用，一般用于收集服务信息，统计服务性能指标等，也可以对 response结果做特殊处理。

> Zuul降级处理
> Zuul提供了ZuulFallbackProvider的子接口 FallbackProvider来提供fallback处理。
> 只针对timeout异常处理
> 限流处理
> 依赖spring-cloud-zuul-ratelimit组件
> 重试处理
> 使用spring-retry实现

> **Nginx 和 Zuu 的区别和共同点**
> 区别
> Nginx是C语言开发,而 Zuu 是Java语言开发
> Nginx采用服务器实现负载均衡,而Zuul负载均衡的实现是采用 Ribbon + Eureka 来实现本地负载均衡
> Nginx适合于服务器端负载均衡,Zuul适合微服务中实现网关
> Nginx 是一个高性能的HTTP 和反向代理服务器。 Zuul本质上是一个web servlet 应用
> 相同点
> 1、可以实现负载均衡(Zuul使用的是Ribbon实现负载均衡) 
>
> 2可以实现反向代理 (即隐藏实ip地址) 
>
> 3可以过滤请求,实现网关的效果

### gateway

> 1. Gateway 的 客 户 端 回 向 Spring Cloud Gateway 发 起 请 求 ， 请 求 首 先 会 被 **HttpWebHandlerAdapter**进行**提取组装成网关的上下文**，然后网关的上下文会传递到 DispatcherHandler
> 2. **DispatcherHandler是所有请求的分发处理器**，DispatcherHandler主要负责分发请求对应的处理器，比如将请求分发到对应RoutePredicateHandlerMapping(**路由断言处理器映射器**）
> 3. **路 由 断 言 处 理 映 射 器 主 要 用 于 路 由 的 查 找 ， 以 及 找 到 路 由 后 返 回 对 应 的 FilteringWebHandler**
> 4. FilteringWebHandler主要负责组**装Filter链表并调用Filter执行一系列Filter处理**，然后**把请求转到后端对应的代理服务处理，处理完毕后，将Response返回到Gateway客户端。**

> Spring 5.，Spring Boot 2.和 Poject Reactor 等响应式编程和事件流技术开发的网关Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFLux，属于响应式编程的实现，，具备更好的性能核心特性:**请求路由、权限控制、限流**
> 对路由的请求或响应做加工处理，比如添加请求头
> 配置在路由下的过滤器只对当前路由的请求生效
>
> defaultFilters的作用对所有路由都生效的过滤器
>
> 1，路由id:路由的唯一标示
>
> 2.路由目标(uri):路由的目标地址，http代表固定地址，L代表根据服务名负载均衡
>
> 3。路由断言(predicates):判断路由的规则，
> 4。路由过滤器(filters):对请求或响应做处理
>
> 实现GLobalFilter接口 实现自定义在fitter中编写自定义逻辑，可以实现下列功能:登录状态判断权限校验请求限流等
> 请求路由后，会将当前路由过滤器和DefaultFilter、GLobalFilter，合并到一个过滤器链(集合)中,排序后依次执行每个过滤器过滤器的order值一样时，会按照 **defaultFilter > 路由过滤器 >GLobalFilter的顺序执行。**

> 限流
>
> 使用令牌桶限流，RequestRateLimiterGatewayFilterFactory结合Redis的lua脚本方式实现令牌桶限流

### hystrix

> 1. 对于**一次依赖调用，会被封装在一个HystrixCommand对象中**，调用的执行有两种方式，一种是调用**execute()方法同步调用**，另一种是调用**queue()方法进行异步调用**。
> 2. 执行时会判断**断路器开关是否打开**，如果断路器打开，则进入getFallback()降级逻辑；**如果断路器关闭，则判断线程池/信号量资源是否已满**，如果资源满了，则进入 getFallback()降级逻辑；如果没满，则执行run()方法。再判断执行**run()方法是否超时**，超时则进入getFallback()降级逻辑，run()方法执行失败，则进入getFallback()降级逻辑，执行成功则报告Metrics。Metrics中的数据包括执行成功、超时、失败等情况的数据，**Hystrix会计算一个**
>    **断路器的健康值，也就是失败率，当失败率超过阈值后则会触发断路器开关打开**。
> 3. getFallback()逻辑为：如果**没有实现fallback()方法，则直接抛出异常**，另外fallback降级也是需要资源的，在fallback时需要获取一个针对fallback的信号量，只有获取成功才能fallback，获取信号量失败，则抛出异常，获取信号量成功，才会执行fallback方法并且会响应fallback方法中的内容

> `健康统计过程：`
>
> 1. HystrixCommand命令器的执行结果（失败、成功）会以事件的形式，形成执行完成事件流。
> 2. 调用HystrixCommandMetrics.appendEventToBucket ，以事件流作为来源，将**事件流中的事件按照固定时间长度**（桶时间间隔）**划分成滚动窗口**，并对时间桶滚动窗口内的事件**按照类型进行累积**，形成桶计数流（`比如桶时间间隔为3s，1s发出一个事件，那么就会有3个事件被添加到桶内`）
> 3. 桶滑动统计流以桶计数流作为来源，**按照(一定规则)**步长为1、长度为设定的桶数（配置的滑动窗口桶数）的规则**划分滑动窗口**，**并对滑动窗口内的所有的桶数据按照各事件类型进行汇总，汇总成最终**，形成最终的桶滑动统计流。(比如设置2个桶为一个滑动窗口，比如桶 1 2 3 4 ，那么步长为1 代表统计 12 两个桶的  2 3 两高桶的 34 两个桶的)

> `熔断：熔断器模式`
>
> 1）closed：熔断器关闭状态，这也是熔断器的初始状态，此状态下RPC调用正常放行。
> 2）open：失败比例到一定的阈值之后，熔断器进入开启状态，此状态下RPC将会快速失败，执行失败回退逻辑。
> 3）half-open：在打开一定时间之后（睡眠窗口结束），熔断器进入**半开启状态，小流量尝试进行RPC调用放行**。如果尝试成功则熔断器变为closed状态，RPC调用正常；如果尝试失败则熔断器变为open状态，RPC调用快速失败。

> 限流
>
> `舱壁模式`
>
> 为每一个HystrixCommand命令关联上一个指定的线程池，来进行隔离RPC请求
>
> `信号量模式`
>
> 信号量的值就是每个命令的并发执行数量，当并发数高于信号量的值时，就不再执行命令。

> 源码分析：
>
> 1、本质是AOP方式HystrixCommandAspect对使用@HystrixCommand或者@HystrixCollapser（合并请求）进行切面
>
> 2、根据注解配置的信息初始化MetaHolder元数据信息，根据方法的元数据信息，创建HystrixCommand对象（`命令模式，对请求进行参数化`）
>
> 3、结合RxJava响应式编程方式进行实际调用，最终反射调用该方法。

### sentinel

> 什么是雪崩问题？
>
> - 微服务之间相互调用，因为调用链中的一个服务故障，引起整个链路都无法访问的情况。
>
> 解决
>
> **限流**是对服务的保护，避免因瞬间高并发流量而导致服务故障，进而避免雪崩。是一种**预防**措施。
>
> **超时处理、线程隔离、降级熔断**是在部分服务故障时，将故障控制在一定范围，避免雪崩。是一种**补救**措施。

> **簇点链路**
> 当请求进入微服务时，首先会访问DispatcherServlet，然后进入Controller、Service、 Mapper，这样的一个调用链就叫做点链路。簇点链路中被监 控的每一个接口就是一个资源

> 限流
>
> `流控模式`
>
> - 直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式
> - 关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流
> - 链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流
> - 热点参数限流
>
> `流控效果`
>
> - 快速失败：达到阈值后，新的请求会被立即拒绝并抛出FlowException异常。是默认的处理方式。
> - warm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值。
> - 排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长
>
> `隔离方式`
>
> 限制资源能使用用的tomcat线程数的最大值。也就是通过限制线程数量，实现**线程隔离**（舱壁模式）。

> `熔断方式`
>
> **断路器****统计服务调用的异常比例、慢请求比例**，如果超出阈值则会**熔断**该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。
>
> `状态机`
>
> - closed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态
> - open：打开状态，服务调用被**熔断**，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态
> - half-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作。
>   - 请求成功：则切换到closed状态
>   - 请求失败：则切换到open状态
>
> `断路器熔断策略`
>
> **慢调用**：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求
>
> **异常比例**：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现**异常的比例**达到设定的比例阈值（或超过指定**异常数**），则触发熔断
>
> **异常数**

> 授权规则
>
> 支持黑白名单处理
>
> **规则管理模式**
>
> - 原始模式：Sentinel的默认模式，将规则保存在内存，重启服务会丢失。
> - pull模式  将配置的规则推送到Sentinel客户端，客户端会将配置规则保存在本地文件或数据库中。以后会定时去本地文件或数据库中查询，更新本地规则
> - push模式 将配置规则推送到远程配置中心，例如Nacos。Sentinel客户端监听Nacos，获取配置变更的推送消息，完成本地配置更新

> sentinel的限流降级等功能，主要是通过一个SlotChain实现的。在链式插槽中，有7个核心的Slot，这些Slot各司其职
> 一、进行资源调用路径构造的NodeSelectorSlot和ClusterBuilderSlot
> 二、进行资源的实时状态统计的StatisticsSlot
> 三、进行系统保护，限流，降级等规则校验的SystemSlot、AuthoritySlot、FlowSlot、DegradeSlot

### feign

> 一个声明式的伪Http客户端。
>
> Feign是一个HTTP请求调用的轻量级框架，可以以JAVA接口注解的方式调用HTTP请求
>
> 通过处理注解，将请求模板化，当实际调用的时候，传入参数，根据参数再应用到请求上，进而 转化成真正的请求。
>
> 它具有可插拔的注解特性，可使用Feign 注解和JAX-RS注解。Feign支持可插拔的编码器和解码器。 
>
> Feign默认集成了Ribbon进行负载均衡

> **OpenFeign** 
>
> 是 spring 官方推出的一种声明式服务调用和负载均衡组件。
> 优化
> 1.修改 OpenFeign 的超时时间，让 OpenFeign 能够正确的处理业务;
>
> 2.通过配置专用的通信组件 Apache Httpclient 或 OKHttp,让 openFeign 可以更好地对 HTTP 连接对象进行重用和管理，以提高其性能
>
> 3。开启数据压缩功能，可以提高宽带利用率和加速教据传输速度:
>
> 4。使用合适的负载均衡策略来替换默认的轮询负载均衡策略，已获得更好的执行效率;
>
> 5。检查生产成环境中 0penFeign 的日志级别，选择合适的日志输出级别，防止无效的日志输出,

### ribbon

> 是一个基于HTTP和TCP的客户端的负载均衡工具。
>
> 微服务之间的Rest请求转为客户端的负载均衡的RPC调用

> ==工作流程==
>
> Ribbon 简单来说 底层采用了一个拦截器LoadBalancerIntercepor，拦截了RestTemplate发出的请求，
> 从请求url中获取服务名称以及client服务上下文环境里获取负债均衡器，
>
> 负债均衡器根据服务名称提取到服务实例集合(到eureka拉取服务列表)
>
> 用内置负载均衡规则，从列表中选择一个，然后修改请求地址，将请求包装为LoadBalancerCommand，进行真实请求。

> ==负载均衡策略==
> 默认的实现是轮询 可以通过继承 RoundRibbonRule 来实现自定义负载均衡策略。。
>
> RoundRobinRule 轮询来获取
>
> AvailabilityFilteringRule 可用性敏感策略: 先过滤掉非健康的服务实例，然后再选择连接数较小的服务实例
>
> WeightedResponseTimeRule权重(越大访问几率大)。根据每个服务提供者的响应时间分配一个权重,响应时间越 长，权重越小，被选中的可能性也就越低。
>
> 它的实现原理是，刚开始使用轮询策略并开启一个计时器， 每一段时间收集一次所有服务提供者的平均响应时间，然后再给每个服务提供者附上一个权重，权重越 高选中的概率也越大
>
> ZoneAvoidanceRule 分区域，使用Zone对服务器进行分类，再对Zone内的多个服务做轮询
>
> BestAvailableRule忽略那些短路的服务器，并选择并发数较低的服务器。最小连接数策略也叫最小并发数策略，它是遍历服务提供者列表，选取连接数最小的一个服务实例。如果有相同的最小连接数，那么会调用轮询策略进行选取
>
> RandomRule  随机选择一个可用的服务器。
>
> RetryRule 重试机制的选择逻辑 按照轮询策略来获取服务，如果获取的服务实例为null 或已经失效，则在指定 的时间之内不断地进行重试来获取服务，如果超过指定时间依然没获取到服务实则返回 null

## [dubbo篇](../dubbo/dubbo.md)

> ==负载均衡策略==
> 随(默认) : 随机来
> 轮询:一个一个来
> 活跃度: 机器活跃度来负 同活跃数的随机 慢的提供者收到更少请求
> 一致性 hash: 落到同一台机器上

> ==容错策略==
>
> **Failover Cluster** 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries="2" 来设置重试次数(不含第一次)。
>
> ***\*Failfast Cluster\****快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。
>
> ***\*Failsafe Cluster\**** 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。
>
> ***\*Failback Cluster\**** 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。
>
> ***\*Forking Cluster\**** 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。
>
> ***\*Broadcast Cluster\**** 广播调用所有提供者，逐个调用，任意一台报错则报错 [2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。

> ==Dubbo的总体的调用过程吗==
>
> 1**.Proxy持有一个Invoker对象，使用Invoker调用**
> 2.之后通过**Cluster进行负载容错**，失败重试
> 3.调用**Directory获取远程服务的Invoker列表**
> 4.负载均衡用户配置了路由规则，则根据路由规则过滤获取到的Invoker列表用户没有配置路由规则或
> 配置路由后还有很多节点，则使用LoadBalance方法做**负载均衡，选用一个可以调用的Invoker**
> 5.经过一个一个**过滤器链，通常是处理上下文、限流、计数**等。
> 6.会使用**Client做数据传输**
>
> 7.私有化协议的构造(Codec)
> 8.进行序列化
>
> 9.服务端收到这个Request请求，将其**分配到ThreadPool中进行处理**
> 10.Server来处理这些Request
> 11.根据**请求查找对应的Exporter**
> 12.之后**经过一个服务提供者端的过滤器链**
> 13.然后**找到接口实现并真正的调用，将请求结果返回**

> ==Dubbo 服务注册与发现的流程？==
>
> Provider(提供者)绑定指定端口并启动服务
> 指供者连接注册中心，并发本机IP、端口、应用信息和提供服务信息发送至注册中心存储
> Consumer(消费者），连接注册中心 ，并发送应用信息、所求服务信息至注册中心
> 注册中心根据 消费 者所求服务信息匹配对应的提供者列表发送至Consumer 应用缓存。
> Consumer 在发起远程调用时基于缓存的消费者列表择其一发起调用。
> Provider 状态变更会实时通知注册中心、在由注册中心实时推送至Consumer

> ==工作原理/十层架构==
>
> 第一层：service 层，接口层，给服务提供者和消费者来实现的（留给开发人员来实现）；
> 第二层：config 层，配置层，主要是对 Dubbo 进行各种配置的，Dubbo 相关配置；
> 第三层：proxy 层，服务代理层，透明生成客户端的 stub 和服务单的 skeleton，调用的是接口，实现
> 类没有，所以得生成代理，代理之间再进行网络通讯、负责均衡等；
> 第四层：registry 层，服务注册层，负责服务的注册与发现；
> 第五层：cluster 层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服
> 务；
> 第六层：monitor 层，监控层，对 rpc 接口的调用次数和调用时间进行监控；第七层：protocol 层，远
> 程调用层，封装 rpc 调用；
> 第八层：exchange 层，信息交换层，封装请求响应模式，同步转异步；
> 第九层：transport 层，网络传输层，抽象 mina 和 netty 为统一接口；
>
> 第十层：serialize 层，数据序列化层。

> ==怎么实现动态感知服务下线的呢？==
>
> Dubbo ZooKeeper 注册中心采用是**事件通知与客户端拉取方式**
>
> 服务第一次订阅的时候将会拉取对应目录下全量数据，然后在订阅的节点注册一个 watcher。
> 一旦目录节点下发生任何数据变化， ZooKeeper 将会通过 watcher 通知客户端。
> 客户端接到通知，将会重新拉取该目录下全量数据，并重新注册 watcher。

> ==Dubbo的服务暴露流程==
>
> 1.通过**ServiceConfig对象解析标签**，并创建dubbo的标签解析器对象来解析dubbo标签，随后通过**触发ContextRefreshEvent事件的回调方法开始暴露服务的动作**。
> 2.通过调用proxyFactory对象的getInvoker方法，并用javassist或DdkProxyFactory来进行动态代理，把**服务暴露接口封装成invoker对象**，在该对象里包含需要执行的方法名、参数和对应的URL地址。
> 3.通过**DubboProtocol的实现类，把包装后的invoker转换成exporter对象**。随后**启动服务器端的server来监听端口，等待服务调用的到来**。
> 4.通过**RegistryProtocol对象，保存URL地址和invoker之间的映射关系，同时把这层映射关系注册到服务中心**，比如Zookeeper里。

> ==Dubbo的服务引用的流程==
>
> 1.Dubbo客户端根据config文件里的信息从注册中心里订阅服务，并缓存到本地，后续的服务相关信息
> 的会动态更新到本地。
> 2.DubboProtocol根据provider的地址和接口连接到服务端server，开启客户端client，再创建
> invoker。
> 3.用invoker为服务接口生成代理对象，这个代理对象是用来远程调用。

> ==Dubbo SPI机制==
>
> SPI(Service Provider Interface)，是**一种服务发现机制**，其实就是**将结构的实现类写入配置当中，在服务加载的时候将配置文件读取，加载实现类，这样就可以在运行的时候，动态的帮助接口替换实现类。**
> Dubbo的SPI其实是对java的SPI进行了一种增强,可以**按需加载实现类之外**，增加了 IOC 和 AOP 的特性，还有自适应扩展机制。
>
> ==Java Spi==
> Java SPI 在查找扩展实现类的时候，遍历 SPI 的配置文件，并且将**实现类全部实例化**
> ==Dubbo Spi==
>
> 1、META-INF/dubbo 路径下.（配置接口的全限定名文件）
>
> 2、通过键值对的方式进行配置，接口的实现类，这样我们可以按需加载指定。
>
> 3、引入@SPI  @Adaptive @Activate 注解来扩展SPI应用场景
>
> 4、在生成Spi扩展实例的时候支持依赖注入
>
> （dubbo有一个AdaptiveExtensionFactory扩展点工程， 在内部持有了所有的factory 实现工厂，即后两个实现类。一个为SPI 工厂（依赖类是扩展接口时发挥作用，由于OrderServiceImpl中的infoService为扩展接口，所以会根据url适配infoService的实现类），一个为Spring 工厂（依赖的是springbean 时发挥作用）。于是，当我们需要为某个生成的对象注入依赖时，直接调用此对象即可。）
>
> ==@Acticate==
>
> 某种时候存在这样的情形，需要同时启用某个接口的多个实现类，如Filter 过滤器。我们希望某种条件下启用这一批实现，而另一种情况下启用那一批实现
>
> **Activate 注解表示一个扩展是否被激活(使用),可以放在类定义和方法上**，dubbo 用它在spi 扩展类定义上，**表示这个扩展实现激活条件和时机**。它有两个设置过滤条件的字段，group，value 都是字符数组。用来指定这个扩展类在什么条件下激活。
>
> ==@Adaptive==
>
> 扩展点对应的实现类不能在程序运行时动态指定，就是extensionLoader.getExtension 方法写死了扩展点对应的实现类.Adaptive注解，也就是dubbo 的自适应机制



> ==和SpringCloud比较==
>
> - 核心要素和开发成本：Spring Cloud 在开发过程中通过整合子项目可以顺利完成组件融合，而 Dubbo 需要通过实现各种 Filter 进行定制，开发成本和技术难度相对较高。
> - ==通信协议==：Dubbo ==默认使用单一长连接和 NIO 异步通讯，适合小数据量大并发的服务调用，支持多种通信协议==；Spring Cloud 使用 ==HTTP 协议的 REST API==，在通信速度上 Dubbo 略胜。
> - 服务依赖方式：Dubbo 服务依赖较重，需要版本管理机制，程序入侵较少；Spring Cloud 使用 JSON 进行交互，省略了版本管理问题，为跨平台调用提供基础。
> - 组件运行流程：Dubbo 的组件需要部署在单独服务器上，而 Spring Cloud 所有请求通过 API 网关（如 Zuul）访问内部服务，由注册中心（如 Eureka）和 Ribbon 进行服务发现和负载均衡。
> - ==初始定位和生态==：==Spring Cloud 定位为微服务架构下的一站式解决方案==，依托于 Spring 生态；Dubbo 起初==关注服务调用和治理==，生态相对不足但逐渐丰富。
> - ==微服务集群规模==：==Spring Cloud 更适用于小规模微服务集群，而 Dubbo 可以在超大规模集群中实现水平扩容，应对集群增长带来的问题==。
> - ==多语言支持：Dubbo 提供 Java 外的多语言实现，支持构建多语言异构的微服务体系；Spring Cloud 主要围绕 Java 生态。==

> ==dubbo协议的派发策略==
>
> 根据请求的消息类被IO线程处理还是被业务线程池处理，Dubbo提供了下面几种线程模型：
>
> 1. all：所有消息都派发到线程池，包括请求、响应、连接事件、断开事件、心跳等。
> 2. direct：所有消息都不派发到线程池，全部在IO线程上直接执行。
> 3. ==message==：只有请求响应消息派发到线程池，其它连接断开事件、心跳等消息，直接在IO线程上执行。
> 4. execution：只请求消息派发到线程池，不含响应，响应和其它连接断开事件，心跳等消息，直接在IO线程上执行。
> 5. connection：在IO线程上，将连接断开事件放入队列，有序逐个执行，其它消息派发到线程池。
>
> ==派发到线程池，线程池的策略==
>
> 1. fixed：固定大小线程池，启动时建立线程，不关闭，一直持有(缺省)。
> 2. cached：缓存线程池，空闲一分钟自动删除，需要时重建。
> 3. limited：可伸缩线程池，但池中的线程数只会增长不会收缩。只增长不收缩的目的是为了避免收缩时突然来了大流量引起的性能问题。

> ==服务降级==
>
> mock=force:return+null 表示消费方对该服务的方法调用都直接返回 null 值，不发起远 程调用。用来屏蔽不重要服务不可用时对调用方的影响。 还可以改为 mock=fail:return+null 表示消费方对该服务的方法调用在失败后，再返回 null 值，不抛异常。用来容忍不重要服务不稳定时对调用方的影响。

> ==dubbo设计模式==
>
> **工厂模式**
>
> Provider在export服务时，会调用ServiceConfig的export方法。ServiceConfig中有个字段
>
> ```java
> 	private static final Protocol protocol = 
> 		ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();
> ```
>
> Dubbo里有很多这种代码。这也是一种工厂模式，只是实现类的获取采用了JDK SPI的机制。这么实现的优点是可扩展性强，想要扩展实现，只需要在classpath下增加个文件就可以了，代码零侵入。另外，像上面的Adaptive实现，可以做到调用时动态决定调用哪个实现，但是由于这种实现采用了动态代理，会造成代码调试比较麻烦，需要分析出实际调用的实现类
> **装饰器模式**
>
> Dubbo在启动和调用阶段都大量使用了装饰器模式。以Provider提供的调用链为例，具体的调用链代码是在ProtocolFilterWrapper的buildInvokerChain完成的，具体是将注解中含有group=provider的Filter实现，按照order排序，最后的调用顺序是：EchoFilter -> ClassLoaderFilter -> GenericFilter -> ContextFilter ->ExecuteLimitFilter -> TraceFilter -> TimeoutFilter -> MonitorFilter ->ExceptionFilter。
>   更确切地说，这里是装饰器和责任链模式的混合使用。例如，EchoFilter的作用是判断是否是回声测试请求，是的话直接返回内容，这是一种责任链的体现。而像ClassLoaderFilter则只是在主功能上添加了功能，更改当前线程的ClassLoader，这是典型的装饰器模式。
>
> **观察者模式**
>
> Dubbo的Provider启动时，需要与注册中心交互，先注册自己的服务，再订阅自己的服务，订阅时，采用了观察者模式，开启一个listener。注册中心会每5秒定时检查是否有服务更新，如果有更新，向该服务的提供者发送一个notify消息，provider接受到notify消息后，即运行NotifyListener的notify方法，执行监听器方法
>
> **动态代理模式**
>
>  Dubbo扩展JDK SPI的类ExtensionLoader的Adaptive实现是典型的动态代理实现。Dubbo需要灵活地控制实现类，即在调用阶段动态地根据参数决定调用哪个实现类，所以采用先生成代理类的方法，能够做到灵活的调用。生成代理类的代码是ExtensionLoader的createAdaptiveExtensionClassCode 方法。代理类的主要逻辑是，获取URL参数中指定参数的值作为获取实现类的key

> **Spring2.x初始化死锁问题**
>
> 在Spring解析到dubbo:service时，就已经向外暴露了服务，而Spring还在接着初始化其他Bean。如果这时有请求进来，并且服务的实现类里有调用applicationContext.getBean()的用法。getBean线程和Spring初始化线程的锁的顺序不一样，导致了线程死锁，不能提供服务，启动不了。
>   解决：不要在服务的实现类中使用applicationContext.getBean();，如果不想依赖配置顺序，可以将dubbo:provider的deplay属性设置为-1，使dubbo在容器初始化完成后再暴露服务。

> ==AllDispatcher策略异常超时问题==
>
> 就是当配置了消息派发策略为AllDispatcher时，当服务端线程池满了之后，当消费端再次发送请求，就会一直傻傻等待超时导致没有任何服务端响应。那么问题就出现在AllChannelHandler，了AllDispatcher策略就是所有消息都派发到线程池，包括请求，响应，连接事件，断开事件，心跳等。即worker 线程接收到事件后，将该事件提交到业务线程池中，自己再去处理其他IO 事件。
>
> 问题出现原因：
>
> 那么当服务端线程池打满之后，此时又再次来了一个请求，此时依然会提交给线程池执行，那么了解线程池原理的就清楚线程池任务满了之后会执行拒绝策略抛出RejectedExecutionException异常，此时就会进入到received的catch方法中去，然后就又再次抛出ExecutionException异常。
>
> 那么抛出的异常就又会被netty捕获，进而继续执行nettyHandler的caught方法，可以看到这里又再次将任务丢到了线程池中。但是此时线程池依然是满的，业务线程池所有线程都堵住了，所以也不能将异常消息返回给客户端，然后客户端消费者只能傻傻等到超时。
>
> ```java
> public void received(Channel channel, Object message) throws RemotingException {
> 	ExecutorService executor = getPreferredExecutorService(message);
> 	try {
> 		executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
> 	} catch (Throwable t) {
> 
> 		throw new ExecutionException(message, channel, getClass() + " error when process received event .", t);
> 	}
> }
> public void caught(Channel channel, Throwable exception) throws RemotingException {
> 	ExecutorService executor = getSharedExecutorService();
> 	try {
> 		executor.execute(new ChannelEventRunnable(channel, handler, ChannelState.CAUGHT, exception));
> 	} catch (Throwable t) {
> 		throw new ExecutionException("caught event", channel, getClass() + " error when process caught event .", t);
> 	}
> }
> ```
>
> 解决
>
> 解决办法可以设置dispatcher为message，只有请求和响应交给业务线程池处理，其他的在IO线程处理
>
> <dubbo:protocol name="dubbo" dispatcher="message" />
>
> 后面dubbo也修复了这个问题，received方法的catch中新加了一部分逻辑，注释的大致意思也就是说：修复当线程池满了之后异常信息无法被发送给消费端的问题（当线程池满了，拒绝执行任务，会引起消费端等待超时），所以代码中判断了下当抛出异常为RejectedExecutionException时，就不把异常抛出交给AllChannelHandler#caught方法中的线程池执行，而是直接用IO线程在通过channel将消息及时反馈给消费者，消费者也就会收到服务端的“threadpool is exhausted ,detail msg”等响应消息。
>
> ```java
> public void received(Channel channel, Object message) throws RemotingException {
> 	ExecutorService cexecutor = getExecutorService();
> 	try {
> 		cexecutor.execute(new ChannelEventRunnable(channel, handler, ChannelState.RECEIVED, message));
> 	} catch (Throwable t) {
> 		//TODO A temporary solution to the problem that the exception information can not be sent to the opposite end after the thread pool is full. 
> 		//fix The thread pool is full, refuses to call, does not return, and causes the consumer to wait for time out
> 		if(message instanceof Request && t instanceof RejectedExecutionException){
> 			Request request = (Request)message;
> 			if(request.isTwoWay()){
> 				String msg = "Server side(" + url.getIp() + "," + url.getPort() + ") threadpool is exhausted ,detail msg:" + t.getMessage();
> 				Response response = new Response(request.getId(), request.getVersion());
> 				response.setStatus(Response.SERVER_THREADPOOL_EXHAUSTED_ERROR);
> 				response.setErrorMessage(msg);
> 				channel.send(response);
> 				return;
> 			}
> 		}
> 		throw new ExecutionException(message, channel, getClass() + " error when process received event .", t);
> 	}
> }
> ```
>
> 

## tomcat篇

> ==tomcat监控==
>
> tomcat 的关键指标有吞吐量、响应时间、错误数、线程池、CPU 以及 JVM 内存
>
> Tomcat 可以通过 JMX 将上述指标暴露出来的,然后通过JConsole 监控 Tomcat
>
> **命令行查看指标**
>
> 1. ps -ef|grep tomcat
> 2. 查看进程状态的大致信 cat/proc/<pid>/status
> 3. 查看监控进程的 CPU 和内存资源使用情况 top -p 30943
> 4. 查看 Tomcat 的网络连接，比如 Tomcat 在 8080 端口上监听连接请求  netstat -na |grep 8080  还可以分别统计处在“已连接”状态和“TIME_WAIT”状态的连接数  netstat -na |grep ESTAB| grep 8080 |wc -l 12   netstat -na |grep TIME_WAIT| grep 8080 |wc -l 43
> 5. 通过 ifstat 来查看网络流量  ifstat

> ==tomcat IO调优==
>
> 所谓的 I/O 调优指的是选择 NIO、NIO.2 还是 APR
>
> - 默认都是 NIO  Linux 平台上，建议使用 NIO   Linux 内核没有很完善地支持异步 I/O 模型，因此 JVM 并没有采用原生的 Linux 异步 I/O，而是在应用层面通过epoll 模拟了异步 I/O 模型
> - Web 应用用到了 TLS 加密传输，而且对性能要求极高 考虑 APR APR 通过 OpenSSL 来处理 TLS 握手和加 / 解密。OpenSSL 本身用 C 语言实现，它还对 TLS 通信做了优化，所以性能比 Java 要高。
> - Tomcat 跑在 Windows平台上，并且 HTTP 请求的数据量比较大，可以考虑 NIO.2  Windows 从操作系统层面实现了真正意义上的异步 I/O
>
> ==tomcat线程池优化==
>
> 核心的就是如何确定 maxThreads 的值
>
> 小了，Tomcat 会发生线程饥饿，并且请求的处理会在队列中排队等待，导致响应时间变长
>
> 过大，服务器的 CPU 的核数有限，线程数太多会导致线程在 CPU 上来回切换，耗费大量的切换开销
>
> **依照公式**，一般来说，如果系统的 TPS 要求足够大，用第一个公式算出来的线程数往往会比公式二算出来的要大。我建议选取这两个值中间更靠近公式二的值。也就是先设置一个较小的线程数，然后进行压测
>
> 线程池大小 = 每秒请求数 × 平均请求处理时间
>
> 线程池大小 = （线程 I/O 阻塞时间 + 线程 CPU 时间 ）/ 线程 CPU 时间

> ==Tomcat内存溢出的原因分析及调优==
>
> **java.lang.OutOfMemoryError: Java heap space**
>
> - 内存泄漏  比如对象池和内存池中的对象无法被 GC 回收
>
> - 配置问题 通过 JVM 参数加大堆的大小
>
> - finalize 方法的过度使用
>
>   如果我们想在 Java 类实例被 GC 之前执行一些逻辑，比如清理对象持有的资源，可以在 Java 类中定义 finalize 方法，这样 JVM GC 不会立即回收这些对象实例，而是将对象实例添加到一个叫“java.lang.ref.Finalizer.ReferenceQueue”的队列中，执行对象的 finalize 方法，之后才会回收这些对象。Finalizer 线程会和主线程竞争 CPU 资源，但由于优先级低，所以处理速度跟不上主线程创建对象的速度，因此ReferenceQueue 队列中的对象就越来越多，最终会抛出 OutOfMemoryError。解决办法是尽量不要给 Java 类定义 finalize 方法。
>
> **java.lang.OutOfMemoryError: GC overhead limit exceeded**
>
> 垃圾收集器一直在运行，但是 GC 效率很低，比如 Java 进程花费超过 98％的 CPU 时间来进行一次 GC，但是回收的内存少于 2％的 JVM堆，并且连续 5 次 GC 都是这种情况，就会抛出 OutOfMemoryError
>
> 查看 GC 日志或者生成 Heap Dump，确认一下是不是内存泄漏，如果不是内存泄漏可以考虑增加 Java 堆的大小。当然你还可以通过参数配置来告诉 JVM 无论如何也不要抛出这个异常，方法是配置-XX:-UseGCOverheadLimit（不推荐）
>
> **java.lang.OutOfMemoryError: Requested array size exceeds VM limit**
>
> “请求的数组大小超过 JVM 限制 
>
> 配置问题（JVM 堆太小）
>
> **java.lang.OutOfMemoryError: MetaSpace**
>
> JVM 的元空间用尽，则会抛出这个异常
>
> 加大 MaxMetaSpaceSize 参数的值。
>
> **java.lang.OutOfMemoryError: Request size bytes for reason. Out of swap space**
>
> 当本地堆内存分配失败或者本地内存快要耗尽时，Java HotSpot VM 代码会抛出这个异常，VM 会触发“致命错误处理机制”，它会生成“致命错误”日志文件，其中包含崩溃时线程、进程和操作系统的有用信息。
>
> 据
> JVM 抛出的错误信息来进行诊断；或者使用操作系统提供的 DTrace 工具来跟踪系统调用，看看是什么样的程序代码在不断地分配本地内存。
>
> **java.lang.OutOfMemoryError: Unable to create native threads**
>
> 操作系统创建新的线程可能会失败
>
> - 内存大小限制 栈空间如果过小，可能会导致 StackOverflowError
> - ulimit 限制，在 Linux 下执行ulimit -a，你会看到 ulimit 对各种资源的限制  max user processes”就是一个进程能创建的最大线程数
> - 参数sys.kernel.threads-max限制 这个参数限制操作系统全局的线程数  在/etc/sysctl.conf配置文件中，加入sys.kernel.threads-max = 999999。
> - 参数sys.kernel.pid_max限制，这个参数表示系统全局的 PID 号数值的限制，每一个线程都有 ID，ID 的值超过这个数，线程就会创建失败 方法是在/etc/sysctl.conf配置
>   文件中，加入sys.kernel.pid_max = 999999

> ==Tomcat拒绝连接原因分析及网络优化==
>
> **java.net.SocketTimeoutException**
>
> 超时错误。超时分为连接超时和读取超时  连接超时往往是由于网络不稳定造成的，但是读取超时不一定是网络延迟造成的，很有可能是下游服务的响应时间过长
>
> **java.net.BindException: Address already in use: JVM_Bind**
>
> 端口被占用  netstat –an命令来查看端口
>
> **java.net.ConnectException: Connection refused: connect**
>
> 连接被拒绝 原因是指定 IP 地址的机器没有找到；或者是机器存在，但这个机器上没有开启指定的监听端口
>
> 从客户端机器 ping 一下服务端 IP，假如 ping 不通，可以看看 IP 是不是写错了；假如能 ping 通，需要确认服务端的服务是不是崩溃了
>
> **java.net.SocketException: Socket is closed**
>
> 通信的一方主动关闭了 Socket 连接（调用了Socket 的 close 方法），接着又对 Socket 连接进行了读写操作，这时操作系统会报“Socket 连接已关闭”的错误。
>
> **java.net.SocketException: Connection reset/Connect reset by peer: Socket write error**
>
> 连接被重置。这里有两种情况，分别对应两种错误：
>
> 第一种情况是通信的一方已经将Socket 关闭，可能是主动关闭或者是因为异常退出，这时如果通信的另一方还在写数据，就会触发这个异常（Connect reset by peer）；
>
> 如果对方还在尝试从 TCP 连接中读数据，则会抛出 Connection reset 异常
>
> 程序退出前要主动关闭所有的网络连接。
> 检测通信的另一方的关闭连接操作，当发现另一方关闭连接后自己也要关闭该连接。
>
> **java.net.SocketException: Broken pipe**
>
> 通信管道已坏。发生这个异常的场景是，通信的一方在收到“Connect reset by peer:Socket write error”后，如果再继续写数据则会抛出 Broken pipe 异常，解决方法同上
>
> **java.net.SocketException: Too many open files**
>
> 进程打开文件句柄数超过限制 并发用户数比较大时，服务器可能会报这个异常
>
> lsof -p pid命令查看进程打开了哪些文件，是不是有资源泄露，也就是说进程打开的这些文件本应该被关闭，但由于程序的 Bug 而没有被关闭
>
> 如果没有资源泄露，可以通过设置增加最大文件句柄数。具体方法是通过ulimit -a来查看系统目前资源限制，通过ulimit -n 10240修改最大文件数。
>
> //
>
> **Tomcat 的最大并发连接数等于maxConnections + acceptCount**。如果acceptCount 设置得过大，请求等待时间会比较长；如果 acceptCount 设置过小，高并发情况下，客户端会立即触发 Connection reset 异常
>
> acceptCount 用来控制内核的 TCP 连接队列长度，maxConnections用于控制 Tomcat 层面的最大连接数

> ==Tomcat进程占用CPU过高怎么办？==
>
> 1. top 命令 查看Java 进程的 CPU 使用率
> 2. top -H -p 4361 查看这个 Java 进程中各线程使用 CPU 的情况
> 3. jstack 命令生成线程快照  jstack 4361  或jstack 4361 > 4361.log  
> 4. 打开 定位 ，或者线程ID转换为16进制  进行查找  看看线程的状态 Block or Waiting 之类
> 5. vmstat 1 100 查看操作系统层面的线程上下文切换活动  cs 那一栏表示线程上下文切换次数，in 表示 CPU 中断次数，我们发现这两个数字非常高，基本证实了我们的猜测，线程上下文切切换消耗了大量 CPU。

> ==tomcat&jetty==
>
> jetty 在吞吐量和响应速度方面稍有优势，并且 Jetty 消耗的线程和内存资源明显比Tomcat 要少，这也恰好说明了 **Jetty 在设计上更加小巧和轻量级的特点**。
> 但是 Jetty 有 2.45% 的错误率，而 Tomcat 没有任何错误，并且我经过多次测试都是这个结果。因此我们可以认为 **Tomcat 比 Jetty 更加成熟和稳定**

## mybatis篇

> ==#{}和${}的区别是什么==
>
> 1）#{}是预编译处理，${}是字符串替换。 
> 2）Mybatis 在处理#{}时，会将 sql 中的#{}替换为?号，调用 PreparedStatement 的 set 方法来赋值； 
> 3）Mybatis 在处理${}时，就是把${}替换成变量的值。 
> 4）使用#{}可以有效的防止 SQL 注入，提高系统安全性

> ==一级、二级缓存==
>
> 1）一级缓存: 基于 PerpetualCache   的 HashMap 本地缓存，其存储作用域为 Session，当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将 清空。 
> 2）二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存 储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如Ehcache。要开启二级缓存，你需要在你的 SQL 映射文件中添加一行： 
> 3 ） 对 于 缓 存 数 据 更 新 机 制 ， 当 某 一 个 作 用 域 ( 一 级 缓 存 Session/ 二 级 缓 存 Namespaces)的进行了 C/U/D 操作后，默认该作用域下所有 select 中的缓存将 被 clear。

> ==Mybatis 是否支持延迟加载？如果支持，它的实现原理是什么==
>
> Mybatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载
>
> ’association 指的就是一对一，collection 指的就是一对多查询。
>
> Mybatis 配置文 件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。 
>
> 它的原理是，使用 **CGLIB 创建目标对象的代理对象**，当调用目标方法时，进入拦截 器方法，比如调用 a.getB().getName()，拦截器 invoke()方法发现 a.getB()是 null 值，
> 那么就会**单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上**来，然后调 用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName()方法的 调用。

> ==Mybatis 都有哪些 Executor 执行器？==
> SimpleExecutor、ReuseExecutor、 BatchExecutor。
> 1）SimpleExecutor：每执行一次 update 或 select，就开启一个 Statement 对 象，用完立刻关闭 Statement 对象。
>
> 2）ReuseExecutor：执行 update 或 select，以 sql 作为  key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象， 而是放置于 Map
> 3）BatchExecutor：完成批处理

> ==工作原理==
>
> mybatis应用程序通过**SqlSessionFactoryBuilder从mybatis-config.xml配置文件**（也可以用Java文件配置的方式，需要添加@Configuration）来构建SqlSessionFactory（SqlSessionFactory是线程安全的）；
>
> 然后，**SqlSessionFactory的实例直接开启一个SqlSession，再通过SqlSession实例获得Mapper对象并运行Mapper映射的SQL语句，完成对数据库的CRUD和事务提交，之后关闭SqlSession。**
> ==详细流程==
>
> 1、加载mybatis全局配置文件（数据源、mapper映射文件等），解析配置文件，MyBatis基于XML配置文件生成Configuration，和一个个MappedStatement（包括了参数映射配置、动态SQL语句、结果映射配置），其对应着<select | update | delete | insert>标签项。
>
> 2、SqlSessionFactoryBuilder通过Configuration对象生成SqlSessionFactory，用来开启SqlSession。
>
> 3、SqlSession对象完成和数据库的交互：
> a、用户程序调用mybatis接口层api（即Mapper接口中的方法）
> b、SqlSession通过调用api的Statement ID找到对应的MappedStatement对象
> c、通过Executor（负责动态SQL的生成和查询缓存的维护）将MappedStatement对象进行解析，sql参数转化、动态sql拼接，生成jdbc Statement对象
> d、JDBC执行sql。
>
> e、借助MappedStatement中的结果映射关系，将返回结果转化成HashMap、JavaBean等存储结构并返回。



## 分布式篇

### cap&base

> ==CAP==
> Consistency(一致性):用户访问分布式系统中的任意节点，得到的数据必须一致。
>
> Availability (可用性):用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝
>
> Partition(分区):因为网络故障或其它原因导致分布式系统中的部分节点与其它节点失去连接，形成独立分区。
> ==BASE==
> Basically Available (基本可用): 分布式系统在出现故障时，允许损失部分可用性，即保证核心可用.
>
> Soft state (软状态)在一定时间内，允许出现中间状态，比如临时的不一致状态。
>
> Eventually Consistent (最终一致性): 虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致

### 分布式事务

> TX协议: 应用或者应用服务器与事务管理器的接口
> XA协议: 全局事务管理器与资源管理器的接口。
> AP: 应用程序，可以理解为使用DTP (Data Tools PLatform) 的程序。
> RM: 资源管理器，这里可以是一个DBMS或者消息服务器管理系统
> TM:事务管理器，负责协调和管理事务，提供给AP编程接口以及管理资源管理器。事务管理器控制着全局事务，管理事务的生命周期，并且协调资源。

> 分布式锁解决的是分布式资源抢占的问题;分布式事务和本地事务是解决流程化提交问题。

> 幻读:在同一事务中，相同条件下，两次查询出来的 记录数 不一样
> 不可重复读:在同一事务中，相同条件下，两次查询出来的 数据 不一样;

> ==事务隔离级别==
>
> 未提交读(READ UNCOMMITTED) : 所有事务都可以看到其他事务未提交的修改。一般很少使用:
> 提交读(READ COMMITTED) : oracle默认隔离级别，事务之间只能看到彼此已提交的变更修改
> 可重复读(REPEATABLE READ): MySOL默认隔离级别，同一事务中的多次查询会看到相同的数据行: 可以解决不可重复读，但可能出现幻读;
> 可串行化(SERIALIZABLE) : 最高的隔离级别，事务串行的执行，前一个事务执行完，后面的事务会执行。读取每条数据都会加锁，会导致大量的超时和锁争用问题;

> ==分布式事务复杂性体现==
> 存储端的多样性
> 事务链路的延展性

> ==定义==
>
> 分布式事务指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上
> 在分布式系统上，一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务节点上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败
>
> ==场景==
>
> 1、跨库事务 service 操作两个库
> 2、分库分表 批量插入 路由至不同的库
> 3、微服务化 服务间调用

> ==CAP解读==
>
> c
>
> 操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，不能存在中间状态。
> 满足上述操作后，客户端看到的数据都是一致的 一 强一致性
> 经过一段时间后，数据最终是一致  一 最终一致性
> 允许存在部分数据不一致 一 弱一致性。
>
> A 
>
> 系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内(合理的RT)返回结果(用户认知的结果)。
>
> P 
>
> 分布式系统在遇到任何网络分区故障时，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障
>
> P不能舍弃，舍弃的话，分区故障时，直接不能对外提供 CA服务， 分区也就不存在意义，也就是扩展不存在意义，无法谈说分布式理念。 (也不是绝对的，银行钱财，C 必须保证。网络发生故障宁可停止服务，这是保证CA，舍弃 P)
> 还有一种是保证 CP，舍弃 A。例如网络故障是只读不写互联网应用的场景 保证 P 和 A，舍弃C (退而求其次保证最终一致性)。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。
>
> CA不能同时满足
> 如果保证了一致性(C):对于节点N1和N2，当往N1里写数据时，N2上的操作必须被暂停，只有当N1同步数据至N2时才能对N2进行读写请求，在N2被暂停操作期间客户端提交的请求会收到失败或超时。显然，这与可用性是相悖的。 (就是必须同步完成保证一致性，那其他节点不可用)
> 如果保证了可用性(A):那就不能暂停N2的读写操作，但同时N1在写数据的话，这就违背了一致性的要求(节点都可用的话，数据可能未同步完成)

> ACID里的一致性指的是事务执行前后，数据库完整性，而CAP的一致性，指的是分布式节点的数据的一致性

> BA Basically Available 基本可用是指分布式系统在出现不可预知的故障的时候，允许损失部分可用性(RT增加 或者 降级)，但不等于系统不可用
>
> Soft state 允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。
>
> Eventually consistent (最终一致性)  强调系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态

> **刚性事务**:通常无业务改造，强一致性，原生支持回滚/隔离性，低并发，适合短事务,要使分布式事务，达到像本地式事务一样，具备数据强一致性，从CAP来看，就是说，要达到CP状态
>
> **柔性事务**的特点为:有业务改造，最终一致性，实现补偿接口，实现资源锁定接口，高并发，适合长事务
> 柔性事务分为:
> 补偿型
>
> 异步确保型
> 最大努力通知型。
> 柔型事务: TCC/FMT、Saga (状态机模式、Aop模式) 、本地事务消息、消息事务(半消息)
> 补偿型事务都是同步的，通知型事务都是异步的。

> **XA 协议的实现** 包括 2PC  JTA  JTS
> 3pc是对2pc的扩展
> 。必须要拿到所有数据源，而且数据源还要支持XA协议。目前MySQL中只有InnoDB存储引擎支持XA协议。
> 。性能比较差，要把所有涉及到的数据都要锁定，是强一致性的，会产生长事务

> **java平台上事务规范 JTA (Java Transaction API)**
> JTA是基于XA架构上建模的，在JTA 中，事务管理器抽象为javax.transaction.TransactionManager接口，并通过底层事务服务《即JTS) 实现
> JTA仅仅定义了接口，具体的实现则是由供应商(如J2EE厂商)负责提供，目前JTA的实现主要由以下几种:
>
> 1.J2EE容器所提供的JTA实现(JBoss)
>
> 2.独立的JTA实现:如JOTM，Atomikos
>
> JTA定义了一套接口，其中约定了几种主要的角色: TransactionManager、UserTransactionTransaction、XAResource，并定义了这些角色之间需要遵守的规范，如Transaction的委托给TransactionManager等。
> JTS也是一组规范，上面提到JTA中需要角色之间的交互，那应该如何交互? JTS就是约定了交互细节的规范,**JTA更多的是从框架的角度来约定程序角色的接口，而JTS则是从具体实现的角度来约定程序角色之间的接口**

> **2pc实现**
>
> seata、 atomikos、 Lcn
>
> 两阶段提交在处理分布式事务时分为两个阶段:
>
> voting (投票阶段，有的地方会叫做prepare阶段)和commit阶段
>
> 2pc中存在两个角色，事务协调者 (seata  atomikos、Lcn)和事务参与者，事务参与者通常是指应用的数据库
>
> - 2PC方案比较适合单体应用
> - 最大缺点就在于它的执行过程中间，节点都处于阻塞状态，各个操作数据库的节点此时都占用着数据库资源.性能问题
> - 协调者单点故障问题 一旦事务协调者节点挂掉，会导致参与者收不到提交或回滚的通知，从而导致参与者节点始终处于事务无法完成的中间状态,
> - 丢失消息导致的数据不一致问题 发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就会导致节点间数据的不一致问题

> **3pc**
>
> 三阶段提交协议**在协调者和参与者中都引入 超时机制**，2PC只有协调者才拥有超时机制
> 并且把两阶段提交协议的第一个阶段拆分成了两步: 询问，然后再锁资源，最后真正提交。三阶段提交的三个阶段分别为: can_commit，pre_commit，do_commit。，相较于2PC而言，多设置了一个缓冲阶段保证了在最后提交阶段之前各参与节点的状态是一致的。

### 分布式ID

> 雪花花法
>
> - 1bit 符号位
> - 41bit 时间戳位
> - 10bit 工作进程位以及
> - 12bit 序列号位。
>
> 在同一个进程中，它首先是通过时间位保证不重复，如果时间相同则是通过序列位保证。同时由于时间位是单调逆增的，且各个服务器如果大体做了时间同步，那么生成的主键在分布式环境可以认为是总体有序的，这就保证了对索引字段的播入的高效性。
>
> ==服务器时钟回拨==
>
> 会导致产生重复序列，因此默认分布式主键生成器提供了一个最大容忍的时钟回拨毫秒数。
>
> 如果时钟回拨的时间超过最大容忍的毫秒数阀值，则程序报错;
>
> 如果在可容忍的范围内，默认分布式主键生成器会等待时钟同步到最后一次主键生成的时间后再继续工作。
> 最大容忍的时钟回拨毫秒数的默认值为0 ，可通过属性设置
> ==涉及场景==
>
> 实例停机，时钟回拨>实例重启>计算ID
> 实例运行中，时钟回拨，计算ID
> 造成时钟回拨的原因多种多样，可能是闰秒回拨，可能是NTP同步，还可能是服务器时间手动调整。总之就是时间回到了过去
> ==方案:==
> 1.少量服务器部署ID生成器实例，关闭NTP服务器，严格管理服务器。这种方案不需要从代码层面解决，完全人为管理
> 2.针对回退时间断的情况，如闰秒回拨仅回拨了1s，可以在代码层面通过判断暂停一定时间内的ID生成器使用，虽然少了几秒钟可用时间，但时钟正常后，业务即可恢复正常
> 3.实例启动后，改用内存生成时间。该方案为baidu开源的UidGeneratar使用的方案，由于实例启动后，时间不再从服务器获取，所以不管服务器时钟如何回拔，都影响不了SnowFLake的执行
>
> 4.实例停机)时钟回拨>实例重启计算ID 的情况，可以通过实例启动的时候，采用未使用过的workerId (采分布式存储，存储下来，比如redis zookeeper)

### 分布式缓存

> ==如何保证MySQL 和 Redis 的数据-致性?==
>
> **Cache-Aside Pattern (旁路缓存模式):** 旁路路由策略，在这种模式中，缓存和数据库的操作都是在应用程序中完成。
>
> 此模式是业务系统最常用的缓存策略。
>
> 读缓存:  先读缓存，缓存命中的话，直接返回数据;如果缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应
>
> 写缓存: step 1: 接收用户的数据写入的请求; step 2: 先写入数据库; step 3: 再写入缓存

> ==数据什么时候从数撼库(Mysql集群) 加 到存(如Redis群) 呢?==
> 懒汉模式:使用时临时加载缓存，当需要使用数据时，就从数据库中把它查询出来，然后写入缓存
>
> 饿汉模式，就是提前预加载缓存。在项目启动的时候，预加载数据到缓存

> ==Cache-Aside如何保证双写的数据一致性?==
>
> 策略一:先更数据库，再更缓存
>
> 策略二: 先删缓存，再更新数据库
>
> 策略三: 先更数据库，再删缓存。 
>
> 策略四: 延迟双删策略
>
> 策略五: 逻辑删除策略。 
>
> 策略六:先更数据库，再基于队列删缓存
> 并发场景下，微服务Provider实例A、 B同时进行同一个数据的更新操作，也就是两个线程同时操作。
>
> ==为何不更新缓存而是删除缓存?==
> 除了能够减少脏数据之外，更新缓存相对于删除缓存，还有两点劣势:
> (1)如果写入Cache的值，**是经过复杂计算才得到的话。更新缓存频率高的话，就会大大降低性能**
>
> (2)**及时更新缓存属于饿汉模式，适用于数据读取高频的场景。**在**写多读少的**情况下，数据很多时候还没被读取到，又被更新了，这也**浪费了Cache的空间，也降低了性能**
>
> 策略-: A update db => B update db => B update cache => A update cache  出现脏数据 3 4步骤操作存属于高并发很难保证先后
> 策略二: A delete cache => B select null,load db,update cache =>A update db  db 和数据不一致 ，中间环节刷入的cache过期时间较长的话，脏数据存活时间过长
>
> 策略三: A update db => B load cache => A delete cache  中间短暂不一致 以及 如果了 步出现卡顿或者失败 会出现cache长期不一致
> 策略四: 延迟双删是基于策略二进行改进，就是先删Cache，后写DB，最后延迟一定时间，再次删Cache A delete cache =>B select null,load db,update cache => A update db =》 A delay deletecache 写操作比较频繁，可能会对Redis造成一定的压力,极端情况下，第二次延迟删Cache失败，操作的效果遇化到策略二。DB和Cache存在较长时间的数据不一致，这个时间会一直持续到Cache过期
> 策略五:查询的时候，检查 逻辑过期时间 LogicExpireTme ，如果发现到时间了，另外有一个缓存的重建线程，异步重建。
> 策略六: 针对策略三的改进
> 第1种细分的方案:基于内存队列删除缓存  支持重试、db和cache操作职责解 / 队列任务多，效率低，可以引入多线程，jvm崩溃，队列数据丢失
> 第2种细分的方案: 基于消息队列删除缓存比1种 更可靠，避免丢失 rocketmg 同步发送
>
> 第3种细分的方案: 基于binlog+消息队列删除缓存 完全解耦  canal 采数据写Mysql时生成binlog日志，然后将日志发送到RocketMq队列。在消费端，可以编写一个专门的消费者(Cache DeletenConsumer)完成缓存binlog日志订阅，筛选出其中的更新类型Log，解析之后进行对cache的删除操作并且通过RocketMq队列ACK机制确认处理这条更新Log，保证Cache除能够得到最终的删除

## redis篇

### 项目中redis key值设置？

项目名+环境名+功能名+业务值

### 项目中使用redis的场景？

- 用户的资源权限集合会存储redis，然后访问接口会进行一些认证。Set存储，元素不可重复，查找快。
- 常用的字典值或者公式存储，方便高频业务使用时缓解数据库压力。string存储
- 比如异步下载，使用redis存储临时变量，前端轮询接口获取变量确认是否完成
- 使用redis的发布订阅模式，提供了业务参数管理的功能，可以针对一些配置修改直接生效。更新后，缓存存储，同时更新spring的@value值

### 你们项目中使用redis哪种方式？展开说说

cluster集群模式

海量数据存储问题
高并发写的问题

> - 集群中有多个master，每个master保存不同数据
> - 每个master都可以有多个slave节点
> - master之间通过ping监测彼此健康状态
> - 客户端请求可以访问集群任意节点，最终都会被转发到正确节点

`数据存储通过插槽方式`

1. Redis会把每 个master节点映射到0~16383共16384个插槽(hash slot)上
2. 数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况:
3. key中包含”(》”，且”(》”中至少包含1个字符，“小"中的部分是有效部分
4. key中不包含”}”，整个ey都是有效部分
5. 计算方式是利用CRC16算法得到一个hash值，然后对16384取余
6. 得到的结果就是slot

### 主从模式和哨兵模式展开说说？

> ==主从模式==
>
> 1. 一个Master可以有多个Slaves
> 2. 默认配置下，master节点可以进行读和写，slave节点只能进行读操作，写操作被禁止
>
> **特性**
>
> 1、支持断点续传：master node会在内存中常见一个backlog，master和slave都会保存一个replica offset还有一个master id，在backlog中的。如果master和slave网络连接断掉了，slave会让master从上次的replica offset开始继续复制。但是如果没有找到对应的offset，那么就会执行一次resynchronization**(****==依据repl_backlog中的offset实现==**）**
>
> 2、无磁盘化复制：master在内存中直接创建rdb，然后发送给slave，不会在自己本地落地磁盘了**
>
> repl-diskless-sync：无磁盘化同步
> repl-diskless-sync-delay，等待一定时长再开始复制，因为要等更多slave重新连接过来
>
> 3、过期key处理：slave不会过期key，只会等待master过期key。如果master过期了一个key，或者通过LRU淘汰了一个key，那么会模拟一条del命令发送给slave。`
>
> **优点**
>
> - 主从模式的一个作用是**备份数据**，这样当一个节点损坏（指不可恢复的硬件损坏）时，数据因为有备份，可以方便恢复。
> - 另一个作用是**负载均衡**(**也就是独写分离**)，所有客户端都访问一个节点肯定会影响Redis工作效率，有了主从以后，查询操作就可以通过查询从节点来完成。
>
> **缺点**
>
> - **master节点挂了以后，redis就不能对外提供写服务了，因为剩下的slave不能成为master**
>
> **同步数据过程**
>
> `全量同步`
>
> 1：当一个从节点启动时，会向主数据库发送sync命令，
>
> 2：主数据库接收到sync命令后会开始在后台保存快照（执行rdb操作），并将保存期间接收到的命令缓存起来记录在repl_backlog中
>
> 3：当快照完成后，redis会将快照文件发送到slave，slave保存到磁盘上，然后加载到内存中
>
> 4、master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave。
>
> 5、slave执行接收到的命令，保持与master之间的同步。
>
> // 同步时间点：
>
> slave节点第-次连接master节点时
> slave节点断开时间太久，repl_baklog中的offset已经被覆盖时
>
> `增量同步`
>
> 通过repl_baklog实现，它是环状的数组，中会记录Redis处理过的命令日志及offset，包括master当前的offset，和slave已经拷贝到的offset：
>
> 1、slave提交自己的offset到master
>
> 2、master获取==repl_baklog中从offset之后的命令给slave==，如果断开时间过久，则导致slave的offset被覆盖，需要进行全量同步。
>
> // 同步时间点：
>
> slave节点断开又恢复，并且在repl_baklog中能找到offset时

> ==哨兵模式sentinel==
>
> 运行在特殊模式下的 Redis 服务器,用来
>
> **监控**：哨兵(sentinel) 会不断地检查你的Master和Slave是否运作正常。
>
> **通知**：当被监控的某个 Redis出现问题时, 哨兵(sentinel) 可以通过 API 向管理员或者其他应用程序发送通知
>
> **自动故障转移：**当一个Master不能正常工作时，哨兵(sentinel) 会开始一次自动故障迁移操作,它会将失效Master的其中一个Slave升级为新的Master, 并让失效Master的其他Slave改为复制新的Master; 当客户端试图连接失效的Master时,集群也会向客户端返回新Master的地址,使得集群可以使用Master代替失效Master。
>
> `切换(自动故障转移)`
>
> 1、sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master
>
> 2、sentinel给所有其它slave发送slaveof 192,168.150.101 7802 命令，让这些slave成为新master的从节点,、
>
> 3、开始从新的master上同步数据，最后，sentinel将故障节点标记为slave，动成为新的master的slave节点
>
> ###### `选举(故障恢复原理),针对上面的该节点为何成为master`
>
> 1、首先会判断**slave节点与master节点断开时间长短**，如果超过指定值down-after-milliseconds * 10)则会排除该slave节点、
>
> 2、然后判断**slave节点的slave-priority值，越小优先级越高**，如果是0则永不参与选举、
>
> 3、如果slave-prority一样，则判断**slave节点的offset值，越大说明数据越新**，优先级越高
>
> 4、最后是判断**slave节点的运行id大小，越小优先级越高**
>
> `监控`
>
> Sentinel如何判断个redis实例是否健康?
> 每隔1秒发送一次ping命令，如果超过一定时间没有相向则认为是主观下线
> 如果大多数sentine1都认为实例主观下线，则判定服务下线

### 持久化的方式?

> ==RDB==
>
> **RDB：快照。**默认开启。是在某个时间点将数据写入一个临时文件，持久化结束后，用这个临时文件替换上次持久化的文件，达到数据恢复.
>
> 优点：单独子线程来持久化，保证了高性能.
>
> 使用：通过配置**redis 在 n 秒内如果超过 m 个 key 被修改**这执行一次 RDB 操作。
>
> 缺点：宕机的话，从最近一次rdb保存到宕机时的数据都会丢失
>
> ==AOF==
>
> append-only file：默认关闭。将“操作 + 数据”以格式化指令的方式追加到操作日志文件的尾部，“日志文件”保存了历史所有的操作过程；当 server 需要数据恢复时，可以直接 **replay 此日志文件，即可还原所有的操作过程。**
>
> 优点：保证了数据安全，
>
> 缺点：但是文件会过大。恢复时间慢
>
> 使用：BGREWRITE: 在 后台（子进程）重写AOF, 不会阻塞工作线程，能正常服务，此方法最常用。
>
> `配置选项`
>
> **always**：每一条 aof 记录都**立即同步到文件**，这是最安全的方式，也以为更多的磁盘操作和阻塞延迟，是 IO 开支较大。
>
> **everysec：每秒同步一次**，性能和安全都比较中庸的方式，也是 redis 推荐的方式。如果遇到物理服务器故障，有可能导致最近一秒内 aof 记录丢失(可能为部分丢失)。
>
> no：redis 并不直接调用文件同步，而是交**给操作系统来处理**，操作系统可以根据 buffer 填充情况 / 通道空闲时间等择机触发同步；这是一种普通的文件操作方式。性能较好，在物理服务器故障时，数据丢失量会因 OS 配置有关



> ==主从模式==
>
> 全量同步:master将完整内存数据生成RDB，发送RDB到sLave。后续命令则记录在repl_baklog，逐个发送给slave。
>
> 增量同步: sLave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave
>
> ==同步时间点==
>
> **全量同步** 
>
> slave节点第一次连接master节点时
>
> slave节点断开时间太久，repl_baklog中的offset已经被覆盖
>
> **增量同步**
>
> slave节点断开又恢复，并且在repl_baklog中能找到offset时

> ==哨兵模式==
>
> **选举新的master依据**
> 1、首先会判断slave节点(与master节点断开时间长短，如果超过指定值 (down-after-mitliseconds *10)则会排除该slave节点
> 2、判断slave节点的(sLave-priority值，越小优先级越高)，如果是0则永不参与选举。
>
> 3、如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高
>
> 4、判断slave节点的运行id大小，越小优先级越高。
> **选完master后切换**
> 1、sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master
>
> 2、sentinel给所有其它sLave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据
>
> 3、最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点
>
> **Sentinel的三个作用是什么?**
>
> 监控
>
> 故障转移
>
> 通知
>
> **Sentinel如何判断一个redis实例是否健康?**
>
> 每隔1秒发送一次ping命令，如果超过一定时间没有响应则认为是主观下线，如果大多数sentinel都认为实例主观下线，则判定服务下线

> ==cluster模式==
>
> **解决**
>
> 海量数据存储问题
>
> 高并发写的问题
>
> **存储**
>
> 集群中有多个master，每个master保存不同数据
>
> 每个master都可以有多个slave节点
>
> master之间通过ping监测彼此健康状态
>
> 客户端请求可以访问集群任意节点，最终都会被转发到正确节点
> Redis会把每一个master节点映射到0~16383共16384个插槽 (hash slot)上，
>
> 数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况
>
> key中包含”{}”，且“{}“中至少包含1个字符，“{}“中的部分是有效部分
>
> key中不包含”{}”，整个key都是有效部分
>
> **计算方式**是利用CRC16算法得到一个hash值，然后对16384取余得到的结果就是slot值
>
> **如何将同一类数据固定的保存在同一个Redis实例**? 这一类数据使用相同的有效部分，例如key都以{typeId}为前缀

## mysql篇

> ==bin Log作用是什么?==
>
> 用来记录MySQL中增删改时的记录日志,最大的用处就是进行**主从复制，以及数据库的恢复**
> ==redo Log作用是什么?==
> 用来在MySQL宕机情况下将不完整的事务执行数据纠正。数据库的更新操作会在内存中先执行，最后刷入磁盘,redo log就是(为了恢复更新了内存但是由于宕机等原因没有刷入磁盘中的那部分数据.
> ==undo Log作用是什么?==
> 用来回滚到某一个版本，是一种逻辑日志。记录的是修改之前的数据，
> 当delete一条记录时，undolog中会记录一条对应的insert记录，从而保证能恢复到数据修改之前。在执行 事务回滚的时候，就可以通过undo log中的记录内容并以此进行回滚

> ==主从同步?==
> 1、在从库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量
> 2、在从库B上执行start slave命令，这时从库会启动两个线程，就是图中的I/0线程和SQL线程。其中I/0线程负责与主库建立连接
> 3、主库A校验完用户名、密码后，开始按照从库B传过来的位置，从本地读取binlog，发给B
>
> 4、从库B拿到binlog后，写到本地文件，称为中继日志
>
> 5、SQL线程读取中继日志，解析出日志里的命令，并执行
>
> ==Mysql主从同步延时产生原因?怎么优化?==
>
> 主节点如果**执行一个很大的事务**，那么就会对主从延迟产生较大的影响
> **网络延迟**，日志较大，slave数量过多
> **主上多线程写入，从节点只有单线程同步**
> 机器性能问题，从节点是否使用了“烂机器"
> **锁冲突问题**也可能导致从机的SQL线程执行慢
>
> 1)大事务: 将大事务分为小事务，分批更新数据
> 2)减少slave的数量，不要超过5个，减少单次事务的大小
> 3)Mysql 5.7之后，可以使用多线程复制，使用MGR复制架构
> 4)在磁盘、raid卡、调度策略有问题的情况下可能会出现单个IO延迟很高的情况，可用iostat命令查看 DB数据盘的I0情况，再进一步判断
> 5)针对锁问题可以通过抓去processlist以及查看information_schema下面和锁以及事务相关的表来查 看
> 主机与从机之间的物理延迟是无法避免的，既然无法避免就可以考虑尝试**通过缓存等方式，降低新修改 数据被立即读取的概率**
>
> ==Mysql主从复制同步方式有哪些?==
>
> (1)异步复制 是主库写入binlg日志后即可成功返回客户端，无须等待binlog日志传递给从库的过程
> (2)同步复制 Master主机将事件发送给SLave主机后会触发一个等待，直到所有SLave节点(如果有多个sLave)返回数据复制成功的信息给Master
> (3)半同步复制 言，Master主机将事件发送给SLave主机后会触发一个等待，直到其中一个SLave节点(如果有多个slave) 返回数据复制成功的信息给Master
> 如果因为网络延迟等原因造 成SLave迟迟没有返回复制成功的信息，超过了Master设置的超时时长，半同步复制就降级为异步复制 方式，而后继续数据复制

> ==读写分离架构中经常出现，那就是谈延迟的问题如何解决?==
> 1、mysqL5.7的主从复制是多线程，一般也能满足
>
> 2、业务层面妥协，是否操作完之后马上要进行读取
>
> 3、这类的读取直接走主库，sharding jdbc 提HintManager.getInstance().setMasterRouteOnly();

> ==MVCC机制如何解决幻读?==
> **幻读:** : 事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次 搜索发现有N+M条数据了，就产生了幻读。(针对insert)
> **MVCC只在读提交 RC /可重复读 RR两种隔离级别下工作**
> 在**RR的隔离级别下，Innodb使用MVCC和 next-key Locks(行锁和间锁的组合)解决幻读**
> 1、MVCC解决的是普通读(快照读)的幻读，
> 2、next-key Locks解决的是当前读情况下的幻读
> ==mvcc 工作流流程==
> 1.首先获取事务自己的版本号，也就是事务 ID;
> 2.获取 ReadView 读试图;
> 3.查询得到的数据，然后与 Readview 中的事务版本号进行比较;
> 4.如果不符合 Readview 规则，就需要从 Undo Log 中获取历史快照
> 5.最后返回符合规则的数据。
>
> ==MVCC解决的问题==
>
> 1.读写之间阻塞的问题。
> 通过MVcc可以让读写互相不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务并发处理能力。
> 2.降低了死锁的概率。
> 这是因为MVCC采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行。
> 3.解次快照读的问题。
> 当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。

> ==readview读取场景==
>
> RC 读已提交(Read Committed) 时，一个事务中的每一次 SELECT 查询都会重新获取一次Read View
>
> RR 可重复读的时候，就避免了不可重复读，这是因为一个事务只在第一次 SELECT 的时会 获取一次 ReadView，而后面所有的 SELECT 都会复用这个 Read View

> ==mysql间锁是如何解决幻读?==
> **MySQL间隙锁+记录锁 ，组合起来，解决的是当前读情况下的幻读**
> 1.记录锁(Record Lock) : 直接加在索记录上面
>
> 2.间隙锁 Gaps Lock  当我们使用范围条件而不是相等条件检索数据，并请求共享或者排他锁时，InnoDb会符合条件的数据记录的索引项加锁；对于键值在条件范围内但不存在的记录叫做间隙 GAP，InnoDB也会对这个间隙加锁，这种机制就叫做间隙锁
> 3.Next-Key Lock: 记录锁与间隙锁组合起来用就叫做Next-Key Lock

> ==快照(历史数据) - mvcc==
> mvcc基于版本的控制协议。该技术不仅可以保证innodb的可重复读，而且可以防止幻读
> 但是它防止的是快照读，也就是读取的数据虽然是一致的，但是数据是历史数据。
> 快照读对应的sql 语法: 简单的select操作(不包括 select . lock in share mode，select .. forupdate)
> ==当前读(最新数据) - next-key Lock==
> 一个事务，其内部读取对应某一个数据的时候，数据都是一样的，同时读取的数据是最新的数据.
> innodb提供了next - key Lock，也就是结合gap锁与行锁，达到最终目的。
> select * from table where ? lock in share mode ;
>
> select * from table where ? for update;
>
> insert into table walues (..) ;
>
> update table set ? where ?;
>
> delete from table where ?;

> 表级锁 :开销小，加锁快，不会出现死锁;锁定粒度大，发生锁冲突的概率最高，并发度最低;MyISAM,MEMORY，CSV等一些非事务性存储引擎。
> 行级锁 :开销大，加锁慢;会出现死锁;锁定粒度最小，发生锁冲突的概率最低，并发度也最高: InnoDB存储引擎
> 页面锁 : 开销和加锁时间界于表锁和行锁之间;会出现死锁;锁定粒度界于表锁和行锁之间，并发度一般。BerkeLeyDB存储引擎

> 共享锁: 阻塞写(X)，但是不会阻塞读(S) select.. in share mode 获得共享锁,
> 排他锁: 读(S)和写(X)都阻塞  select... for update 获得排他锁

> ==**记录锁:**== 对表中的记录加锁，叫做记录锁，简称(行锁。**要锁的列没有索引，进行全表记录加锁**。 也是排它(X)锁，所以会阻塞其他事务对其插入、更新、删除
>
> ==**临键锁(Next-Key Locks** :== Next-key锁是**记录锁和间隙锁的组合**，它指的是加在某条记录以及这条记录前面间隙上的锁。一种特殊的间隙锁。
> 每个数据行上的(非唯一索引列上都会存在一把临健锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据
> ==**意向锁**==
> 意向共享(IS)锁: 事务有向对表中的某些行加共享锁(S锁)
> 意向排他(IX)锁: 事务有意向对表中的某些行加排他锁(X锁)
>
> 意向共锁 (IS)和 意向排他锁 (IX) 都是锁表。
> **意向锁是一种 不与行级锁冲突的表级锁**，这一点非常重要。
> 意向锁是 InnoDB 自动加的， 不需用户干预。
> 意向锁是在 InnoDB 下存在的内部锁，对于MyISAM 而言 没有意向锁之说。
> 意向锁类似于一种全局性的许可，可以直接查看全局是否存在锁有没有释放，比如事务A获取了表行锁，事务B想要获取表锁，就得挨个判断。有了意向锁就不需要了。它的存在是为难 表级 排他(X)/共享(X)锁。
>
> ==**插入意向锁:**==
> 1、插入意向锁是一种特殊的间隙锁 -- 间隙锁可以锁定开区间内的部分记录
> 2、插入意向锁之间互不排斥，所以即使多个事务在同一区间插入多条记录，只要记录本身 (主键、唯一索引)不冲突，那么事务之间就不会出现冲突等待。
> 3、RR的事务隔离级别下，使用插入意向锁来控制和解决并发插入

> ==什么是索引下推?==
> 索引下推 也被称为索引条件下推 (Index Condition Pushdown) ICP
> 5.6之前通过**非主键索引查询时**，存储引擎通过索引查询数据，然后将结果返回给MySQL server层，在server层判断是否符合条件，
>
> 在以后的版本可以使用索引下推，当存在索引列作为判断条件时，Mysql server 将这一部分判断条件传递给存储引擎，
> 然后存储引擎会筛选出符合传递传递条件的素引项，即**在存储引擎层根据索引条件过滤掉不符合条件的索引项，然后回表查询得到结果，将结果再返回给Mysql server**
> **某些场景下，可以减少回表次数。**

> ==什么是MRR优化?==
>
> MRR，全称 [Multi-Range Read 0ptimization]。
> 在不使用 MRR 时，优化器需要根据二级索引返回的记录来进行“回表”，这个过程一般会有较多的随机 I0,使用MRR 时，SQL 语句的执行过程是这样的:
> 1、先把通过二级索引取出的值缓存在缓冲区中,
> 这个缓冲区叫做 read_rnd_buffer ，简称 rowid buffer。
> 2、再把这部分缓冲区中的数据按照ID进行排序。
> 如果二级索引扫描到索引文件的末尾或者缓冲区已满，则使用快速排序对缓冲区中的内容按照主键进行排序;
> 3、然后再依次根据ID去聚集索引中获取整个数据行。
> 线程调用 MRR 接口取 rowId，然后根据rowId 取行数据;
> 当根据冲区中的 rowId 完数，则继续调用过程 2) 3)，直至扫描结束
> ==MRR 的本质:==
> 是**在回表的过程中， 把分散的无序回表， 变成排序后有序的回表**， 从而**实现 随机磁盘读 尽可能变成 顺序读**。**借助 空间的局部性原理和磁盘预读取等底层机制完成的**.、
> MRR 适用于range、ref、eq_ref的查询

## 分库分表篇

> ==常见分片算法？==
>
> **range 分片**:每个片，一段连续的数据，这个一般是按比如时间范围/数据范围(15 51~100)来的，容易发生数据倾斜，大量的流量都打在最新的数据上了.
>
> **ID取模分片**:此种分片规则将数据分成n份(通常dn节点也为n)，从而将数据均的分布于各个表中，或者各节点
> ==hash 哈希分布==
> **哈希取余分片**:每个数字进行哈希运算，然后对每个数的哈希结果除以节点数进行取余，余数为节点下标 对数据进行哈希，然后取余
> 数据节点伸缩时，导致数据迁移/迁移数量和添加节点数据有关，建议翻倍扩容(可以少迁移部分数据)
>
> **一致性哈希分片**: 将所有的数据当做一个token环，token环中的数据范围是0到2的32次方。然后为每一个数据节点分配一个token范围值，这个节点就负责保存这个范围内的数据。对每一个key进行hash运算，被哈后的结果在哪个token的范围内，则按顺时针去找最近的节点，这个key将会被保存在这个节点上
>
> 哈希结果一般情况下比较均匀/节点伸缩时，只影响邻近节点，但是还是有数据迁移/数据规模小的场景下，会出现单位时间内某个节点完全空闲的情况出现。 
>
> **虚拟槽分片:** 可以理解为范围分片的变种，预设虚拟槽，每个槽为一个hash值，每个node负责一定槽范围

> ==shardingjdbc分片策略?==
> **标准分片策略**
> 1.支持 PreciseShardingAlgorithm 和 RangeShardingAlgorithm 两个分片算法
>
> 2.其中 PreciseShardingAgorithm 是必选的，用于处理 =和 IN 的分片。
>
> 3.RangeShardingAlgorithm 用于处理BETWEEN AND， ，<，，s 条件分片，
>
> 4.RangeShardingAlgorithm 是可选的, 如果不配置RangeShardingAlgorithm，SQL中的条件等将按照全库路由处理
> **复合分片策略**
> 1.对应 ComplexShardingStrategy.。同样支持对 SQL语句中的，>，《， ， ，IN和 BETWEEN AND 的分片操作
> 2.支持多分片键
> **表达式分片策略 (inline内联分片策略)**
> 1.支持对 SQL语句中的 = 和 IN 的分片操作，但只支持单分片键。 
>
> 2.简单的分片，直接在配置文件中接着写规则，t_order_$-t_order_id % 43
> **强制分片略 (Hint 暗示分片策略)**
> 1.通过指定分片健而非SQL 中提取分片健的方式进行分片的策略。。 
>
> 2.HintShardingAlgorithm算法

> ==分库的join怎么解决?==
> 1、两个表用相同的分片建，
> 2、并且进行表绑定，防止产生数据源实例内的笛卡尔积路由。t1*t2

## 消息队列篇

> ==**优点**==
> **异步处理** - 相比于传统的串行、并行方式，减少了RT,提高了系统吞吐量。
>
> **应用解耦** - 系统间通过消息通信，不用关心其他系统的处理。一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，通过MQ解耦
> **流量削锋** - 可以通过消息队列长度控制请求量;可以缓解短时间内的高并发请求
> 日志处理  解决大量日志传输。
> 消息通讯  消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点息队列，或者聊天室等
>
> ==缺点==
>
> 系统可用性降低  那消息队列挂了，系统受影响
> 系统复杂度提高 一致性问题、可靠性传输、避免消息被重复消费等

> ==MQ选用==
> activeMQ 高并发、高负载以及高吞吐的复杂场景国内落地较少。
> rabbitMQ 落地的案例较多、社区活跃，但是基于erlang语言，定制和改造费事
> rocketMQ 阿里系，性能、场景经过实际验证，java语言，源码定制方便
> kafka 主要应用场景 实时日志采集、实时数据同步、实时数据计算，大数据领域

> ==选择依据==
>
> 1.协议: AMQP、STOMP、MQTT、私有协议等
>
> 2.消息是否需要持久化。
> 3.吞吐量。
> 4.高可用支持，是否单点。
>
> 5.分布式扩展能力。
>
> 6.消息堆积能力和重放能力。
>
> 7.开发便捷，易于维护。8.社区成熟度

> ==消息可靠性/一致性保证？==
>
> **rabbitMq**
>
> producer端
>
> - 事务机制
>
> - confirm确认机制，rabbitMq收到消息会给producer发送ack 或nck确认
>
> rabbitMq自身
>
> - 队列和消息设置持久化
>
> consumer
>
> - 手动ACK

> ==消息有序性保证？==
>
> **rabbitMq**
>
> - 拆分queue，使得一个queue只对应一个消费者
> - 多线程消费一个队列，使用重试机制判断顺序

> ==消息堆积处理？==
>
> **rabbitMq**
>
> - 解决consumer消费问题
> - 临时扩容，写一个临时分发数据的消费者程序，写入临时建立好的 N 倍数量的 queue中，临时征用 N 倍的机器来部署 consumer，每个 consumer 消费一个临时 queue 的数据。

> ==恢复队列中丢失的数据：？==
>
> **rabbitMQ**
>
> -  rabbitMQ，并且设置了过期时间，消息在 queue 里积压超过一定的时间会被 rabbitmq 清理掉，导致数据丢失
> -  流量低峰期，写一个程序，手动去查询丢失的那部分数据，然后将消息重新发送到mq里面，把丢失的数据重新补回来。

> ==MQ长时间未处理导致MQ写满的情况如何处理?==
>
> 丢弃+批量重导
>
> 临时写个程序，连接到mq里面消费数据，消费一个丢弃一个，快速消费掉积压的消息，降低MQ的压力，然后在流量低峰期时去手动查询重导丢失的这部分数据。

> ==高可用保证？==
>
> **rabbitMq**
>
> - 单机模式
> - 普通集群模式  队列 queue 的消息只会存放在其中一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）
> - **镜像模式**  每个 RabbitMQ 节点都有这个 queue 的完整镜像，任何一个机器宕机了，其它机器节点还包含了这个 queue 的完整数据，其他消费者都可以到其它节点上去消费数据

## [ES篇](../ElasticSearch/ElasticSearch(搜索服务器).md)

> ==ELasticsearch 中素引在设计阶段如何调优?==
>
> 1)根据业务增量需求，采取基于日期模板创建索引，通过roll over- API滚动索引;
> 2)使用别名进行索引管理;
> 3)每天凌晨定时对索引做force_merge操作，以释放空间;
> 4)采取冷热分离机制，热数据存储到SSD，提高检索效率; 冷数据定期进行shrink操作，以缩减存储;
> 5)采取curator进行索引的生命周期管理;
> 6)仅针对需要分词的字段，合理的设置分词器;
> 7)Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。

> ==es master选举==
> **前提**
> 1、只有候选主节点 (master: true) 的节点才能成为主节点
> 2、最小主节点数(min_master_nodes)的目的是防止脑裂。
> 首先确认候选主节点数达标，也就是discovery.zen,minimum_master_nodes
>
> 选主
> 1、ELasticsearch 的选主是 ZenDiscovery 模块负责的，主要包含 Ping (节点之间通过这RPC 来发 现彼此)和 Unicast (单播模块包含一个机列表以控制哪些节点需要 ping 通)这两部分
> 2、对所有可以成为 master 的节点 (**node.master: true) 根据 nodeId 字典排序**，每次选每个节 点都把自己所知道节点排一次序，然后选出第一个 (第0  位)节点，暂且认为它是 mastel
> 节 点。
>
> ​    3、如果**对某个节点的投票数达到一定的值 (可以成为 master 节点数 n/2+1)** 并且该节点自己选 举自己，那这个节点就是 master。否则重新选举一直到满足上述条件。
>
> ​    4、master 节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理;data 节点可以 关闭 http功能。

> ==脑裂问题==
> 其实 就是选举master的 配置导致 7.4版本后已被移除  这个配置就是说 当前node想要成为master，得多个node同意才行。
>
> 脑裂问题 就是比如 master slave slave 一主两从 主机后 两从之间选取一个master 而原先故障master重启后 ，按选举配置 自己给自己投一票成为master 就形成脑裂现象。
>
> 简单描述就是 多个master共存的 现象。
>
> 脑裂”问题可能的成因: (有两个master)
> 网络问题: **集群间的网络延迟导致一些节点访问不到 master，认为 master 挂掉了**从而选举出新 的master，并对 master 上的分片和副本标红，分配新的主分片
>
> 节点负载: **主节点的角色为 master 又为 data**，**访问量较大时可能会导致 ES 停止响应造成大面积延迟，**此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点.
> 内存回收: **data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收**，造成 ES 进程 失去响应。
> 脑裂问题解决方案
> **减少误判**: discovery.zen.ping_timeout 节点状态的响应时间 (超过这个时间就会重新选举master)，默认为 3s，可以适当调大，如果 **master在该响应时间的范围内没有做出响应应答**， 判该节点已经挂掉了。**调大参数** (如 6 s，discovery,zen,ping_timeout:6)，可适当减少误判
> 选举触发: discovery.zen.minimum_master_nodes:1 该参数是用于控制选举行为发生的最小集主节点数量。当备选主节点的个数大于等于该参数的值， 且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为 **(n/2) +1，n 为主节点个数(即有资格成为主节点的节点个数)**
> 角色分离: 即 master 节点与 data 节点分离，限制角色 主节点配置为: node.master: true node.data: false 从节点配置为: node.master: false node.data: true

> ==全文索引/倒排索引==
> 简单来说 就是针对 搜索的关键词建立索引 然后根据这个索引 查找文档的过程 ，存的时候，对关键词进行分词 建立索引，一同建立的还有这个索引 和文档的 映射关系。

> tf term frequency 描述的是关键词在文档中出现的次数 越大 权重越高
> df document frequency 有多少文档包含此关键词 越大说明越普遍，说明权重越低不重要。

> ==写入过程==
> 客户端选择node发送，这个节点属于协调节点。
>
> 协调节点根据文档ID进行路由，hash 取模 获取数据应该存在在哪个node，转发至实际node处理
>
> 实际的节点主分片primary shard 复制处理请求，然后将数据同步的副本节点上 replcia node
>
> 协调节点等主分片和副本分片都执行成功后，返回响应给客户端

> ==主分片写入过程分析==
> 先写入memory buffer 内存缓冲区
> 然后 每隔1s从缓冲区读取并写入segment文件中(这个文件存储的就是索引集合)，同时进入filesystem cahe，完事后清空内存缓冲区。这个叫refresh 也就是 es 1s 延迟的由来

> ==保证memory buffer filesystem cache 可靠性==
> **es通过transLog保证**。写入缓冲区同时，会进行translog日志记录，用于岩机重启恢复。translog也是先写入filesystem cache然后 5s后刷到磁盘 ，其实也会有丢失问题。强制每次写操作都刷，会有性能问题
>
> ==translog过大问题==
> 采用flush操作 文件过大超过值，会将内存中所有数据落盘后，清空translog日志。

> ==es 搜索过程==
> **query+fetch过程**
>
> 1、搜索被执行成一个两阶段过程，我们称之为Query Then Fetch;
>
> 2、在初始查询阶段时，查询会广播到索引中每一个分片拷贝 (主分片或者副本分片)。 每个分片在本地执行搜索并构建一个匹配文档的大小为from + sze的优先队列、PS:在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在MemoryBuffer，所以搜索是近 实时的.
> 3、每个分片返回各自优先队列中 所有文档的ID和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表
> 4、接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个GET请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。。一旦所有的文档都披取回了，协调节点返回结果给客户端
> 5、补充: Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term 和Document frequency，这个评分更准确，但是性能会变差。

> ==ELasticsearch更新和删除文档的过 程==
>
> 磁盘上的每个段都有一个相应的del文件
> 当删除请求发送后，文档并没有真的被删除，而是在**deL 文件中被标记为删除**。该文档依然能匹配查询但是会在结果中被过滤掉。当段合并时，在del文件中 被标记为删除的文档将不会被写入新段。
>
> 当执行更新时，旧版本的文档在 del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在 结果中被过滤掉

> ==ELasticsearch 如果保证读写一致==
>
> 可以通过**版本号使用乐观锁并发控制**，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突
> **对于写操作:**一致性级别支持 quorum/one/alL，默认为 quorum,quorum: 即只**有当大多数(一半以上)分片可用时才允许写操作**。但即使大多数可用，也 可能存在因为网络等原因导致写入本失败，这样该副本被认为故障，分片将会在一个不同 的节点上重建。 one: 即只要主分片数据保存成功，那么客户端就可以进行查询操作了。 al1: 是最高的一致性级别，要求所有分片的数据要部保存成功，才可以继续进行。
> 对于读操作:可以设置 replication 为 sync(默认为同步)，这使得提作在主**分片和副本分片都完成 后才会返回;** 设置 replication 为 async (异步)时，也可以通过**设置搜索请求参数_preference 为 primary 来查询主分片，确保文档是最新版本。**

> ==ELasticsearch索引文档的过程==
>
> 首先客户端向集群发出索引文档的请求，它会选择任何一个节点，这个节点当接收到请求后会根据路由算法找到应该放的那个主分片的位置，从而索引数据
> shard = hash(document_id) % (num_of_primary_shards)
> 1，当**分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer**，然后**定时(默认是每隔1秒)写入到 Filesystem Cache**，这个从MomeryBuffer到Filesystem Cache的过程就做 refresh
> 2、当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，**ES是通过translog的机制来保证数据的可靠性的**。其实现机制是**接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做fLush**;
> 3、在 fush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。
>
> 4、flush触发的时机是定时触发(默认30分钟)或者translog变得太大(默认为512M) 时



## [Docker篇](../docker/Docker.md)

> **虚拟机**（virtual machine）是在操作系统中**模拟**硬件设备，然后运行另一个操作系统    操作系统中的操作系统
>
> **Docker**仅仅是封装函数库，并没有模拟完整的操作系统    系统进程

> **镜像（Image）**：Docker将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。
>
> **容器（Container）**：镜像中的应用程序运行后形成的进程就是**容器**，只是Docker会给容器进程做隔离，对外不可见。
>
> **Dockerfile**就是一个文本文件，其中包含一个个的**指令(Instruction)**，用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层Layer。
>
> Compose文件是一个文本文件，通过指令定义集群中的每个容器如何运行  看做是将多个docker run命令写到一个文件

> - docker run：创建并运行一个容器，处于运行状态
> - docker pause：让一个运行的容器暂停
> - docker unpause：让一个容器从暂停状态恢复运行
> - docker stop：停止一个运行的容器
> - docker start：让一个停止的容器再次运行
> - docker rm：删除一个容器
> - docker pull 拉取镜像
> - docker push 推送镜像
> - docker build 构建镜像
> - docker images 查看
> - docker rmi 删除镜像
> - docker save 保存镜像为压缩包
> - docker load 加载压缩包为镜像
> - docker volume命令是数据卷操作，根据命令后跟随的command来确定下一步的操作：
>
>   - create 创建一个volume
>   - inspect 显示一个或多个volume的信息
>   - ls 列出所有的volume
>   - prune 删除未使用的volume
>   - rm 删除一个或多个指定的volume



## 响应式编程篇

### RxJava

> 与传统的观察者模式不同：
>
> - RxJava中，在**主题内部有一个弹射器的角色**；而经典的观察者模式，主题所发送的是单个的消息，并不是一个消息序列
>
> - Observable 主题**还会负责消息序列缓存，这一点像经典的生产者消费者模式**

> 基于观察者模式设计
>
> **Observable类  等价于  观察者模式中的Subject（抽象主题）**
>
> **Subscriber类   等价于  观察者模式中的Observer（抽象观察者）**
>
> - Observable和Subscriber通过**subscribe()方法实现订阅关系**
> - Observable和Subscriber之间通过emitter.**onNext(…)弹射的方式实现主题的消息发布**
> - RxJava中主题的消息发布方式之一是通过内部的弹射器（Emitter）完成。弹射器除了调用
>   onNext()方法弹射消息之外，还定义了两个特殊的通知方法：onCompleted()和onError()
> - Subscriber有3个回调方法。其中，onNext(String s)回调方法用于响应
>   Observable主题的正常的弹射消息；onCompleted()回调方法用于响应Observable主题的结束消息；
>   onError(Throwable e)回调方法用于响应Observable主题的异常消息

> RxJava支持函数式编程，就是对subscribe()方法进行了重载，重载版本里对函数式接口进行了封装。实际上最终订阅者还是Subscriber。
>
> Hystrix大量使用RxJava里的函数式方式

> **背压问题**
>
> **当上下游的流操作处于不同的线程时**，如果**上游弹射数据的速度快于下游接收处理数据的速度**，这样对于那些没来得及处理的数据就会造成积压，这些**数据**既不会丢失，也不会被垃圾回收机制回收，而是**存放在一个异步缓存池中**，如果缓存池中的数据一直得不到处理，越积越多，最后就会造成**内存溢出**，这便是响应式编程中的背压问题。
>
> - Emitter.BackpressureMode.LATEST  **最近模式** 如果消费跟不上，则`仅缓存最近弹射出来的数据，将老旧一点的数据直接丢弃`
> - BackpressureMode.NONE和BackpressureMode.ERROR  **不使用背压模式**  在这两种模式中发送的数据，不使用背压。当上游Observable主题弹射数据的速度大于下游通
>   过Subscriber接收的速度，造成上游数据积压时，会抛出MissingBackpressureException异常
> - BackpressureMode.BUFFER  **缓冲模式**  在这种模式下，有一个无限的缓冲区（初始化时是128）。下游消费不了的元素，统统都会放
>   到缓冲区中。如果缓冲区中持续地积累，会导致内存耗尽，最终抛出OutOfMemoryException异常
> - BackpressureMode.DROP **固定缓冲区模式(丢弃模式)** 这种模式下Observable主题使用固定大小为1的缓冲区。如果下游订阅者无法处理，则流的第
>   一个元素会缓存下来，后续的会被丢弃

## 网络编程篇

### 三次握手？

第一次握手：主机A通过向主机B 发送一个**含有同步序列号的标志位**的数据段给主机B，向主机B 请求建立连接，通过这个数据段， 主机A告诉主机B 两件事：我想要和你通信；你可以用哪个序列号作为起始数据段来回应我。（**<u>同步位SYN=1，序号SEQ=x（表明传送数据时的第一个数据字节的序号是x</u>**））

第二次握手：主机B 收到主机A的请求后，用一个**带有确认应答（ACK）和同步序列号（SYN）标志位的数据段响应主机A**，也告诉主机A两件事：我已经收到你的请求了，你可以传输数据了；你要用那个序列号作为起始数据段来回应我（**<u>该报文段中同步位SYN=1，确认号ACK=x+1，序号SEQ=y；</u>**）

第三次握手：主机A收到这个数据段后，**再发送一个确认应答**，（**<u>ACK(ack=y+1)</u>**）确认已收到主机B 的数据段："我已收到回复，我现在要开始传输实际数据了，这样3次握手就完成了，主机A和主机B 就可以传输数据了。

*<u>为了保证服务端能收接受到客户端的信息并能做出正确的应答而进行前两次(第一次和第二次)握手，为了保证客户端能够接收到服务端的信息并能做出正确的应答而进行后两次(第二次和第三次)握手。</u>*

<img src="img/v2-2a54823bd63e16674874aa46a67c6c72_r.jpg" alt="v2-2a54823bd63e16674874aa46a67c6c72_r"  />

`为什么需要三次握手，两次不行吗?`

第一次握手：客户端发送网络包，服务端收到了。

这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。

第二次握手：服务端发包，客户端收到了。

这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。**不过此时服务器并不能确认客户端的接收能力是否正常**。

第三次握手：客户端发包，服务端收到了。

这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。

因此，需要三次握手才能确认双方的接收与发送能力是否正常。

### 四次挥手？

第一次： 当主机A完成数据传输后,将**控制位FIN置1**，提出停止TCP连接的请求 ；

第二次： 主机B收到FIN后对其作出响应，确认这一方向上的TCP连接将关闭,**将ACK置1；**

第三次： 由B 端再提出**反方向的关闭请求,将FIN置1** ；

第四次： 主机A对主机B的请求进行确认，**将ACK置1**，双方向的关闭结束。

![image-20241211095338000](img/image-20241211095338000-17338820197982.png)

`挥手为什么需要四次？`

关闭连接时，当**服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，“你发的FIN报文我收到了”。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送**。故需要四次挥手。

> ==三次握手过程==
> TCP连接的建立时，双方需要经过三次握手，具体过程如下
> (1)第一次握手: **CLient进入SYN_SENT状态**，发送一个SYN来主动打开传输通道，该的SYN标志位被设置为1，同时会带上Client分配好的SN序列号，该SN是根据时间产生的一个随机值，通常情况下每间隔4ms会加1。除此之外，SYN还会带一个MSS(最大报文段长度)可选项的值，表示客户端发 送去的最大数据块的长度。
> (2)第二次握手: **Server端在收到SYN帧之后，会进入SYN_RCVD状态，**同时返回SYN+ACK顿给client，主要目的在于通知cLient，Server端已经收到SYN消息，现在需要进行确认。Server端发出的 SYN+ACK顿的ACK标志位被设置为1，其确认序号AN (Acknowledgment Number) 值被设置为Client的SN+1; SYN+ACK的SYN标志位被设置为1，SN值为Server端生成的 SN序号:SYN+ACK的MSS (最大报文段长度)表示的是Server端的最大数据块长度
> (3)第三次握手: **cLient在收到Server的第二次握手SYN+ACK确认顿之后，首先将自己的状态会从SYN_SENT变成ESTABLISHED**，表示自己方向的连接通道已经建立成功，CLent可以发送数据给Serve端了。然后，cLient发ACK给Server端，该ACK帧的ACK标志位被设置为1，其确认序号 AN(Acknowledqment Number) 值被设置为Server端的SN序列号+1。还有一种情况，client可能会将ACK城和第一怖要发送 的数据，合并到一起发送给Server端
> (4)**Server端在收到client的ACK帧之后，会从SYN_RCVD状态会进入ESTABLISHED状态**，至此Server方向的通道连接建立成功，Server可以发送数据给CLient，TCP的全双工连接建立完成。

> ==四次挥手具体过程，具体如下==
> (1)第一次挥手:**主动断开方(可以是客户端，也可以是服务器端)，向对方发送一个FIN结束请求报文**，此报文的FIN位被设置为1，并目正确设置Sequence Number (序列号) 和AcknowledqmentNumber (确认号)。发送完成后，主动断开方进入FIN_WAIT_1状态，这表示主动断开方没有业务数据要发送给对方，准备关闭S0CKET连接了。
> (2)第二次挥手:正常情况下，在收到了主动断开方发送的FIN断开请求报文后，**被动断开方会发送-个ACK响应报文**，报文的Acknowledament Number (确认号) 值为断开请求报文的Sequence Numb(序列号)加1，该ACK确认报文的含义是:“我同意你的连接断开请求"。之后，被动断开方就进入了CLOSE-WAIT(关闭等待)状态，TCP协议服务会通知高层的应用进程，对方向本地方向的连接已经关闭，对方已经没有数据要发送了，
> 若本地还要发送数据给对方，对方依然会接受。被动断开方的 CLOSE-WAIT (关闭等待)还要持续一段主动断开方在收到了ACK报文后，由FIN_WAIT_1转换成间，也就是整个CLOSE-WAIT状态持续的时间。FIN_WAIT_2状态。
> (3)第三次挥手:在发送完成ACK报文后，被动断开方还可以继续完成业务数据的发送，待剩余数据发送完成后，或者CLOSE-WAIT(关闭等待)截止后，被动断开方会向主动断开方发送一个FIN+ACK结 束响应报文，表示被动断开方的数据都发送完了，然后，被动断开方进入LAST_ACK状态。
>
> (4)第四次挥手:主动断开方收在到FIN+ACK断开响应报文后，还需要进行最后的确认，向被动断开 方发送一个ACK确认报文，然后，自己就进入TIME_WAIT状态，等待超时后最终关闭连接。处于TIME_WAIT状态的主动断开方，在等待完成2MSL的时间后，如果期间没有收到其他报文，则证明对方 已正常关闭，主动断开方的连接最终关闭。 被动断开方在收到主动断开方的最后的ACK报文以后，最终关闭了连接，自己啥也不管了

> `IO 多路复用  IO Multiplexing `  **是一种IO模型**
>
> 操作系统引入了一类**新的系统调用，专门用于查询IO文件描述符的（含socket连接）的就绪状态**
>
> Linux系统中，**通过select/epoll系统调用**，**一个用户进程（或者线程）可以监视多个文件描述符**，一旦某个描述符就绪（一般是内核缓冲区可读/可写），**内核能够将文件描述符的就绪状态返回给用户进程（或者线程），用户空间可以根据文件描述符的就绪状态，进行相应的IO系统调用**

> **Channel（通道）怎么理解？**
>
> NIO中的TCP传输通道，实际上就是对**底层的传输链路所对应的文件描述符（file descriptor）的一种封装**

> **通道类型？**
>
> （1）FileChannel文件通道，用于文件的数据读写；
> （2）**SocketChannel**套接字通道，用于Socket套接字**TCP连接的数据读写**；
> （3）**ServerSocketChannel**服务器套接字通道（或服务器监听通道），允许我们**监听TCP连接请求**，为每个监听到的请求，创建一个SocketChannel套接字通道；
> （4）DatagramChannel数据报通道，用于UDP协议的数据读写。

> **通道IO事件？**
>
> （1）可读：SelectionKey.OP_READ   
> （2）可写：SelectionKey.OP_WRITE
> （3）连接：SelectionKey.OP_CONNECT   完成了和对端的三次握手过程
> （4）接收：SelectionKey.OP_ACCEPT  监听到一个新连接的到来时  **接收就绪**
>
> 一条通道若能被选择，必须继承SelectableChannel类  ，它提供了实现通道的可选择性所需要的公共方法
>
> **FileChannel文件通道就不能被选择器复用**

> **selector** 
>
> Selector 选择器可以理解为一个**IO事件的监听与查询器**。通过选择器，一个线程可以查询多个通道的IO事件的就绪状态。**选择器和通道的关系，是监控和被监控的关系**  `它的使命是完成IO的多路复用`
>
> `简单来说一旦在通道中发生了某些IO事件（就绪状态达成），这个事件就被记录在SelectionKey的readyOps上，并且这个SelectionKey被记录在Selector内部`
> `的selectedKeys集合中。`

> **缓冲区**
>
> 缓冲区，实际上是一个容器，一个连续数组。Channel提供从文件、网络读取数据的渠道，但是**读写的数据都必须经过Buffer**。本质是为了完成NIO的非阻塞读写操作

> SelectionKey理解？
>
> - Selector并不直接去管理Channel，而是直接管理SelectionKey，通过SelectionKey与Channel发生关系
> - **类似一个中介者，同时拥有Selector  以及Channel**  ，也可以认为是一种关联表
> - Channel最多能向Selector注册一次，**注册之后就形成了唯一的SelectionKey**，然后**被Selector管理起来**
> - SelectionKey**是IO事件的记录者（或存储者**），SelectionKey 有两个核心成员，存储着自己关联的Channel上的感兴趣IO事件和已经发生的IO事件

> ==IO分类==
>
> 阻塞IO  blocking io
>
> 非阻塞IO non blocking io 
>
> IO多路复用  io multiplexing
>
> 信号驱动IO   signal driven io
>
> 异步IO  asynchronous  io 

> ==BIO==
>
> 两阶段等待  用户空间-内核空间
>
> 1、**用户进程尝试读取数据，内核数据没有，等待直至数据来了，内核将数据拷贝至用户缓冲区，用户进程解除阻塞，读取数据**
>
> ==NIO==
>
> 一节点非阻塞，二阶段阻塞
>
> **1、用户进程尝试读取数据，内核数据未到达，返回error给用户进程。**
>
> **2、用户进程再次循环读取。**
>
> **3、内核数据来了，拷贝至用户空间缓冲区，用户进程解除阻塞，读取数据。   拷贝过程中，用户进程阻塞。**
>
> ==IO多路复用==
>
> **文件描述符FD** file descriptor ,从0开始的无符号整数，用来关联linux的一个文件。包括socket
>
> **利用单个线程来监控FD,并在FD可读、可写时，得到通知**，进行处理。
>
> 监听FD 通知FD的方式 包括 **select  poll epoll**
>
> select  和poll 只是通知用户进程FD就绪，但是不确定是哪个FD，需要用户遍历确认
>
> epoll 则会在通知用户进程FD就绪同时，将就绪的FD写入用户空间

> ==select==
>
> 1、创建FD集合
>
> 2、将FD集合拷贝至内核态
>
> 3、内核态循环遍历，将有事件响应的FD集合返回
>
> 4、将FD集合拷贝至用户态
>
> 5、用户态再针对这个FD集合遍历，找到对应可读、可写的FD处理。
>
> ==poll==
>
> 本质上和select没有区别  最本质区别就是**它没有最大连接数的限制**，因为它基于链表存储的。
>
> ==epoll==
>
> 1、构建epoll对象
>
> 2、有连接接入时，会插入至epoll对象中。这个对象包含 红黑树和双向链表，fd插入至红黑树中。
>
> 3、一旦fd就绪，就会触发回调，将就绪的fd插入至就绪链表中，并唤醒用户进程
>
> 4、用户进程调用epoll_wait只需要检查就绪列表是否存在数据，有则返回给用户程序，否则进入等待队列。

基于epoll实例中的**红黑树保存**要监听的FD，**理论上无上限**，而且增删改查效率都非常高

每个**FD只需要执行一次epoll_ctl添加到红黑树**，以后每次epol_wait，**无需重复拷贝FD到内核空间**

利用ep_po无需传递任何参数ll_**callback机制来监听FD状态，无需遍历所有FD**，因此性能不会随监听的FD数量增多而下降

**事件通知模式**

LevelTriggered：简称LT，也叫做水平触发。只要某个FD中有数据可读，每次调用epoll_wait都会得到通知。

EdgeTriggered：简称ET，也叫做边沿触发。只有在某个FD有状态变化时，调用epoll_wait才会被通知。

<img src="img/6cadb9bca18b9745152d708b2ae431de.png" alt="img" style="zoom:50%;" />



### 

> ==信号驱动IO==
>
> 阶段一
>
> ①用户进程调用sigaction，注册信号处理函数
>
> ②内核返回成功，开始监听FD
>
> ③用户进程不阻塞等待，可以执行其它业务
>
> ④当内核数据就绪后，回调用户进程的SIGIO处理函数
>
> 阶段二：
>
> ①**收到SIGIO回调信号**
>
> ②调用recvfrom，**读取**
>
> ③**内核将数据拷贝到用户空间**
>
> ④**用户进程处理数据**

> ==异步IO  AIO==
>
> 整个过程都是非阻塞的，用户进程调用完异步API后就可以去做其它事情，内核等待数据就绪并拷贝到用户空间后才会递交信号，通知用户进程.
>
> 阶段一
>
> ①用户进程调用aio_read，**创建信号回调函数**
>
> ②**内核等待数据就绪**
>
> ③用户进程**无需阻塞，可以做任何事情**
>
> 阶段二：
>
> ①内核数据**就绪**
>
> ②内核数据**拷贝到用户缓冲区**
>
> ③拷贝完成，内核递交信号**触发aio_read中的回调函数**
>
> ④**用户进程处理数据**

## 反应器模式 Reactor

> Reactor反应器模式**由Reactor反应器线程、Handlers处理器两大角色组成**，也叫Dispatcher模式  **`是一种线程模型`**
> （1）Reactor反应器线程的职责：负责响应IO事件，并且分发到Handlers处理器。
> （2）Handlers处理器的职责：非阻塞的执行业务处理逻辑

> 单线程Reactor反应器模式的缺点
>
> 单线程反应器模式中，**Reactor反应器和Handler处理器都执行在同一条线程上**  容易造成阻塞问题

> 多线程版本的反应器模式
>
> （1）将负责**数据传输处理的IOHandler处理器的执行，放入独立的线程池中**。这样，**业务处理线程与负责新连接监听的反应器线程就能相互隔离**，避免服务器的连接监听受到阻塞。
> （2）**如果服务器为多核的CPU**，可以将反应器线程拆分为多个子反应器（SubReactor）线程；同时，引入多个选择器，并且**为每一个SubReactor引入一个线程，一个线程负责一个选择器的事件轮询**。

> 1. 反应器模式和生产者消费者模式对比
>
>    一定程度上，反应器模式有点类似生产者消费者模式。但是**反应器模式没有专门的队列去缓冲存储IO事件**，是直接分发的。
>
> 2. 反应器模式和观察者模式（Observer Pattern）对比
>
>    相似之处在于分发的思想，不同之处在于反应器一个事件只能被一个Handler处理，观察者模式中，同一个主题可以被订阅过的多个观察者处理。

## netty篇

> **netty的反应器模式**
>
> - **通道注册** 封装了NIO的Selector组件和Thread线程实例，设计了自己的Reactor角色，名称叫做EventLoop（事件循环），封装了NIO的Channel组件也叫Channel，所以所谓通道注册就是将Netty的Channel注册到EventLoop上
> - **查询事件** EventLoop内部Thread不断地轮询(**一个线程会负责一个反应器**)，查询选择器Selector中的IO事件
> - **事件内部分发、数据读取和发射**  传统反应器模式是将分发和数据读取分开，netty这里有点不一样。反应器EventLoop这两个操作都接管了。**EventLoop能访问到通道的Unsafe成员，当IO事件发生时，直接通过Unsafe成员完成NIO底层的数据读取**。EventLoop**读取到的数据后，会把数据发射到Channel内部的Pipeline流水线通道**
> - **流水线传播和业务处理**  Netty通过责任链模式将多个业务处理器组织起来，成为一个pipeline（流水线）。由通道负责管理，属于通道的一部分。

> **netty中的通道**
>
> NioSocketChannel：异步非阻塞TCP Socket传输通道。
> NioServerSocketChannel：异步非阻塞TCP Socket服务器端监听通道。  。。。其他不说明了
>
> 比如 Netty的NioSocketChannel**内部封装了一个Java NIO的SelectableChannel**成员，通过对该内部的Java NIO通道的封装，对Netty的NioSocketChannel通道上的**所有IO操作**，**最终会落地到Java NIO的SelectableChannel底层通道**。

> **Netty中的Reactor 反应器**
>
> 1. Netty中的**反应器组件有多个实现类，这些实现类与其Channel通道类型相互匹配**
>
>    对应于**NioSocketChannel**通道，Netty的反应器类为**NioEventLoop ** 一个NioEventLoop拥有一个Thread线程，负责一个Java NIO Selector选择器的IO事件、轮询。

> **Netty中的Handler处理器**
>
> 第一类是**ChannelInboundHandler入站处理器**；负责接收（或者执行）
>
> 第二类**是ChannelOutboundHandler出站处理器 **指的是从**ChannelOutboundHandler处理器到通道的某次IO操作**

> **ChannelPipeline**（通道流水线）的默认实现，实际上被设计成一个**双向链表**。所有的Handler处理器实例被包装成了双向链表的节点，被加入到了ChannelPipeline（通道流水线）中。

> Bootstrap类是Netty提供的一个便利的工厂类，可以通过它来完成Netty的客户端或服务器端的Netty组件的组装，以及Netty程序的初始化和启动执行。

> **父子通道**
>
> 在Netty中，**将有接收关系的监听通道和传输通道，叫做父子通道**。
>
> 其中，**负责服务器连接监听和接收的监听通道**（如NioServerSocketChannel），也叫父通道（Parent Channel）。
> 对应于**每一个接收到的传输类通道**（如NioSocketChannel），也叫子通道（Child Channel）

> **EventLoopGroup  就是多线程版本的反应器模式**
>
> EventLoopGroup轮询组就是一个**多线程版本的反应器**，其中的**单个EventLoop线程对应于一个子反应器（SubReactor**）。
>
> EventLoopGroup的构造函数有一个参数，用于指定内部的线程数。在构造器初始化时，会按照传入的线程数量，在**内部构造多个Thread线程和多个EventLoop子反应器（一个线程对应一个EventLoop子反应器），进行多线程的IO事件查询和分发。**
>
> 如果使用EventLoopGroup的无参数的构造函数，默认的EventLoopGroup内部线程数量为最大可用的CPU处理器数量的2倍
>
> Boss）轮询组： 新连接的监听和接收
>
> Worker）轮询组：  查询所有子通道的IO事件，并且执行对应的Handler处理器完成IO处理

> Netty零拷贝实现方式？  `注意和操作系统的零拷贝区别`
>
> （1）Netty提供**CompositeByteBuf组合缓冲区类**, 可以**将多个ByteBuf合并为一个逻辑上的ByteBuf**, 避免了各个ByteBuf之间的拷贝。
> （2）Netty提供了ByteBuf的**浅层复制操作（slice、duplicate**），可以将ByteBuf**分解为多个共享同一个存储区域的ByteBuf,** 避免内存的拷贝。
> （3）在使用Netty进行**文件传输时**，可以调用**FileRegion包装的transferTo**方法，**直接将文件缓冲区的数据发送到目标Channel**，避免普通的循环读取文件数据和写入通道所导致的内存拷贝问题。
> （4）在将一个**byte数组转换为一个ByteBuf对象的场景**，Netty**提供了一系列的包装类，避免了转换过程中的内存拷贝。**(Unpooled了提供了一系列的wrap包装方法，帮助大家方便快速包装出CompositeByteBuf
> 实例或者ByteBuf实例，而不用进行内存的拷贝)
> （5）如果**Channel接收和发送ByteBuf都使用direct直接内存进行Socket读写，不需要进行缓冲区的二次拷贝**。

> ByteBuf 核心优势
>
> **池化机制**
> 可以重用池中 ByteBuf 实例，减少内存分配与释放的开销，减少内存溢出的机会。
> **读写指针分离**
> 读取和写入索引分开，不需要像 ByteBuffer 一样，调用flip()方法去切换读/写模式，使用起来更加便捷。
> **可以自动扩容**
> ByteBuffer的内部数组大小是固定的，初始化之后，不支持动态扩容。ByteBuf 实例可以自动进行扩容。
> **支持零拷贝**
> ByteBuffer所提供零拷贝机制更好的提高性能，例如 slice切片、duplicate浅层复制、CompositeByteBuf等等

> **池化**
>
> 创建一个缓冲区对象池，将没有被引用的 ByteBuf 对象，放入对象缓存池中；当需要时，则重新从对象缓存池中取出，而不需要重新创建
>
> **扩容**
>
> 写入后新的数据规模未超过64，则选择则扩容后 capacity 是 64；
> 写入后新的数据规模超过 64，则选择64的下一个 2^n，例如128/256/512等，一直到满足需要为止；
> 扩容不能超过 max capacity ，超过会报错。
>
> Netty的**ByteBuf的内存回收工作是**通过引用计数的方式管理的。（引用计数的一系列方法定义在ReferenceCounted 接口中，每个 ByteBuf 都实现了
> ReferenceCounted 接口）
>
> 在默认情况下，当创建完一个ByteBuf时，它的引用为1；每次调用retain()方法，它的引用就加1；每次调用release()方法，就是将引用计数减1；
> 如果引用为0，再次访问这个ByteBuf对象，将会抛出异常；如果引用为0，表示这个ByteBuf没有哪个进程引用它，它占用的内存需要回收
>
> **（这里的回收分为）**
>
> - 属于Pooled池化的ByteBuf内存，放入可以重新分配的ByteBuf池子，等待下一次分配
> - 未池化的ByteBuf缓冲区，如果是堆（Heap）结构缓冲，会被JVM的垃圾回收机制回收；如果是Direct直接内存的类型，则会调用本地方法释
>   放外部内存（unsafe.freeMemory）。

> (1) 粘包，指Receiver ((接收端) 收到一个BteBuf，包含了Sender (发送端)的多个ByteBuf)，发送端的多个ByteBuf在接收端“粘”在了一起。
>
> (2)半包，就是Receiver将Sender的一个ByteBuf“拆”开了收，收到多个破碎的包。换句话说，Receiver收到了Sender的一个ByteBuf的一小部分。

> ==拆分阶段(粘包、半包,原因)==
> DMA复制阶段，DMA设备会把内核缓冲区(Socket发送缓冲区) 中的数据复制到网卡设备中，会进行二进制数据的合并或者拆分
> TCP协议报文的有效数(净数据) 大小是有限制的，MSS,也会合并或者拆分

> ==解决方式==
> 将读取到的进程缓冲区ByteBuf，在应用层进行二次组装，重新组装我们应用层的数据包
> (1)**可以自定义解码器分包器:** 基于ByteToMessageDecoder或者ReplayingDecoder，定义自己的用户缓冲区分包器。
> (2)**使用Netty内置的解码器。**如可以使用Netty内置的(LengthFieldBasedFrameDecoder) 自定义长度敬据包解码器。对用户缓冲区ByteBuf进行正确的分包。
>
> FixedLengthFrameDecoder  LengthFiedBasedFrameDecoder ，固定长度是消息头指定消息长度的一种形式，进行粘包拆包处理的。
> LineBasedFrameDecoder 、DelimiterBasedFrameDecoder ，换行是于指定消息边界方式的-种形式，进行消息粘

> ==ByteToMessageDecoder(抽象类)解码的流程==
> 首先，它将上一站传过来的输入到Bytebuf中的数据进行解码，解码出一个List对象列表(这个List来源于子类解码后，添加到父类的集合中):
> 然后，迭代List列表，逐个将Java POJ0对象传入下一站Inbound入站处理器

> ==解码器有ByteToMessageDecoder和MessageToMessageDecoder两大基类==。
> 如果要从ByteBuf到POJ0解码，则可继承ByteToMessageDecoder基类; 如果要从某一种POJ0到另一种POJO解码，则可继承MessageToMessageDecoder基类。
> Netty提供了不少开箱即用的Decoder解码器，能满足很多解码的场景需求，几个比较基础的解码器如下:
> 1、固定长度数据包解码器-FixedLengthFrameDecoder
> 2、行分割数据包解码器-LineBasedFrameDecoder
> 3、自定义分隔符数据包解码器-DeLimiterBasedFrameDecoder
> 4、自定义长度数据包解码器-LengthFieldBasedFrameDecoder

> ==Netty 如何实现心跳机制?==
> 所谓心跳，即在 TCP 长连接中，客户端和服务器之间定期发送的一种特殊的数据包，通知对方自己还在线，以确保 TCP 连接的有效性
> 在 Netty 中，实现心跳机制的关键是 IdLeStateHandler,构造配置
> readerIdleTimeSeconds: 读超时，即当在指定的时间间隔内没有从 Channel 读取到数据时，会触发 一个 READER_IDLE 的 IdleStateEvent 事件.
> writerIdleTimeSeconds: 写超时，即当在指定的时间间隔内没有数据写入到 Channel 时，会触发- 个 WRITER_IDLE 的 IdleStateEvent 事件。
> allIdleTimeSeconds: 读/写超时。即当在指定的时间间隔内没有读或写操作时，会触发一个ALL_IDLE 的 IdleStateEvent 事件.

> ==Netty如何实现断线重连?==
> 1、检测断开 重写ChannelInboundHandler#channelInactive来实现，当连 接不可用，该方法会被触发
> 2、重试策略 使用指定的重连策略进行 重连操作，直到重新建立连接或重试次数耗尽

> ==Netty如何解决SeLector空轮询BUG==
> 1.对Selector的s**elect操作周期进行统计**，每完成一次空的select操作进行一次计数.
> 2。若在某个周期内连续发生N次空轮询，则触发了epoll死循环bug。
> 3，**重建SeLector**，判断是否是其他线程发起的重建请求，若不是则将原SocketChannel从旧的Selector上去除注册，重新注册到新的Selector上，并将原来的SeLector关闭。

## [DDD篇](../DDD/DDD.md)

## 

