# :star:JavaBooklet

> 旨在形成一套java相关的使用手册，集学习、面试、工作一体。
>
> 提问篇用于面试



# :bookmark:知识块

| 基础知识 | [<font color=green>设计模式</font>](设计模式/设计模式.md) | [<font color=green>JVM</font>](jvm/JVM.md) | [<font color=green>并发编程</font>](并发编程/并发编程.md) | [<font color=green>线程池</font>](线程池/线程池.md) |       锁       | [<font color=green>网络编程</font>](网络编程/网络编程.md) | 项目管理 |   缓存   | redis |
| :------: | :-------------------------------------------------------: | :----------------------------------------: | :-------------------------------------------------------: | :-------------------------------------------------: | :------------: | :-------------------------------------------------------: | :------: | :------: | ----- |
|          |                          UML类图                          |                  内存结构                  |                         进程/线程                         |                      属性解释                       |   多种锁解释   |                          TCP/UDP                          |  gradle  | jetcache |       |
|          |                       常用设计模式                        |                     GC                     |                          多线程                           |                        分类                         | 字节码层面分析 |                         粘包/拆包                         |  maven   | j2cache  |       |
|          |                      使用及案例描述                       |                   字节码                   |                         内存模型                          |                        原理                         |                |                         滑动窗口                          |          |          |       |
|          |                                                           |                   类加载                   |                        多线程通信                         |                        配置                         |                |                         三次握手                          |          |          |       |
|          |                                                           |                JVM性能调优                 |                          原子类                           |                      拒绝策略                       |                |                         四次挥手                          |          |          |       |
|          |                                                           |                  双亲委派                  |                          并发包                           |                                                     |                |                         七层模型                          |          |          |       |
|          |                                                           |                                            |                         并发队列                          |                                                     |                |                         多路复用                          |          |          |       |
|          |                                                           |                                            |                         volatile                          |                                                     |                |                          零拷贝                           |          |          |       |
|          |                                                           |                                            |                        ThreadLocal                        |                                                     |                |                                                           |          |          |       |

|   技术框架   |      分布式      |                       中间件                        |                      数据库                      | [<font color=green>微服务</font>](微服务/微服务.md) | [<font color=green>消息队列</font>](消息队列/消息队列.md) | [<font color=green>DDD</font>](DDD/DDD.md) |  前端   |                  容器编排                  | linux    |
| :----------: | :--------------: | :-------------------------------------------------: | :----------------------------------------------: | :-------------------------------------------------: | :-------------------------------------------------------: | :----------------------------------------: | :-----: | :----------------------------------------: | -------- |
|    spring    |     分布式锁     |               [nginx](nginx/Nginx.md)               | [<font color=green>mysql</font>](mysql/Mysql.md) |                      注册中心                       |                         ActiveMQ                          |                领域驱动理解                |   vue   |                   docker                   | shell    |
|  springboot  |     分布式ID     | [<font color=green>tomcat</font>](tomcat/Tomcat.md) |                        es                        |                        熔断                         |                         RabbitMQ                          |                  角色职权                  | node.js | [<font color=green>k8s</font>](k8s/k8s.md) | 常用命令 |
| springCloud  |    分布式事务    |  [<font color=green>redis</font>](redis/Redis.md)   |                     mongodb                      |                      请求/负载                      |                         RocketMQ                          |                  工程样例                  |         |                                            |          |
|    dubbo     |    分布式缓存    |                      zookeeper                      |                    memcached                     |                        配置                         |              <font color =green>Kafka</font>              |                                            |         |                                            |          |
|   mybatis    |  分布式session   |                        gRpc                         |                  sharding-jdbc                   |                        网关                         |                                                           |                                            |         |                                            |          |
| mybatis-plus |  分布式任务调度  |                        etcd                         |                      mycat                       |                        限流                         |                                                           |                                            |         |                                            |          |
|    netty     | 分布式协议和算法 |                        canal                        |                                                  |                 springcloud Alibaba                 |                                                           |                                            |         |                                            |          |
|              |                  |                         ELK                         |                                                  |                                                     |                                                           |                                            |         |                                            |          |
|              |                  |                        solr                         |                                                  |                                                     |                                                           |                                            |         |                                            |          |
|              |                  |                      Activity                       |                                                  |                                                     |                                                           |                                            |         |                                            |          |

| 算法和数据结构 | 理论 | 日志         | 其他     | 大数据                     | java版本特性                                     | 其他编程语言 | [软件测试](软件测试/软件测试.md) |      |      |
| -------------- | ---- | ------------ | -------- | -------------------------- | ------------------------------------------------ | ------------ | -------------------------------- | ---- | ---- |
|                | 架构 | log4j        | 认证     | [python](python/Python.md) | [<font color=green>java8</font>](java8/Java8.md) |              | [jmeter](软件测试/jmeter.md)     |      |      |
|                |      | Resilience4j | 性能优化 |                            |                                                  |              |                                  |      |      |
|                |      |              | 服务网格 |                            |                                                  |              |                                  |      |      |
|                |      |              | 跨域     |                            |                                                  |              |                                  |      |      |
|                |      |              | 幂等方案 |                            |                                                  |              |                                  |      |      |



# :question:面试篇

## 进度总览

> **spring/springMVC/springboot/springcloud**
>
> **mq**
>
> **mysql**/es/mongodb
>
> 设计模式
>
> DDD
>
> 分布式/事务/缓存/存储
>
> 中台
>
> **dubbo**
>
> **jvm**
>
> netty
>
> **mybatis**
>
> tomcat/jetty
>
> **多线程**
>
> 网络通信/协议
>
> DevOps
>
> Saas
>
> linux
>
> vue
>
> SOA
>
> nginx
>
> gradle/maven
>
> zookeeper
>
> TODO 消息队列  tomcat  dubbo  其他 按上面补充



## 简历篇

> **技术能力**
>
> - 技术技能不能模板化，需要细化，描述细节点
> - 提炼职业生涯遇到的组件和使用场景、提炼主要项目和经验积累
>
> **项目经验**
>
> - 主要在于个人职责上，需要细化职责
> - 落实技术细节，结合业务场景，解决了什么问题、技术亮点和难点。项目本身不具备的话，可以移花接木，掌握这块的技术就可以移植过来
> - 如果本身项目是CRUD，完全可以将自己手写的高并发、分布式项目写上

## 项目介绍篇

> **主要职责**
>
> 负责galaxy国际化多语言的后端改造工作以及境外雪球业务功能、11号牌申请业务功能的开发工作
>
> **项目介绍**
>
> galaxy运营业务平台是运营使用，主要帮助客户处理境内外场外衍生品簿记、清算、结算、估值一体化工作。
>
> 我在这期间主要处理的是场外衍生品的簿记模块功能。包含
>
> 境外雪球业务功能的开发工作，包括现金流、交易流水以及合约的接收处理、计算、复核以及确认书的生成等。数据来源上游通过kafka消息推送或者通过dubbo接口推送，galaxy这边接收，执行后续的处理流程，包括数据的校验以及数据的计算、组装、入库。自动或者手动复核数据，生成确认书文件等。
>
> 11号牌申请业务主要是针对原有境内功能，进行EQD、EST部门及业务品种的扩张，这里使用境外数据源。包括一些行情资讯、CA流水、对账、新品种监控等功能
>
> **难点**
> 1、针对境内外数据的隔离以及接口的隔离2、针对扩展部门及品种代码结构臃肿的问题3、针对部分业务表数据量过大的问题
> **解决**
>
> 1、数据源的隔离，针对韩国雪球业务，数据方案采用的是境内外独立schema存储数据的方案，针对境内外不同的业务实现动态切换数据源，实现数据在业务层面的隔离。主要包含三类场景
>
> web接口：通过拦截器方式，在请求进入阶段，获取用户权限或者指定url方式比如/hk/，判断用户境内还是境外数据权限
>
> 定时任务或者dubbo接口：通过部门标识判断数据源配置
>
> kafka消息：通过消息体中的部门或者subbook（境外的业务属性）来判断数据源配置
>
> 技术上 ：
>
> galaxy使用的技术栈是springboot，spring自身提供了AbstractRoutingDataSourcec能够解决多数据源场景。新建动态数据源类继承AbstractRoutingDataSource，同时采用TransmittableThreadLocal来存储当前数据源信息,方便子线程获取父线程的值。
>
> 2、业务部门以及品种的，多使用策略模式进行解耦，相同的业务操作流程采用模板模式进行步骤共用，以及一些复杂的流程进行拆分使用观察者者模式进行一些通用功能的接口，比如spring event在接收处理一系列处理后，生成报表的操作。
>
> 3、数据量过大的问题
>
> - 首先数据库的库表建立要增加必要的索引以支撑搜索查询
> - 大表的话采用月表的形式，针对历史数据进行归档。
> - 导出以及查询方面，陷定条数以及数据范围。支持异步导出,同步返回文件的名称，记录数等，异步下载记录redis标识，前端通过指定频率来检测后端是否下载完毕，下载完再通过浏览器进行文件下载
> - 还有些日常全量跑批的场景，通过分部门进行多线程跑批，同时针对个别单个部分体量较大的数据，对接并行计算平台进行分片处理，计算平台通过数据切片，进行多实例分发，回调galaxy系统进行业务数据。
> - 针对必要的计算公式以及固定配置，采用redis进行缓存，避免数据库的直接访问。
>
> **实际的技术问题**
>

> **主要职责**
>
> 分布式调度平台的深度定制，基于源码级别以及项目提出的个性需求进行功能定制。
>
> **项目介绍**
>
> 批量任务调度平台
> 基于xxLjob开源组件做深度定制
> 实现单任务、流程类任务调度，以及任务生命周期的监控、管理.
> 定制和扩展体现在:
> 调度架构上，由调度服务和执行服务的交互，扩展一级调度服务、二级调度服务、执行服务的交互。(应对行内单元化的变革)
>
> 调度模式上，由简单任务调用、父子任务调用。扩展为流程任务调用。类似工作流的方式，形成任务流。支持对任务节点的控制，比如定时、循环(本质上是对任务定义的扩展，但是是基于每次流程版才而言，不是固定的)流程的控制(比如暂停、终止、恢复、重试等)
>
> 任务自身属性的丰富，比如对任务设置虚拟资源分、并行度，还有实际资源分等，本质上是一种资源的限制操作。
> 生命周期的监控，调度、回调环节的成功与否，通过日志状态的记录、事件的通知，告警(通知到统监控平台)，未名状态的补偿机制，比如服务下线、执行结果丢失等。。 执行器资源的动态启停等。
> **难点**
> 深度定制和原有的简单调度模式耦合过大，随着版本的迭代，功能之间互相影响,不稳定因素增加
> **解决**
> 进行定制功能的剥离，重构，比如资源分、cpass资源、运行态、单元化，单独构建模块。
> 对调度、回调环节中进行步骤的抽象，各个定制功能进行顶层接口的实现。通过一些设计模式，将固有功能和定制功能进行整合。
> 比如责任链，对于调度前置，存在默认实现和定时的实现比如pod启用，资源分消耗，根据依赖引入和配置开关决定是否状态。更细化的对于部分环节细分吗，根据不同的场景细分链条。
> 比如借助spring的事件通知机制，也就是观察者模式，实现一些业务逻辑的解摆，比如告警、pod资源的释放等
> 比如装饰器模式，对一些默认功能的增强，比如注册支持资源分的增强、
> 比如中介者模式 对于默认实现和定制实现的调用逻辑统一通过功能中介来进行逻辑选择
> **实际的技术问题**
> 比如流程调用并行节点的后置重复调度的问题。解决方式: 防重表
> 比如执行器服务有一个使用阻寨队列，批量回调方式，调度端同步接收回调处理超时问题。批量数据多了，整体超时。arthas检测，最后进行异步处理。

## 基础篇

### HashMap

> ==HashMap和ConcurrentHashMap区别？==
>
> 主要区别在多线程下线程安全上
>
> 1、hashMap在hash值存在冲突的情况下，采用拉链法。形成链表，**jdk1.7 采用头插法**，多线程下存在**死链**问题。**jdk1.8 多线程下存在值覆盖问题**。
>
> 2、多线程下put remove操作修改结构时，**hashMap会抛出ConcurrentModificationException异常，而ConcurrentHashMap不会**。
>
> 使用建议：
>
> HashMap 单线程运行环境使用
>
> 多线程下使用同步或加锁  Collections 提供线程安全方法synchronizedMap
>
> 使用ConcurrentHashMap

> ==ConcurrentHashMap数据结构？==
>
> jdk1.7 
>
> ConcurrentHashMap维护了一个**Segment数组**，Segment这个类**继承了重入锁ReentrantLock**。
>
> 该类里面维护了一个 HashEntry<K,V>[] table数组，在写操作**put，remove，扩容的时候，会对Segment加锁**
>
> 所以解决了**线程的安全**问题，同时又采用了**分段锁也提升了并发的效率**
>
> jdk1.8
>
> **Node数组+链表+[红黑树](https://so.csdn.net/so/search?q=红黑树&spm=1001.2101.3001.7020)的数据结构来实现**，并发控制使用Synchronized和CAS



> ==死链问题==
>
> **多线程下，扩容的同一个链表**。
>
> 当线程一执行到e.next = new table[i] 的时候，由于线程二之前数据迁移的原因导致此时new table[i] 上就有ertry存在，所以线程一执行的时候，会将next节点，设置为自己，导致**自己互相使用next引用对方**，因此产生链表，导致死循环。
>
> 
>
> 解决
>
> - 使用synchronize
> - 使用collection.synchronizeXXX方法
> - 使用concurrentHashmap来解决。

> ==HashMap jdk1.7 jdk1.8区别？==
>
> 1、数据结构上   
>
> JDK1.7的时候使用的是**数组+ 单链表**的数据结构。**数组和链表节点的实现类是Entry类**
>
> JDK1.8及之后时，使用的是**数组+链表+红黑树**的数据结构（当**链表的深度达到8**的时候，也就是默认阈值，就会**自动扩容把**链表转成红黑树的数据结构来把时间复杂度从O（n）变成O（logN）提高了效率）。**数组和链表节点的实现类是Node类**
>
> 2、Hash值计算上 
>
> jdk1.7  9次扰动处理
>
> jdk1.8  2次扰动处理=1次位运算+1次异或
>
> 3、链表数据插入方法上
>
> jdk1.7 头插法
>
> jdk.1.8 尾插法
>
> 4、内部Entry类的实现
>
> jDK1.7数组和链表节点的实现类是**Entry类**，实现了Map.entry接口。
>
> JDK1.8数组和链表节点的实现类是**Node类**，但是**还是实现了Map.entry接口**

> ==hash实现==
> (h = key.hashCode())^ (h >>> 16);
> hash取值 = key的hashcode 与 hashcode右位移 16位进行一个异或。
> ==定位下标==
> (n - 1) & hash 这是一个与的操作。
> 如果不进行右移异或，直接用hashcode进行与，当数组很小时，参与 与操作的只是低位，如果hashcode低位变化小，容易产生冲突。右移16位其实就是讲hashcode高位和低位进行异或，加大低位的随机性，混合后的低位具有高位的特性，不易产生冲突)。效率也高。
> ==为什么大小是2的幂==
> (n - 1) & hash 和这个下标定位方式有关，n=2的n次幕时，n-1的二进制数据，呈现111111***111，就是高低位普遍都是1的形式，这样和hashcode与时，能够充分的散列)，每一位都能进行位运算，减少hash碰撞，元素够均匀散列在每个位置上。
> ==put实现==
> 1.调用hash函数计算key的hash值，然后计算下标(与数组长度-1进行与的运算)*
>
> 2。如果没有出现hash冲突，则直接放入数组，如果出现冲突，则以链表形式放在链表的后面
>
> 3.如果链表长度超多闻值8，则链表转为红黑树，链表长度低于6，则转回链表。
>
> 4.如果key已经存在，则替换value
> 5。如果集合中的键值对大于12了(数组长度*负载因子0.75)，进行resize扩容。
>
> ==扩容==
> 1.hashmap中元素个数超过数组大小*负载因子时，进行扩容，2倍扩容。
> 2，如果链表对象达到8个时，Node的数量没有到64，先进行扩容，如果到达64转为红黑树，节点Node类型变为treeNode类型，如果map元素被移除，导致树的节点数低于6，则再转回链表。
>
> 3，扩容的同时，伴随着rehash分配，但是(n-1)&hash 结果，只是多了一个Bit位，所以节点位置要么就在先位置，要么原位置+旧容量。
>
> ==为什么选用红黑树而不是二又查找树==
> 二叉查找树在特殊情况下会变成线性结构，跟原来的链表一样，遍历查找会比较慢。而红黑树在插入数据后，进行左旋、右旋、变色，保证平衡，查找比较快。
> ==底层数据结构==
> 1.8前数组+链表
> 1.8后数组+链表+红黑树
> ==concurrentHashMap==
> JDK 1.8 之前是采用分段锁来现实的 Segment + HashEntry， Segment 数组大小默认是 16，2的 n次节
> JDK 1.8 之后，采用 Node + CAS + Synchronized 来保证并发安全进行实现。

### semaphore

> 信号量，**用来限制同一时刻访问共享资源的线程上限**。
> 设置许可3个，5个线程来竞争。三个获取到许可进行处理。另外两个进入AQS队列park阻塞。thread0释放许可，thread4竞争成功，再次设置许可permits=0，同时unpark剩余线程进行竞争，由于许可为日，继续阻塞等待。

### countdownLatch

> 计数器，**允许多个线程阻塞在一个地方，直到所有线程执行完毕，再一起向下执行**。
> 用来协调线程同步协作 。 其中构造参数用来初始化等待计数值，await() 用 来等待计数归零，countDown()用来让计数减一。
> 人都走了，关门。
>
> ==共享锁的实现。==
> 默认构造AQS的state值为count,线程使用countDown方法时，本质是去调用tryReleaseShared去减少state的值，state=0代表所有线程都调用了countDown方法
>
> 当调用await方法时，发现state不为0，代表有线程未执行countDown方法，那么已经调用过countDown方法的线程会被放在阻塞队列里park，并自旋CAS判断是否state=0，直至最后的线程调用countDown方法state=0，则阻塞的线程判断成功，全部往下调用.

### cyclicsBarrier

> 循环栅栏，初始化时规定一个数目，每个线程执行到 某个需要”同步”的时刻,调用了CyclicBarrier.await()进入等待。当等待的线程数满足了初始计数个数]时，所有进入等待状 态的线程被唤醒并继续。人齐了出发的概念

### juc

> Abstract Queued Synchronized，AQS 抽象队列同步器是JUC包同步机制的基础设施，更是JUC锁框架的基础

> 内置锁和显式锁比较
>
> 限时抢锁 
>
> 可中断抢锁
>
> 多个等待队列：为锁维持多个等待队列，以便提高锁的效率
>
> Java对象锁还存在性能问题。在竞争稍微激烈的情况下，Java对象锁会膨胀为重量级锁（基于操作系统的Mutex Lock实现）

>  LockSupport.park()和 Thread.sleep()的区别
>
>  1）**Thread.sleep()没法从外部唤醒**，只能自己醒过来；而被LockSupport.park()方法阻塞的线程,可以通过调用LockSupport.unpark()方法去唤醒。
>  2）Thread.sleep()方法声明了InterruptedException中断异常，这是一个受检异常，调用者需要捕获这个异常或者再抛出；而使用LockSupport.park()方法时不需要捕获中断异常。
>  3）当被阻塞线程的**Thread.interrupt()方法调用时，LockSupport.park()方法不会抛出InterruptedException异常，仅仅设置了线程的中断标志**；而**Thread.sleep()方法还会抛出InterruptedException**异常。
>  4）与Thread.sleep()相比，调用LockSupport.park()能更精准、更加灵活地阻塞、唤醒指定线程。
>  5）Thread.sleep()本身就是一个原生（native）方法；LockSupport.park()并不是一个原生方法，只是调用了一个Unsafe类的原生方法（名字也叫park）去实现。
>
>  6)**LockSupport.park()方法还允许设置一个Blocker对象，主要用来供监视工具或诊断工具确定线程受阻塞的原因**

>  LockSupport.park()与 Object.wait()的区别
>
>  1)Object.wait()方法需要在synchronized块中执行，而LockSupport.park()可以在任意地方执行
>
>  2)当被阻塞线程中断时，Object.wait()方法抛出了中断异常，调用者需要捕获或者再抛出；当被阻塞线程中断时，LockSupport.park()不会抛出异常，调用时不需要处理中断异常。

> CLH锁其实就是一种是基于队列（具体为单向链表）排队的自旋锁，由于是Craig、Landin和Hagersten三人一起发明的，因此被命名为CLH锁，也叫CLH队列锁
>
> 简单的CLH锁可以基于单向链表实现，申请加锁的线程首先**会通过CAS操作在单向链表的尾部增加一个节点**，之后该线程只需要在其前驱节点上进行普通自旋，等待前驱节点释放锁即可.(`有没有点类似zookeeper的加锁watch机制 监听前一个小的节点，这里普通自旋也是看前驱节点有没有释放锁`)
>
> 加锁表示前驱节点lock 状态为false  可以加锁，解锁就是设置自身锁状态为false，后置节点就可以自旋获取到锁

> 非公平锁是指多个线程获取锁的顺序并不一定是其申请锁的顺序，**有可能后申请的线程比先申请的线程优先获取锁**，**抢锁成功的次序不一定体现为FIFO（先进先出）顺序**。非公平锁的优点在于**吞吐量比公平锁大**，其缺点是有可能会导致线程优先级反转或者线程饥饿现象。

> 死锁是指**两个或以上线程因抢占锁而造成的互相等待**的现象
>
> 线程X先后按照先后次序去抢占锁A与锁B，线程Y先后按照先后次序去抢占锁B与锁A

> **JVM管理工厂ManagementFactory类提供静态方法，返回各种获取JVM信息的Bean实例**。我们
> 通过这些Bean实例能获取大量的**JVM运行时信息，比如JVM堆的使用情况、GC情况、线程信息**、`死锁监测`等

> 共享锁就是在**同一时刻允许多个线程持有的锁**。当然，**获得共享锁的线程只能读取临界区数据，不能修改临界区的数据**。
>
> Semaphore（信号量）、ReadLock（读写锁）中的读锁、CountDownLatch倒数闩

> ReentrantReadWriteLock更适合于读多写少的场景（两把锁），可以提高并发读的效率；而ReentrantLock更适合于读写比例相差不大或写比读多的场景。

> StampedLock（印戳锁）是对ReentrantReadWriteLock读写锁的一种改进
>
> 主要的改进为：**在没有写只有读的场景下，StampedLock支持不用加读锁而是直接进行读操作**，最大程度提升读的效率，
> **只有在发生过写操作之后，再加读锁才能进行读操作**。

### AQS

> AbstractQuevedSynchronizer，是阻塞式锁和相关的同步器工具的框架。
>
> 用 state 属性来表示资源的状态(分独占模式和共享模式)，子类需要定义如何维护这个状态， 控制如何获取锁和释放锁
> getState  获取 state 状态 setstate -
> 设置 state 状态 compareAndSetState - cas 机制设置 state 状态

> AQS是CLH队列的一个变种   **模板模式**
>
> AQS队列`内部维护的是一个FIFO的双向链表`,**每个节点其实是由线程封装的**，当线程争抢锁失败后会封装成Node加入到AQS队列中去,释放锁以后，会从队列中唤醒一个阻塞的节点（线程)

> 1、AQS中维持了一个单一的volatile修饰的状态信息state
>
> 2、AbstractQueuedSynchronizer继承了AbstractOwnableSynchronizer，这个基类只有一个变量叫exclusiveOwnerThread，表示当前占用该锁的线程。（`是不是有点类似monitor的owner`）`其实就是java层面实现类jvm的monitor锁相关操作`
>
> 3、AQS的内部队列是CLH队列的变种，每当**线程通过AQS获取锁失败时，线程将被封装成一个Node节点，通过CAS原子操作插入队列尾部**。当有线程**释放锁时，AQS会尝试让队首的后驱节点占用锁**

> 显式锁与AQS之间是一种强依赖的聚合关系，如果显式锁的实例销毁，其聚合的AQS子类实例也被销毁，因此显式锁与AQS之间是组合关系
>
> ReentrantLock的显式锁操作是委托（或委派）给一个Sync内部类的实例完成的。
>
> 而**Sync内部类只是AQS的一个子类，**
>
> 所以**本质上ReentrantLock的显式锁操作是委托（或委派）给AQS完成的**。一个ReentrantLock对象的内部一定有一个AQS类型的组合实例，二
> 者之间是组合关系。

> **AQS抢占锁**
>
> 1、CAS操作state字段，成功获取到锁
>
> 2、失败，以当前线程构造Node节点，CAS自旋将节点添加到队列尾部。
>
> 3、当前Node节点在死循环中不断获取同步状态，并且不断在前驱节点上自旋，只有**当前驱节点是队首节点才能尝试获取锁**（队首节点的线程释放了同步状态以后，将会唤醒其后驱节点）（`自旋过程中会阻塞线程，等待前驱节点唤醒后才启动循环`）
>
> 4、**前驱节点是队首节点**并且**当前线程使用钩子方法tryAcquire(arg)获得了锁**，则移除队首节点，将当前节点设置为队首节点
>
> **AQS释放锁**
>
> 1、队首节点的状态变成初始状态，设置Owner为Null
>
> 2、唤醒后驱节点

> 非公平同步器ReentrantLock.NonfairSync的核心思想就是当前进程尝试获取锁的时候，**如果发现锁的状态位是0（也就是占用锁的节点释放锁了），就直接尝试将锁拿过来，然后执行setExclusiveOwnerThread()，根本不管同步队列中的排队节点**

> 公平抢占的钩子方法中，**首先判断是否有后驱节点，如果有后驱节点，并且当前线程不是锁的占有线程**，钩子方法就返回false，模板方法会**进入排队的执行流程**

> **await()方法的整体流程如下：**
>
> 1）执行await()时，会新**创建一个节点并放入到Condition队列尾部**。
> 2）然后**释放锁，并唤醒AQS同步队列中的队首节点的后一个节点**。
> 3）然后执行while循环，将该节点的线程阻塞，直到该节点离开等待队列，重新回到同步队列成为同步节点后，线程才退出while循环。
> 4）退出循环后，开始调用acquireQueued()不断尝试拿锁。
> 5）拿到锁后，会清空Condition队列中被取消的节点。

> **signal()方法的整体流程如下：**
> 1）通过enq()方法自旋，**将条件队列中的队首节点放入到AQS同步队列尾部**，**并获取它在AQS队列中的前驱节点**。
> 2）如果前驱节点的状态是取消状态，或者设置前驱节点为Signal状态失败，就唤醒当前节点的线程；否则节点在同步队列的尾部，参与排队。
> 3）同步队列中的线==程被唤醒==后，表示重新获取了显式锁，然后继续执行condition.await()语句后面的临界区代码。

> **节点入队的时机**
>
> 1、**调用tryAcquire(arg)尝试，如果不成功，则开始将线程加入等待队列**（加到尾部，存在竞争就CAS）
>
> 2、**Condition等待队列上的节点被signal()唤醒**，会通过enq(final Node node)**自旋入队，插入AQS的尾部**。

### monitor

> 监视器或者叫管程。thread0进入，synchronized 给对象上锁(重量级)，该对象与monitar对象关联，对象头的 Mark Word中就被设置为指向 Monitor 对象的指针。monitor此时owner为线程0，其余进入entryList阻塞

### 对象头

Mark Word  指向类的指针  数组长度

### mark word

> 无锁标记(hashcode、分代年龄、偏向锁标志)
>
> 偏向标记(偏向线程 id)
> 轻量级
> 重量级锁标记 (Monitor)
> GC标记

### 锁升级过程

> **偏向锁**:针对一个线程来说的，主要作用是优化(同一个线程多次获取一个锁的) 情况。当一个线程 执行了一个 synchronized 方法的时候，肯定能得到对象的 monitor ，加锁(**对象会在 Mark Wor处设为偏向锁标记**，同时(一个字段指向拥有锁的这个线程的线程 ID。当这个线程再 次访问同一个 synconized 方法的时候，会检查这个对象的 Mark word 的偏向锁标记，再判断下这个字段记录的线程 ID 是不是跟第二个线程的 ID 是否相同的，如果相同，就无需再获取 monitor 了，直接入方法体中
>
> 1）线程抢锁时，JVM**首先检测内置锁对象Mark Word中biased_lock（偏向锁标识）**是否设置成1，lock（锁标志位）是否为01，如果都满足，确认内置锁对象为可偏向状态。
> 2）在内置锁对象确认为可偏向状态之后，JVM检查Mark Word中线程ID是否为抢锁线程ID，**如果是，就表示抢锁线程处于偏向锁状态**，抢锁线程快速**获得锁，开始执行临界区代码**。
> 3）如果Mark Word中**线程ID并未指向抢锁线程，就通过CAS操作竞争锁**。如果**竞争成功，就将Mark Word中线程ID设置为抢锁线程**，偏向标志位设置为1，锁标志位设置为01，然后执行临界区代码，此时内置锁对象处于偏向锁状态。
> 4）如果CAS操作**竞争失败**，就说明发生了竞争，撤销偏向锁，进而**升级为轻量级锁**。
> 5）JVM使用**CAS将锁对象的Mark Word替换为抢锁线程的锁记录lockrecord指针**，如果**成功，抢锁线程就获得锁**。如果替**换失败**，就表示其他线程竞争锁，JVM**尝试使用CAS`自旋`替换抢锁线程的锁记录**指针，如果自旋成功（抢锁成功），那么锁对象依然处于轻量级锁状态。
> 6）如果JVM的CAS替换锁记录指针**自旋失败，轻量级锁膨胀为重量级锁**，后面等待锁的线程也要进入阻塞状态，**进入EntryList等待执行**

### 线程池

> 1，线程池中刚开始没有线程，当一个任务提交给线程池后，线程池会创建一个新线程来执行任 务。
>
> 2，当线程数达到 corePoolSize 并没有线程空闲，这时再加入任务，新加的任务会被加入 workQueue 队列排 队，直到有空闲的线程。
> 3.如果队列选择了有界队列，那么任务超过了队列大小时，会创建 maximumPoolSize - corePooLSize 数目的线 程来救急。
>
> 4，如果线程到达 maximumPoolSize 仍然有新任务这时会执行拒绝策略

> 什么是进程呢?简单来说，进程是程序的一次启动执行。
> 什么是程序呢?程序是存放在硬盘中的可执行文件，主要包括代码指令和数据。
> 一个进程是一个程序的一次启动和执行，是操作系统将程序装入内存，给程序分配必要的系统资源，并且开始运行程序的指令。
>
> 进程与程序是什么关系呢?同一个程序可以多次启动，对应多个进程。比如，多次打开Chrome浏览器程序，在Process Explorer中可以看到多个Chrome浏览器进程。
>
> Java编写的程序都运行在Java虚拟机 (JVM)中，**每当使用Java命令启动一个Java应用程序时，就会启动一个JVM进程**。在这个JVM进程内部，所有Java程序代码都是以线程来运行的。JVM找到程序的入口点main()方然后运行main()方法，这样就产生了一个线程，这个线程称为主线程。当main()方法结束后，主线程运行完JVM进程也随即退出

> **BLOCKED 状态**
> (1)线程等待获取一个锁，而该锁被其他线程持有，则该线程进入阻塞状态。当其他线程释放了该锁，并且线程调度器允许该线程持有该锁时，该线程退出阻塞状
>
> (2) I0阻线程发起了一个阻式I0作后，如果不备操作的条件，线程就会进入阻塞状态。I0包括磁盘I0、网络I0等。I0阻塞的一个简单例子: 线程等待用户输入内容后继续执行
>
> **WAITING 状态**
> 0bject.wait()方法，对应的唤醒方式为: 0bject.notify() / 0bject,notifyAll()。
> Thread.join()方法，对应的唤醒方式为: 被合入的线程执行完毕。
> LockSupport.park()方法，对应的唤醒方式为: LockSupport.unpark(Thread)。
>
> **进入BLOCKED状态、WAITING状态、TIMED_WAITING状态的线程都会让出CPU的使用权**

> 线程池任务被拒绝
>
> 1) 线程池已经被关闭。
> 2) 工作队列已满且maximumPoolSize已满。

> **线程池状态**
>
> 1)RUNNING: 线程池创建之后的初始状态，这种状态下可以执行任务。
> 2)SHUTDOVIN: 该状态下线程池不再接受新任务，但是会将工作队列中的任务执行完毕。
> 3)STOP:该状态下线程池不再接受新任务，也不会处理工作队列中的剩余任务，并且将会中断所有工作线程
> 4)TIDYING: 该状态下所有任务都已终止或者处理完成，将会执行terminated()钩子方法。
> 5)TERMINATED: 执行完terminated()钩子方法之后的状态。

> **线程池的状态转换规则为:**
> 1)线程池创建之后状态为RUNNING。
> 2)执行线程池的shutdown实例方法，会使线程池状态从RUNNING转变为SHUTDOWN。此方法会**等待当前工队列中的剩余任务全部执行完成之后才会执行关闭**，但是此方法被调用之后线程池的状态转变为SHUTDOWN，线池不会再接收新的任务
> 3)执行线程池的shutdownNow()实例方法，会使线程池状态从RUNNING转变为STOP。此方法会打断正在执行的工作线程，并且会清空当前工作队列中的剩余任务，**返回的是尚未执行的任务**。
> 4)当线程池处于SHUTDOVN状态，执行其shutdownNow()方法会将其状态转变为STOP。
> 5)等待线程池的所有工作线程停止，工作队列清空之后，线程池状态会从STOP转变为TIDYING。
> 6)执行完terminated()钩子方法之后，线程池状态从TIDYING转变为TERMINATED。

> **awaitTermination**
>
> 等待线程池完成关闭。在调用线程池的shutdown()与shutdownNow()方法时，当前线程会立即返回，不会一直等待直到线程池完成关闭。如果需要等到线程池关闭完成，可以调用awaitTermination()方法

> (1)FixedThreadPool和SingleThreadPooL 这两个工厂方法所创建的线程池，**工作队列(任务排队的队列)长度都为Integer,MAX_VALUE，可能会堆积大量的任务，从而导致00M (即耗尽内存资源)**。
>
> (2) CachedThreadPoo 和ScheduledThreadPool 这两个工厂方法所创建的**线程池允许创建的线程数量为Integer.MAX_VALUE，可能会导致创建大量的线程**，从而导致00M问题。

> 最佳线程数目 = (线程等时间与线程CPU时间之比 + 1) *CPU核数
>
> 通过公式可以看出: 
>
> **等待时间所占比例越高，需要的线程就越多**
>
> **CPU耗时所占比例越高，需要的线程就越少。**
>
> 下面举一个例子:比如在Web服务器处理HTTP请求时，假设平均线程CPU运行时间为100毫秒，而线程等待时间(比如包括DB操作、RPC操作、缓存操作等)为900毫秒，如果CPU核数为8，那么根据上面这个公式，估算如下(900ms+100ms) /100ms 8= 10 8 = 80

### ThreadLocal

> **ThreadLocal使用场景**
>
> 1、ThreadLocal的主要价值在于**线程隔离，提升了并发性的性能**。数据库连接独享、Session数据管理等
>
> 2、**跨函数传递数据**。同一个线程内，跨类、跨方法传递数据时，如果不用ThreadLocaL，那么相互之间的数据传递势必要靠返回值和参数，这样无形之中增加了这些类或者方法之间的耦合度。 (可以为每个线程绑定一个Session(用户会话)信息，这样一个线程所有调用到的代码都可以非常方便地访问这个本地会话，而不需要通过参数传递)

> 与早期版本的ThreadLocalMap实现相比，**新版本的主要变化**为:
> 1)拥有者发生了变化: **新版本的ThreadLocaMap拥有者为Thread(优势2)**，早期版本的ThreadLocalMap拥有者为ThreadLocal。
>
> 2)Key发生了变化: **新版本的Key为ThreadLocal实例(优势1)**，早期版本的Key为Thread实例。与早期版本的ThreadLocalMap实现相比,
> **新版本的主要优势为**
>
> 1)每个ThreadLocalMap存储的“Key-Value对"数量变少。早期版本的“KeyValue对”数量与线程个数强关联，若线程数量多，则ThreadLocalMap存储”Key-Value对”数量也多，**新版本的ThreadLocalMap的Key为ThreadLocal实例，多线程情况下ThreadLocal实例比线程数少。**
>
> 2)早期版本ThreadLocalMap的拥有者为ThreadLocal，在Thread (线程)实例被销毁后ThreadLocalMap还是存在的; **新版本的ThreadLocalMap的拥有者为Thread，现在当Thread实例被销毁后ThreadLocaLMap也会随之被销毁，在一定程度上能减少内存的消耗**

> ThreadLocalMap发生hash冲突，使用开放定址法找后面空的位置

> 由于ThreadLocalMap中Entry的Key使用了弱引用，在下次**GC发生时，就可以使那些没有被其他强引用指向、仅被Entry的Key所指向的ThreadLocal实例能被顺利回收**，并且，在Entry的Key引用被回收之后，其Entry的Key值变为null。后续**当ThreadLocal的get()、set()或remove()被调用时，ThreadLocalMap的内部代会清除这些Key为null的Entry，从而完成相应的内存释放**
>
> **如果是强引用的话，如果方法栈桢使用ThreadLocal，执行结束，ThreadLocal理应被释放，但是由于内部ThreadLocaLMap的key强引用ThreadLocal导致，无法被释放，容易造成内**存泄漏。

### cas&juc

> public final native boolean compareAndSwapObject(Object o, long offset,Objectexpected,0bject update);
>
> Unsafe提供的CAS方法包含4个操作数-一字段所处的对象、字段内存位置、预期原值及新值。
>
> 在执行Unsafe的CAS方法时，这些方法首先**将内存位置的值与预期值(旧的值)比较**，如果相匹配，那么处理器会自动将该内存置的值更新为新值，并返回true; 如果不匹配，处理器不做任何操作，并返回false。
>
> **Unsafe的CAS操作会将第一个参数(对象的指针、地址) 与第二个参数(字段偏移量,这个是相对偏移量，从对象头markworld+kclass后算)组合在一起，计算出最终的内存操作地址**

> **引用原子类 引用原子类主要包括以下三个**
> AtomicReference: 引用类型原子类。
> AtomicMarkableReference: 带有更新标记位的原子引用类型。 类似 数据库更新加了版本号的概念
>
> AtomicStampedReference: 带有更新版本号的原子引用类型。 类似状态位概念 只有 true false
>
> AtomicMarkableReference类将boolean标记与引用关联起来，可以解决使用AtomicBoolean进行原子方式的更新时可能出现的ABA问题
> AtomicstampedReference类将整数值与引用关联起来，可以解决使用AtomicInteger进行原子方式的更新时可能出现的ABA问题。

> **LongAdder**
>
> 基本思路就是**分散热点，将value值分散到一个数组中，不同线程会命中到数组的不同槽(元素)中，各个线程只对自己槽中的那个值进行CAS操作**
>
> LongAdder继承于Striped64类，Striped64内部包含一个base和一个CelL[]类型的ceLLs数组，ceLLs数组又叫哈希表。在**没有竞争的情况**下，要累加的数通过**CAS累加到base**上; 如果**有竞争的话，会将要累加的数累加到CelLs数组中的某个ceLL元素里面**。所以striped64的整体值value =base+∑[0~n]cells

> **Copy0nWirite(写时复制)**
> 就是在修改器对一块内存进行修改时，不直接在原有内存块上进行写操作，而是将内存复制一份，在新的内存中进行写操作，写完之后，**再将原来的指针(或者引用)指向新的内存**，原来的内存被回收
>
> 读取操作没有任何同步控制和锁操作，读取的是操作内存
> add()方法在执行时加了独占锁，底层都是重新复制了一份数组，再往新的数组中添加新元素，待添加完了，再将新的array引用指向新的数组。
> Copy0nyriteArrayList和ReentrantReadWriteLock读写锁的思想非常类似，即读读共享、写写互斥、读互斥、写读互斥。但是前者相比后者更进一步: 为了将读取的性能发挥到极致，Copy0nWriteArrayList**读取是完全不用加锁的，而且写入也不会阻塞读取操**作，只有写入和写入之间需要进行同步等待，于是读操作的性能得至大幅度提升

> //初始化单例 instance = new Singleton();
> 这行初始化单例代码转换成了汇编指令 (具有原子性的指令)后，大致会细分成三个:
> 1)分配一块内存M。
> 2)在内存M上初始化singleton对象。
> 3)M的地址赋值给instance变量。
>
> 编译器、CPU都可能对没有内存屏障、数据依赖关系的操作进行重排序，上述的三个指令优化后可能就变成了这
> 1)分配一块内存M
> 2)将M的地址赋值给instance变量。
> 3)在内存M上初始化Singleton对象。
> **静态内部类实例懒汉单例模式**只有在getInstance()被调用时才去加载内部类并且初始化单例，该方式既解决了线程安全问题，又解决了写法烦琐问题。**线程安全主要是静态内部类加载时，jvm虚拟机会保证线程安全，只加载一次，cinit方法**

> **ForkJoin框架的核心原理**:
>
> 1) ForkJoin框架的线程池ForkJoinPool的任务分为“外部任务”和“内部任务”。
> 2)“外部任务”是放在ForkJonPool的全局队列中。
>
> 2) ForkJoinPool池中的每个线程都维护着一个任务队列用于存放”内部任务”，线程切割任务得到的子任务就会作为“内部任务”放到内部队列中。
>
> 4)当工作线程想要拿到子任务的计算结果时，先判断子任务有没有完成，如果没有完成，再判断子任务有没有被其他线程“窃取”，如果子任务没有被窃取，就由本线程来完成;一旦子任务被窃取了，就去执行本线程“内部队列的其他任务，或者去扫描其他的任务队列并窃取任务。
>
> 5)当工作线程完成其“内部任务”，处于空闲的状态时，就会扫描其他的任务队列窃取任务，尽可能不会阻塞等
>
> **窃取算法: 简单来说，获取自己队列的任务时从头开始，窃取其他队列的任务时从尾开始**

### CAS

> **弊端和规避措施**
>
> 1、ABA问题: 使用版本号 JDK提供了两个类AtomicStampedReference(印戳方式，类似数据库更新version)和AtomicMarkableReference（状态位方式 true false ）来解决ABA问题
>
> 2、只能保证一个共享变量之间的原子性操作 ：对多个共享变量操作时，**CAS无法保证操作的原子性  把多个共享变量合并成一个共享变量来操作** 比如AtomicReference
>
> 3、无效CAS会带来开销问题
>
> 4、部分CPU平台上存在“总线风暴”问题
>
> CAS操作和volatile一样也需要CPU进行通过**MESI协议各个内核的“Cache一致性”**，**会通过**
> **CPU的BUS（总线）发送大量MESI协议相关的消息，产生“Cache一致性流量”**。因为总线被设计
> 为固定的“通信能力”，如果Cache一致性流量过大，总线将成为瓶颈，这就是所谓的“总线风暴”
>
> **提升 CAS 性能**
>
> `方式一：以空间换时间，分散竞争热点`
>
> 1、**分散操作热点**，使用LongAdder替代基础原子类AtomicLong，LongAdder将单个CAS热点（value值）分散到一个cells数组中
>
> 2、使用**队列削峰**，将发生CAS争用的线程加入一个队列中排队
>
> `方式二是使用线程本地变量，从根本上避免竞争`

### 可见性与有序性原理

> **原子性**
>
> 指不会被线程调度机制打断的操作，中间不会有任何线程的切换。
>
> sum++
>
> ① 获取当前sum变量的值，并且放入栈顶。
> ② 将常量1放入栈顶。
> ③ 将当前栈顶中两个值（sum的值和1）相加，并把结果放入栈顶。
> ④ 把栈顶的结果再赋值给sum变量。



> **可见性**
>
> 一个线程对**共享变量的修改**，另一个线程能够立刻可见，我们称为**该共享变量具备内存可见性**
>
> 由于每个线程可能会运行在不同的CPU内核中，因此**每个线程拥有自己的高速缓存**。**同一份数据可能会被缓存到多个CPU内核中，在不同CPU内核中运行的线程看到同一个变量的缓存值就会不一样，就会存在内存的可见性问题**
>
> 为了解决内存的可见性问题，CPU主要提供了两种解决办法：`总线锁和缓存锁`。
>
> **`总线锁**
>
> 前端总线（也叫CPU总线）是**所有CPU与芯片组连接的主干道**，负责CPU与外界所有部件的通信，包括高速缓存、内存、北桥，其控制总线向各个部件发送
> 控制信号、通过地址总线发送地址信号指定其要访问的部件、通过数据总线双向传输。
>
> **某一个CPU访问主存时，总线锁把CPU和主存的通信给锁住了，其他CPU不能操作其他内存地址的数据**
>
> **缓存锁**
>
> 每个CPU通过嗅探在总线上传播的数据来检查自己高速缓存中的值是否过期，**当CPU发现自己缓存行对应的内存地址被修改时，就会将当前CPU的缓存行设置成无效状态**，当CPU对这个数据进行修改操作时，会**重新从系统主存中把数据读到CPU的高速缓存中**
>
> CPU对高速缓存副本如何与主存内容保持一致有几种写入方式供选择，主要的写入方式有以下两种：
>
> Write-Through（直写）模式  数据修改之后需要同时写入低一级的高速缓存和主存
>
> Write-Back（回写）模式  只写入高速缓存。只在**数据被替换出高速缓存或者变成共享（S）状态时**，如果发现数据有变动，才会将最新的数据更
> 新到主存。

> 缓存一致性协议为**MESI写入失效协议**
>
> Modified、Exclusive、Share、Invalid
>
> M 处于Modified状态的缓存行数据，只有在本CPU中有缓存，且其**数据与主存中的数据不一致，数据被修改过**
>
> E 处于Exclusive状态的缓存行数据**只在本CPU中有缓存，且其数据与主存中一致**，**没有被修改过。**
>
> S 处于Shared状态的缓存行的数据在**多个CPU中都有缓存，且与主存一致**。
>
> I 该缓存行是无效的，可能有其他CPU修改了该缓存行。

> Store Buffer 
>
> 用于临时存放没有收到失效Ack（确认）的写入结果
>
> **本地内核将不再需要等待其他内核的响应结果**，只需要把修改的数据临时**写入到Store Buffer**，然后给其他CPU内核发送失效请求；接下来本地内核即可去执行其他指令。**当收到其他内核的失效Ack（响应结果）后，本地内核再把Store Buffer中的数据写入本地缓存行****，并
> 把缓存行状态修改为Modified。
>
> Invalidate Queue
>
> **用于临时存放接收到的失效请求（Invalidate Request**），一旦失效请求进入队列之后，缓存失效方立即进行Ack回复，而不是在执行完成缓存失效操作才进行回复
>
> `Store Buffer是属于缓存写入方（修改数据方）的异步优化措施，而Invalidate Queue可以理解为缓存失效方（失效请求的接收方）的异步优化措施`

> **JMM**
> 将所有的变量都存放在公共主内存中，当线程使用变量时会把主存中的变量复制到自己的工作空间（或者叫作私有内存）中，线程对变量的读写操作，是自己工作内存中的变量副本。
>
> **有序性**
>
> 所谓的程序的有序性，是指程序执行的顺序按照代码的先后顺序执行。如果**程序执行的顺序与代码的先后顺序不同，并导致了错误的结果，即发生了有序性问题**
>
> 

> volatile汇编指令
>
> 汇编指令中，volatile var之前多出一个lock前缀指令`lock addl`
>
> 这个lock的作用就是上面说的总线锁和缓存锁，新版CPU（如IA-32、Intel 64）通过**缓存锁实现对共享内存的独占性访问**，缓存锁（缓存一致性协议）**会阻止两个CPU同时修改共享内存的数据**
>
> 1、**将当前CPU缓存行的数据立即写回系统主存**
>
> 2、lock前缀指令会引起在**其他CPU中缓存了该内存地址的数据无效**  **以上缓存锁的描述**
>
> 3、lock前缀指令的最后一个作用是作为**内存屏障（Memory Barrier）使用，可以禁止指令重排序**，  `硬件层面`
>
> 编译器层面就是保证从主存读取最新值覆盖副本值，每次对变量的改变都会立即同步到主存中

> As-if-Serial规则的具体内容为：不管如何重排序，都必须保证代码在单线程下运行正确。**只能保障单内核指令重排序之后的执行结果正确**，不能保障多内核以及跨CPU指令重排序之后的执行结果正确

> Happens-Before（先行发生）规则，并且确保**只要两个Java语句之间必须存在Happens-Before关系**，JMM尽量确保这两个Java语句之间的内存可见性和指令有序性
>
> 1）程序顺序执行规则（as-if-serial规则）
>
> 2）volatile变量规则   对volatile（修饰的）变量的写操作必须先行发生于对volatile变量的读操作
>
> 3）传递性规则 如果A操作先行发生于B操作，而B操作又先行发生于C操作，那么A操作先行发生于C操作
>
> 4）监视锁规则（Monitor Lock Rule） 对一个监视锁的解锁操作先行发生于后续对这个监视锁的加锁操作
>
> 5）start规则 如果线程A执行 B.start()启动线程B，那么线程A的B.start()操作先行发生于线程B中的任意操作。
>
> 6）join规则   如果线程A执行了B.join()操作并成功返回 B中的任意操作肯定已经发生了

### 红黑树相关

> BST 二叉查找树
>
> 1. 左子树上所有结点的值均小于或等于它的根结点的值.
> 2. 右子树上所有结点的值均大于或等于它的根结点的值.
> 3. 左、右子树也分别为二叉排序树。
> 4. 退化为链表后，时间复度O(n)

> AVL 平衡二树
>
> 1、对于任何一颗子树的root根结点而言，它的左子树任何节点的key一定比root小，而右子树任何节点的key一定比root大 (和BST一致，本身就是一棵BST)
> 2、对于AVL树而言，其中任何子树仍然是AVL树
> 3、**每个节点的左右子节点的高度之差的绝对值最多为1** (插入删除的时候，会自平衡)
> AVL树，**本质上是带了平衡功能的二叉查找树**(二叉排序树，二叉搜索树)。

> **RBTree 红黑树**
> -红黑树也是一种自平衡二叉查找树，与AVL树相比，红黑树牲了部分平衡性，以换取插入/删除操作时较少的旋转操作，整体来说性能要优 于AVL树。
> -在0(logn)时间内做查找,插入和删除
> (颜色属性) 性质1: 节点非黑即红 
>
> (根属性)性质2: **根节点一定是黑色**
> (叶子属性) 性质3: **叶子节点《NIL) 一定是黑色**
> (红色属性)性质4:**每个红色节点的两个子节点，都为黑色**。(从每个叶子到根的所有路径上不能 有两个连续的红色节点)
> (黑色属性)性质5: **从任一节点到其每个叶子的所有路径，都包含相同数目的黑色节点**。

> **红黑树与AVL树区别**
> 1、调整平衡的实现机制不同
> 红黑树根据路径上黑色节点数目一致，来确定是否失衡，如果失衡，就通过变色和旋转来恢复
> AVL根据树的平衡因子(所有节点的左右子树高度差的绝对值不超过1)，来确定是否失衡，如果失衡，就 通过旋转来恢复
> 2、红黑树的插入效率更高
> 红黑树并不追求”完全平衡”，它只要求部分地达到平衡要求，降低了对旋转的要求
> 红黑树能够以0(log n) 的时间复度进行查询、插入、删除操作
> 3、红黑树统计性能比AVL树更高
> AVL树查找、插入和删除在平均和最坏情况下都是0(n)。
> 4、适用性: AVL查找效率高

### JVM

> ==即时编译==
> 将一些字节码编译为机器码，并存入 Code Cache，下次遇到相同的代码，直接执行，无需 再编译

> ==类加载过程==
> 加载-连接-初始化-使用-销毁
> 1，将类的(字节码文件装载进方法区)，1.8后也就是元空间，并且内存中生成一个 class对象和方法区的class文件互相保存了各自的地址用于访问。
>
> 2.**连接分为验证、准备、解析**
>
> 验证就是验证类是否符合ivm规范
>
> 准备就是对静态变量分配空间和赋值(如果是final 基本类型 直接赋值) 不是final的或者是final 但是是引用类型的，初始化的赋值
>
> 解析就是将常量池中的符号引用 替换为直接引用
> 3.初始化 是执行初始化方法 cinit()方法的过程
> main 方法所在的类，总会被首先初始化
> 首次访问这个类的静态变量或静态方法时
> 子类初始化，如果父类还没初始化，会引发
> 子类访问父类的静态变量，只会触发父类的初始化
> Class.forName
> new 会导致初始化
> 4.卸载自定义的加载器可能被卸载，jdk自带的不会
> 该类的所有的实例对象都已被GC，也就是说堆不存在该类的实例对象。
> 该类没有在其他任何地方被引用。
> 该类的类加载器的实例已被GC

> ==完整的对象分配流程==
>
> 1、首先Eden 区，满了， 触发一次 Minor GC 存活下来的对象，则会转移到 Survivor**区**
>
> 2、**大对象**（需要**大量连续内存空间的Java对象**，如那种很长的字符串）**直接进入老年代**
>
> 3、Survivor中长期存活的对象进入老年代(年龄超过一定限制（15))
>
> 4、老年代满了而无法容纳更多的对象，Minor GC 之后通常就会进行Full GC，Full GC 清理整个内存堆 – 包括年轻代和年老代。

> ==JVM调优方案==
>
> 1. 调优时机： 
>    a. **heap内存（老年代）持续上涨**，达到设置的最大内存值； 
>    b. **Full GC 次数频繁**； 
>    c. **GC 停顿时间过长（超过1秒**）； 
>    d. **应用出现OutOfMemory 等内存异常**； 
>    e. 应用中有使用本地缓存，且**占用大量内存空间**； 
>    f. 系统吞吐量与响应性能不高或下降。
> 2. 调优原则：
>    a. 多数的Java应用不需要在服务器上进行JVM优化； 
>    b. 多数导致GC问题的Java应用，都不是因为我们参数设置错误，而是代码问题； 
>    c. 在**应用上线之前，先考虑将机器的JVM参数设置到最优**（最适合）； 
>    d. ==**减少创建对象的数量**==； 
>    e. **减少使用全局变量和大对象**； 
>    f. JVM优化，是到最后不得已才采用的⼿段； 
>    g. 在实际使用中，**分析GC情况优化代码**比优化JVM参数更好；
> 3. 调优目标： 
>    a. GC低停顿； 
>    b. GC低频率； 
>    c. 低内存占用； 
>    d. 高吞吐量；
>
>
> 4. 调优步骤： 
>    a. **分析GC⽇志及dump⽂件，判断是否需要优化**，确定瓶颈问题点； 
>    b. 确定jvm调优量化目标； 
>    c. **确定jvm调优参数**（根据历史jvm参数来调整）； 
>    d. **调优⼀台服务器，对比观察调优前后的差异**； 
>    e. 不断的分析和调整，知道找到合适的jvm参数配置； 
>    f. 找到最合适的参数，将这些参数应用到所有服务器，并进行后续跟踪

> ==如何排查JVM问题==
>
> **对于还在正常运行的系统：**
>
> 1. 可以使用**jmap来查看JVM中各个区域的使用情况**
> 2. 可以通过**jstack来查看线程的运行情况**，比如哪些线程阻塞、 是否出现了死锁
> 3. 可以通过**jstat命令来查看垃圾回收的情况**，特别是fullgc，如果发现fullgc比较频繁，那么就得进行
>    调优了
> 4. 通过各个命令的结果，或者jvisualvm等⼯具来进行分析
> 5. ⾸先，初步猜测频繁发送fullgc的原因，如果**频繁发⽣fullgc但是⼜⼀直没有出现内存溢出**，那么**表**
>    **示 fullgc实际上是回收了很多对象**了，所以这些对象最好能在younggc过程中就直接回收掉，避免这些对象进⼊到老年代，对于这种情况，就要考虑这些存活时间不⻓的对象是不是比较大，导致年轻代放不下，直接进⼊到了老年代，**尝试加大年轻代的大⼩，如果改完之后，fullgc减少，则证明**
>    **修改有效**
> 6. 同时，还可以**找到占用CPU最多的线程，定位到具体的方法，优化这个方法的执行**，看是否能避免某些对象的创建，从而节省内存
>
> **对于已经发⽣了OOM的系统：**
>
> 1. ⼀般⽣产系统中都会设置当系统发⽣了OOM时，⽣成当时的dump⽂件（- 
>    **XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/base**）
> 2. 我们可以利用jsisualvm等⼯具来**分析dump⽂件**
> 3. 根据dump⽂件找到异常的实例

> ==GCR0TS==
> 虚拟机栈(栈帧中的本地变量表》 中引用的对象。
> 方法区中类静态属性引用的对象
> 方法区中常量引用的对象
> 本地方法栈中 JNI (即一般说的Native方法) 引用的对象



## 方案篇

> ==高并发设计方向？==
>
> 1、系统拆分   微服务解耦，每个系统连一个数据库。
> 2、缓存          读多写少场景，保证db与cache的一致性就ok
> 3、MQ           写高并发的场景，必须得用 MQ
> 4、分库分表
> 5、读写分离    读从库，写主库，能容忍解决数据的同步延迟的问题
> 6、ElasticSearch   全文搜索类

> ==幂等性==
>
> 场景: 表单重复提交、接口非法调用、失败重试、重复消息
>
> 前端解决
>
> 1、按钮置灰
>
> 2、提交后重定向新的提示页面，避免刷新，回退，用户需要再进行录入
> 后端解决
> 1.唯-KEY方案 redis set key nx px 成功 代表已经第一次 失败，不操作
> 2 防重表方案 唯一索引 单独的防重表
> 3.状态机表增加状态字 有一个 变换 1 2 3  更新某一次的时候，状态 是前一个 update set status =2 where status =1
> 4、数据库乐观锁 加version或者表字段唯一索引限制
>
> 5.token方案进入表单，去后端申请token，放入redis,同时返回给前端存储cookie 或者变量中
>
> 表单提交时，header携带token，后端先尝试删除，删除成功则代表第一次，否则代表之前已经制除过，属于重复请求
>
> 6、分布式锁

## 算法&协议篇

> ==限流算法==
> **计数器限流**
> 比如规定10分钟内，调用接口的频率不允许超过3次
> redis.incr命令 结合 同时redis的key比如“INTERFACE_用户ID "就是操作标识+用户ID   key设置过期时间10分钟
> <u>解决不了临界问题，10分钟前后都调用3次，超过上限</u>
> **时间窗口限流方案**
> 解决临界问题，计数器其实是一种固定窗口方案。将时间窗划分出来多个时间窗口，每个窗口有独立的计数器。并且每个窗口被分为多个单位，比如600s一个窗口窗口分为200s一个单位，每过200向后滑动。 当在窗口后调用时，其实已经滑动了一个小的单位，这个窗口范围就变化了。
> 时间单位格子划分的越小，滑动越平缓，统计越精确。
> **令牌桶方案**
> 1。初始化令牌桶，设置最大令牌数，当桶内的令牌达到阈值时，拒绝新加的令牌或者丢弃。
> 2.根据限流大小，启动一个线程，按一定速率向令牌桶中不断增加新的令牌。
> 3。任何处于限流访问的请求，都需要获取到一个可用令牌，再处理。
> 4。获取到令牌时，执行，执行完成，从桶内移除令牌。
> 5，桶也会设置最小阈值。桶内令牌数低于最小阈值时，不会移除，会还给桶。
> **漏桶方案**
> 请求进入的速率大于漏桶下方的处理速率时，多出来的请求放入桶中等待，当阻塞超过最大限制时，丢弃或拒绝.
>
> 宽进严出

## 理论篇

> ==微服务理解？==
>
> 微服务把各个模块 拆分成不同的项目，每个模块都只关注一个特定的业务功能，发布时每一个项目都是一个独立的包，运行在独立的进程上。
> 优点:
> 解耦大的业务板块，可维护性高。
> 服务可以独立部署，风险降低
> 服务自身，易于扩展，技术栈也不受限制，通过轻量通信机制通信
> 缺点:
> 服务增多，运维要求高
> 分布式固有的复杂性，比如容错，存在服务调用了、数据一致性、通信成本、监控
> 接口修改成本高，需要排查影响范围
> 重复代码，功能

> ==微服务设计原则==
> **AKF划分原则** ，旨在提供一个系统化的扩展思路
> X轴:直接水平复制应用进程来扩展系统。(无状态服务，集群) 无法解决数据增长带来的压力
> Y 轴: 将功能拆分出来扩展系统(分库分表、引入缓存)。
> z 轴: 基于用户信息扩展系统(比如分地域，本质是拆分用户数据，用户路由至不同的数据库中)。
> **前后端分离**
> **高内聚、低糊合**
> **服务自身符合开闭原则，更改只影响自身**

> ==负载均衡的意义==
> 负载平衡旨在优化资源使用，最大化吞吐量，最小化响应时间并避免任何单一 资源的过载.

> ==微服务之间如何通信?==
> 同步进行远程过程调用，(RPC REST,服务注册和发现，直接调用远程服务)
> 使用异步消息来做服务间通信。服务间通过消息管道来交换消息，从而通信(消息队列)

## spring篇

> IOC/DI

> AOP 静态代理 动态代理 cglib jdk

> 循环循赖
> setter注入 入 三级缓存实现 singtonobjects earlysingtonobjects singtonFactories

> @trancsactional实现细节

> 事务传播级别

> ==(BeanFactory 和 ApplicationContext有什么区别?==
>
> 从依赖关系看
> BeanFactory: 是Spring里面最底层的接口，包含了各种Bean的定义，读取bean配置文档，管理bean的加载、实例化，控制bean的生命周期，维护bean之间的依赖关系。ApplicationContext接口作为BeanFactory的派生，除了提供BeanFactory所具有的功能外，还提供了 更完整的框架功能:
> 继承MessageSource，因此支持国际化
>
> 统一的资源文件访问方式。
> 提供在监听器中注册bean的事件。
> 同时加载多个配置文件。 载入多个 (有继承关系)上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web 层。
>
> 从加载方式看
> BeanFactroy采用的是延迟加载形式来注入Bean的，即只有在使用到某个Bean时(调用getBean())，才 对该Bean进行加载实例化。
> ApplicationContext，它是在容器启动时，一次性创建了所有的Bean
>
> ==ApplicationContext通常的实现是什么?==
> FileSystemXmlApplicationContext : 此容器从一个XML文件中加载beans的定义，XML Bean 配置 文件的全路径名必须提供给它的构造函数
> ClassPathXmLApplicationContext: 此容器也从一个XML文件中加载beans的定义，这里，你需要正确设置classpath因为这个容器将在classpath里找bean配置WebXmLApplicationContext: 此容器加载一个XML文件，此文件定义了一个WEB应用的所有bean.
> ==@Autowired注解自动装配的过程是怎样的?==
> 在启动spring IoC时，容器自动装载了一个AutowiredAnnotationBeanPostProcessor后置处
> 当 容器扫描到@Autowied、 @Resource或@Inject时，就会在IoC容器自动查找需要的bean，并装配给该对象的属性。
> 在使用@Autowired时，首先在容器中查询对应类型的bean:
> 如果查询结果刚好为一个，就将该bean装配给@Autowired指定的数据
> 如果查询的结果不止一个，那么@Autowired会根据名称来查找;
> 如果上述查找的结果为空，那么会抛出异常。解决方法时，使用required=false。

## springboot篇

> ==优势&介绍==
>
> springboot 使用“习惯优于配置”的理念让项目快速运行起来，
> 独立运行spring项目，springboot可以以jar包的形式独立运行,
>
> 内嵌servLet容器，可以内嵌tomcat，接天jetty，或者undertow，这样我们就可以不用war包形式部署项目
>
> 提供starter简化maven配置，spring提供了一系列starter pom 来简 化maven的依赖加载， 当使用了spring-boot-starter-web时，会自动加载所需要的依赖包
>
> 自动配置spring sprintboot 会根据在类路径的jar包，类，为jar包中的类自动配置bean，这样会极大的减少使用的配置，会根据启动类所在的目录，自动配置bean

> ==springboot 和spring区别?==
>
> 编码风格 restful 
>
> 配置 xml一 java config propertites xml -yml默认starter支持
>
> 部署 内嵌tomcat
>
> 监控 actuator restful接口获取

> ==自动装配==
> 启动类的@SpringBootApplication注解由@SpringBootConfiguration，@EnableAutoConfiguration，@ComponentScan三个注解组成，三个注解共同完成自动装配;
>
> @SpringBootConfiguration 注解标记启动类为配置类
>
> @ComponentScan 注解实现启动时扫描启动类所在的包以及子包下所有标记为bean的类由IOC容器注册为bea
>
> @EnableAutoConfiguration通过 @Import 注解导入 AutoConfigurationImportSelector类，然后过AutoConfigurationImportSelector 类的 selectImports 方法去读取需要被自动装配的组件依赖下spring.factories文件配置的组件的类全名，并按照一定的规则过滤掉不符合要求的组件的类全名，将剩余读取到的各个组件的类全名集合返回给IOC容器，并将这些组件注册为bean

> SpringBoot专注于快速、方便的开发单个微服务个体，Springcloud关注全局的服务治理框架



## springcloud篇

> ==项目使用版本==
>
> <springframework.version>5.3.12</springframework.version>
>
> <spring.boot.version>2.5.6</spring.boot.version>
>
> <spring.cloud.version>2020.0.4</spring.cloud.version>

> ==springcloud和dubbo区别==
> (1) 服务调用方式: dubbo是RPC，Spring cloud是Rest Api。
> (2) 注册中心: dubbo 是zookeeper，spring cloud可以是zookeeper或其他。
> (3)服务网关: dubbo本身没有实现，只能通过其他第三方技术整合，springcloud有Zuul路由网关 作为路由服务器，进行消费者的请求分发,springcloud支持断路器，与git完美集成配置文件，支持版本控 制，事物总线实现配置文件的更新与服务自动装配等等一系列的微服务架构要素。
> (4) 架构完整度: Spring CLoud包含诸多微服务组件要素，完整度上比Dubbo高

> ==Feign Ribbon Hystrix 三者关系==
> 1介绍三个的定义和功能
> 2、如果微服务项目加上了spring-cloud-starter-netflix-hystrix依赖，那么，feign会通过代理模式自动 将所有的方法用 hystrix 进行包装
>
> 3、一方面，微服务之间的互相调用可以通过Feign进行声明式调用，在这个过程中Feign会通过Ribbon从服务册中心获取目标微服务的服务器地址列表，进行负债均衡调用。
>
> 另一方面微服务在互相调用的过程中，为了防止某个微服务的故障消耗掉整个系统所有微服务的连接资源，调用方会针对被调用微服务设置调用超时时间，一旦超就会进入熔断逻辑，而这个故障指标信息也会 返回给Hystrix组件，Hystrx组件会根据熔断情况判断被调微务的故障情况从而打开熔断器，之后所有针对该微服务的请求就会直接进入熔断逻辑，直到被调微服务故障恢复Hystrix断路器关闭为止。
>
> 
>
> 如果不启用Hystrix，Feign的超时时间则是Ribbon的超时时间，Feign自身的配置也会被覆 盖。如果启用，ribbon的超时时间需要小于hystrix配置的超时时间(由于ribbon需要重试)

### 服务注册和管理

#### eureka

> **eureka与zookeeper服务拉取方式**
>
> eureka 服务主动拉取策略，每隔30s去eureka拉取服务缓存在本地
> zk中服务首次启动去zk订阅自己需要的服务信息，缓存在本地，然后监听服务列表的变化，变化后zk会推送给消费者
>
> AP 模式
>
> - 服务注册：服务启动检查是否注册属性，为true，**携带自身元数据信息，向eureka server发送rest请求**，eureka保存数据Map<服务名称，服务实例ID>
> - 服务消费：服务启动检查是否拉取服务信息，为true，从rureka server**拉取数据缓存在本地**，30s拉取一次
> - 无效剔除：**eureka server开启定时任务扫描那些心跳过期的服务**，90s没有更新认为失效，进行剔除
> - 自我保护：Eureka会统计最近15分钟心跳失败的服务实例的比例是否超过了85%，超过进入**自我保护机制，不再剔除实例**。`基于所有服务的。`
> - 连接方式：基于短链接和注册中心联系
>
> 存储机制：
>
> 多级缓存机制
> 	1、拉取服务的时候首先从**readOnlycacheMap**中找，其次是**readWriteCacheMap**,最后是**注册表regisstry**
>     2、二级缓存也就是读写缓存数据来源于数据启动从注册表中加载
>     3、三级缓存可用开关开启，关闭则直接从读写缓存取，开启的化，会有一个定时任务从读写缓存到只读缓存的同步。
>     4、只**读缓存ConcurrentHashMap**    **读写缓存guava cache**
> 	**过期策略**
> 		主动过期，服务下线故障的时候，读写缓存过期
> 		**定时过期，读写缓存构建的时候就是180s默认过期**
> 		被动过期，定时30s比对读写缓存和只读缓存的数据，不一致的化，读写覆盖只读
>
> 通过过期的机制，可以发现一个问题，就是如果ReadwriteCacheMap发生了主动过期或定时过期， 此时里面缓存就被清空或部分被过期了， 但是在此之前 readnlyCacheMap刚执行了被动 过期，发现两个缓存是一致的，就会接着使用里面的缓存数据 所以可能会存在30秒的时间，read0nlyCacheMap和ReadWriteCacheMal的据不一致
>
> **eureka和zookeeper比较**
> 1.ZooKeeper保证的是CP,Eureka保证的是AP
> ZooKeeper在选举期间注册服务瘫痪,虽然服务最终会恢复,但是选举期间不可用的 Eureka各个节点是平等关系只要有一台Eureka就可以保证服务可用，而查询到的数据并不是最新的
>
> 自我保护机制会导致 Eureka不再从注册列表移除因长时间没收到心跳而应该过期的服务 ,Eureka仍然能够接受服务的注册和查询请求,但是不会被同步到其他节点(高可用) ,当网络稳定时，当前实例新的注册信息会被同步到其他节点中(最终一致性)
> Eureka可以很好的应对因网络故障导致部分节点失去联系的情况,而不会像ZooKeeper一样使得整 个注册系统瘫痪
> 2.ZooKeeper有Leader和Follower角色,Eureka各个节点平等
> 3.ZooKeeper采用过半数存活原 则,Eureka采用自我保护机制解决分区问题
> 4.Eureka本质上是一个工程,而ZooKeeper只是一个进程

#### nacos

> 临时节点 AP      永久节点CP   Spring Cloud注册中心 + Spring Cloud配置中心
>
> - 临时实例：临时实例会与注册中心保持心跳，不健康会被剔除。
>
> - 永久实例：不会主动向注册中心上报心跳，**注册中心主动探测的方式。**
>
> - 服务注册：也是openAPI方式，调用 Http 接口对服务进行注册
>
> - 连接方式：基于netty长连接方式与注册中心联系
>
> - 自我保护：当**基于某个service的**健康实例 (Instance) 占总服务实例(Instance) 的比例小于阈值时，无论实例 (Instance) 是否健康，都会将这个实例 (Instance) 返回给客户端。**基于某个service的**
>
> - 服务发现：
>
>   **主动拉取模式**，消费者定期主动从Nacos拉取服务列表并缓存起来，在服务调用时优先读取本地缓存中的服务列表。
>
>   订阅模式，消费者订阅Nacos中的服务列表，并基于UDP协议来接收服务变更通知。当Nacos中的服务列表发生更新时，会发送UDP广播给所有订阅者。
>
> 存储模型
>
> Nacos采用了数据的分级存储模型，最外层是**Namespace**，用来隔离环境。然后是**Group**，用来对服务分组。接下来就是**服务(Service)**了，一个服
> 务包含多个实例，但是可能处于不同机房，因此**Service下有多个集群(luster)**，**Cluster下是不同的实例(Instance)**，`对应java代码采用了多层的Map表示`
>
> Nacos = Spring CLoud注册中心 + Spring cloud配置中心，(可以做配置中心，，Nacos采用Netty保持TCP长连接实时推送)
>
> **配置功能**
> 引入 spring-cloud-starter-alibaba-nacos-config
>
> 读取顺序 --本地bootstrap.xml 一远程nacos配置文件 =》 本地application.yml = 》合并然后加载
>
> 配置热更新 @Value注入的变量所在类上添加注解@RefreshScop / @ConfigurationProperties注解代替@Value注解
>
> 配置共享优先级 [spring.application,name].yaml 不包含环境，因此可以被多个环境共享.
>
> 配置共享的优先级nacos中服务名-profile.yaml>nacos中 服务名yaml >本地配置
>
> **Nacos如何保证并发写的安全性?**
> 答: 首先，在注册实例时，会对service加锁，不同service之间本身就不存在并发写问题，互不影响。(相同service时通过锁来互斥)。并且，在更 新实例列表时，是基于异步的线程池来完成，而线程池的线程数量为
> **Nacos如何避免并发读写的冲突?**
> 答: Nacos在更新实例列表时，(会采用Copyonlirite技术)，首先将0Ld实例列表拷贝一份，然后更新拷贝的实例列表，再用更新后的实例列表来 覆盖旧的实例列表。
> **Nacos如何应对阿里内部数十万服务的并发写请求**?
> 答: Nacos内部会将服务注册的任务放入阻塞队列，采用线程池异步来完成实例更新，从而提高并发写能力。

#### consul

> CP模式
>
> Leader挂掉时重新选举期间整个consul不可用

#### zookeeper

> CP 模式

### zuul

> Zuul是spring cloud中的微服务网关。
>
> 网关: 是一个网络整体系统中的前置门户入口。请求首先通过网 关，进行路径的路由，定位到具体的服务节点上。
> **使用策略**
> 使用Zuul，一般在微服务数量较多(多于10个)的时候推荐使用
>
> 对服务的管理有严格要求的时候推荐 使用
>
> 当微服务权限要求严格的时候推荐使用。
> 统一入口:为全部为服务提供一个唯一的入口，网关起到外部和内部隔离的作用，保障了后台服务 的安全性。
> 鉴权校验:识别每个请求的权限，拒绝不符合要求的请求。
> 动态路由: 动态的将请求路由到不同的后端集群中。
> 减少客户端与服务端的耦合: 服务可以独立发展，通过网关层来做映射。

> 过滤器
> 继承父类ZuulFilter，过滤器类型包括;
> pre - 前置过滤器，在请求被路由前执行，通常用于处理身份认证，日志记录等;
> route --在路由执行后，服务调用前被调用;
> error  任意一个filter发生异常的时候执行或远程服务调用没有反馈的时候执行(超时)，通常用 于处理异常
> post - 在route或error执行后被调用，一般用于收集服务信息，统计服务性能指标等，也可以对 response结果做特殊处理。

> Zuul降级处理
> Zuul提供了ZuulFallbackProvider的子接口 FallbackProvider来提供fallback处理。
> 只针对timeout异常处理
> 限流处理
> 依赖spring-cloud-zuul-ratelimit组件
> 重试处理
> 使用spring-retry实现

> **Nginx 和 Zuu 的区别和共同点**
> 区别
> Nginx是C语言开发,而 Zuu 是Java语言开发
> Nginx采用服务器实现负载均衡,而Zuul负载均衡的实现是采用 Ribbon + Eureka 来实现本地负载均衡
> Nginx适合于服务器端负载均衡,Zuul适合微服务中实现网关
> Nginx 是一个高性能的HTTP 和反向代理服务器。 Zuul本质上是一个web servlet 应用
> 相同点
> 1、可以实现负载均衡(Zuul使用的是Ribbon实现负载均衡) 
>
> 2可以实现反向代理 (即隐藏实ip地址) 
>
> 3可以过滤请求,实现网关的效果

### gateway

> 1. Gateway 的 客 户 端 回 向 Spring Cloud Gateway 发 起 请 求 ， 请 求 首 先 会 被 **HttpWebHandlerAdapter**进行**提取组装成网关的上下文**，然后网关的上下文会传递到 DispatcherHandler
> 2. **DispatcherHandler是所有请求的分发处理器**，DispatcherHandler主要负责分发请求对应的处理器，比如将请求分发到对应RoutePredicateHandlerMapping(**路由断言处理器映射器**）
> 3. **路 由 断 言 处 理 映 射 器 主 要 用 于 路 由 的 查 找 ， 以 及 找 到 路 由 后 返 回 对 应 的 FilteringWebHandler**
> 4. FilteringWebHandler主要负责组**装Filter链表并调用Filter执行一系列Filter处理**，然后**把请求转到后端对应的代理服务处理，处理完毕后，将Response返回到Gateway客户端。**

> Spring 5.，Spring Boot 2.和 Poject Reactor 等响应式编程和事件流技术开发的网关Zuul是基于Servlet的实现，属于阻塞式编程。而SpringCloudGateway则是基于Spring5中提供的WebFLux，属于响应式编程的实现，，具备更好的性能核心特性:**请求路由、权限控制、限流**
> 对路由的请求或响应做加工处理，比如添加请求头
> 配置在路由下的过滤器只对当前路由的请求生效
>
> defaultFilters的作用对所有路由都生效的过滤器
>
> 1，路由id:路由的唯一标示
>
> 2.路由目标(uri):路由的目标地址，http代表固定地址，L代表根据服务名负载均衡
>
> 3。路由断言(predicates):判断路由的规则，
> 4。路由过滤器(filters):对请求或响应做处理
>
> 实现GLobalFilter接口 实现自定义在fitter中编写自定义逻辑，可以实现下列功能:登录状态判断权限校验请求限流等
> 请求路由后，会将当前路由过滤器和DefaultFilter、GLobalFilter，合并到一个过滤器链(集合)中,排序后依次执行每个过滤器过滤器的order值一样时，会按照 **defaultFilter > 路由过滤器 >GLobalFilter的顺序执行。**

> 限流
>
> 使用令牌桶限流，RequestRateLimiterGatewayFilterFactory结合Redis的lua脚本方式实现令牌桶限流

### hystrix

> 1. 对于**一次依赖调用，会被封装在一个HystrixCommand对象中**，调用的执行有两种方式，一种是调用**execute()方法同步调用**，另一种是调用**queue()方法进行异步调用**。
> 2. 执行时会判断**断路器开关是否打开**，如果断路器打开，则进入getFallback()降级逻辑；**如果断路器关闭，则判断线程池/信号量资源是否已满**，如果资源满了，则进入 getFallback()降级逻辑；如果没满，则执行run()方法。再判断执行**run()方法是否超时**，超时则进入getFallback()降级逻辑，run()方法执行失败，则进入getFallback()降级逻辑，执行成功则报告Metrics。Metrics中的数据包括执行成功、超时、失败等情况的数据，**Hystrix会计算一个**
>    **断路器的健康值，也就是失败率，当失败率超过阈值后则会触发断路器开关打开**。
> 3. getFallback()逻辑为：如果**没有实现fallback()方法，则直接抛出异常**，另外fallback降级也是需要资源的，在fallback时需要获取一个针对fallback的信号量，只有获取成功才能fallback，获取信号量失败，则抛出异常，获取信号量成功，才会执行fallback方法并且会响应fallback方法中的内容

> `健康统计过程：`
>
> 1. HystrixCommand命令器的执行结果（失败、成功）会以事件的形式，形成执行完成事件流。
> 2. 调用HystrixCommandMetrics.appendEventToBucket ，以事件流作为来源，将**事件流中的事件按照固定时间长度**（桶时间间隔）**划分成滚动窗口**，并对时间桶滚动窗口内的事件**按照类型进行累积**，形成桶计数流（`比如桶时间间隔为3s，1s发出一个事件，那么就会有3个事件被添加到桶内`）
> 3. 桶滑动统计流以桶计数流作为来源，**按照(一定规则)**步长为1、长度为设定的桶数（配置的滑动窗口桶数）的规则**划分滑动窗口**，**并对滑动窗口内的所有的桶数据按照各事件类型进行汇总，汇总成最终**，形成最终的桶滑动统计流。(比如设置2个桶为一个滑动窗口，比如桶 1 2 3 4 ，那么步长为1 代表统计 12 两个桶的  2 3 两高桶的 34 两个桶的)

> `熔断：熔断器模式`
>
> 1）closed：熔断器关闭状态，这也是熔断器的初始状态，此状态下RPC调用正常放行。
> 2）open：失败比例到一定的阈值之后，熔断器进入开启状态，此状态下RPC将会快速失败，执行失败回退逻辑。
> 3）half-open：在打开一定时间之后（睡眠窗口结束），熔断器进入**半开启状态，小流量尝试进行RPC调用放行**。如果尝试成功则熔断器变为closed状态，RPC调用正常；如果尝试失败则熔断器变为open状态，RPC调用快速失败。

> 限流
>
> `舱壁模式`
>
> 为每一个HystrixCommand命令关联上一个指定的线程池，来进行隔离RPC请求
>
> `信号量模式`
>
> 信号量的值就是每个命令的并发执行数量，当并发数高于信号量的值时，就不再执行命令。

> 源码分析：
>
> 1、本质是AOP方式HystrixCommandAspect对使用@HystrixCommand或者@HystrixCollapser（合并请求）进行切面
>
> 2、根据注解配置的信息初始化MetaHolder元数据信息，根据方法的元数据信息，创建HystrixCommand对象（`命令模式，对请求进行参数化`）
>
> 3、结合RxJava响应式编程方式进行实际调用，最终反射调用该方法。

### sentinel

> **簇点链路**
> 当请求进入微服务时，首先会访问DispatcherServlet，然后进入Controller、Service、 Mapper，这样的一个调用链就叫做点链路。簇点链路中被监 控的每一个接口就是一个资源

> 限流
>
> `流控模式`
>
> - 直接：统计当前资源的请求，触发阈值时对当前资源直接限流，也是默认的模式
> - 关联：统计与当前资源相关的另一个资源，触发阈值时，对当前资源限流
> - 链路：统计从指定链路访问到本资源的请求，触发阈值时，对指定链路限流
> - 热点参数限流
>
> `流控效果`
>
> - 快速失败：达到阈值后，新的请求会被立即拒绝并抛出FlowException异常。是默认的处理方式。
> - warm up：预热模式，对超出阈值的请求同样是拒绝并抛出异常。但这种模式阈值会动态变化，从一个较小值逐渐增加到最大阈值。
> - 排队等待：让所有的请求按照先后次序排队执行，两个请求的间隔不能小于指定时长
>
> `隔离方式`
>
> 限制资源能使用用的tomcat线程数的最大值。也就是通过限制线程数量，实现**线程隔离**（舱壁模式）。

> `熔断方式`
>
> **断路器****统计服务调用的异常比例、慢请求比例**，如果超出阈值则会**熔断**该服务。即拦截访问该服务的一切请求；而当服务恢复时，断路器会放行访问该服务的请求。
>
> `状态机`
>
> - closed：关闭状态，断路器放行所有请求，并开始统计异常比例、慢请求比例。超过阈值则切换到open状态
> - open：打开状态，服务调用被**熔断**，访问被熔断服务的请求会被拒绝，快速失败，直接走降级逻辑。Open状态5秒后会进入half-open状态
> - half-open：半开状态，放行一次请求，根据执行结果来判断接下来的操作。
>   - 请求成功：则切换到closed状态
>   - 请求失败：则切换到open状态
>
> `断路器熔断策略`
>
> **慢调用**：业务的响应时长（RT）大于指定时长的请求认定为慢调用请求
>
> **异常比例**：统计指定时间内的调用，如果调用次数超过指定请求数，并且出现**异常的比例**达到设定的比例阈值（或超过指定**异常数**），则触发熔断
>
> **异常数**

> 授权规则
>
> 支持黑白名单处理
>
> **规则管理模式**
>
> - 原始模式：Sentinel的默认模式，将规则保存在内存，重启服务会丢失。
> - pull模式  将配置的规则推送到Sentinel客户端，客户端会将配置规则保存在本地文件或数据库中。以后会定时去本地文件或数据库中查询，更新本地规则
> - push模式 将配置规则推送到远程配置中心，例如Nacos。Sentinel客户端监听Nacos，获取配置变更的推送消息，完成本地配置更新

> sentinel的限流降级等功能，主要是通过一个SlotChain实现的。在链式插槽中，有7个核心的Slot，这些Slot各司其职
> 一、进行资源调用路径构造的NodeSelectorSlot和ClusterBuilderSlot
> 二、进行资源的实时状态统计的StatisticsSlot
> 三、进行系统保护，限流，降级等规则校验的SystemSlot、AuthoritySlot、FlowSlot、DegradeSlot

### feign

> 一个声明式的伪Http客户端。
>
> Feign是一个HTTP请求调用的轻量级框架，可以以JAVA接口注解的方式调用HTTP请求
>
> 通过处理注解，将请求模板化，当实际调用的时候，传入参数，根据参数再应用到请求上，进而 转化成真正的请求。
>
> 它具有可插拔的注解特性，可使用Feign 注解和JAX-RS注解。Feign支持可插拔的编码器和解码器。 
>
> Feign默认集成了Ribbon进行负载均衡

> **OpenFeign** 
>
> 是 spring 官方推出的一种声明式服务调用和负载均衡组件。
> 优化
> 1.修改 OpenFeign 的超时时间，让 OpenFeign 能够正确的处理业务;
>
> 2.通过配置专用的通信组件 Apache Httpclient 或 OKHttp,让 openFeign 可以更好地对 HTTP 连接对象进行重用和管理，以提高其性能
>
> 3。开启数据压缩功能，可以提高宽带利用率和加速教据传输速度:
>
> 4。使用合适的负载均衡策略来替换默认的轮询负载均衡策略，已获得更好的执行效率;
>
> 5。检查生产成环境中 0penFeign 的日志级别，选择合适的日志输出级别，防止无效的日志输出,

### ribbon

> 是一个基于HTTP和TCP的客户端的负载均衡工具。
>
> 微服务之间的Rest请求转为客户端的负载均衡的RPC调用

> ==工作流程==
>
> Ribbon 简单来说 底层采用了一个拦截器LoadBalancerIntercepor，拦截了RestTemplate发出的请求，
> 从请求url中获取服务名称以及client服务上下文环境里获取负债均衡器，
>
> 负债均衡器根据服务名称提取到服务实例集合(到eureka拉取服务列表)
>
> 用内置负载均衡规则，从列表中选择一个，然后修改请求地址，将请求包装为LoadBalancerCommand，进行真实请求。

> ==负载均衡策略==
> 默认的实现是轮询 可以通过继承 RoundRibbonRule 来实现自定义负载均衡策略。。
>
> RoundRobinRule 轮询来获取
>
> AvailabilityFilteringRule 可用性敏感策略: 先过滤掉非健康的服务实例，然后再选择连接数较小的服务实例
>
> WeightedResponseTimeRule权重(越大访问几率大)。根据每个服务提供者的响应时间分配一个权重,响应时间越 长，权重越小，被选中的可能性也就越低。
>
> 它的实现原理是，刚开始使用轮询策略并开启一个计时器， 每一段时间收集一次所有服务提供者的平均响应时间，然后再给每个服务提供者附上一个权重，权重越 高选中的概率也越大
>
> ZoneAvoidanceRule 分区域，使用Zone对服务器进行分类，再对Zone内的多个服务做轮询
>
> BestAvailableRule忽略那些短路的服务器，并选择并发数较低的服务器。最小连接数策略也叫最小并发数策略，它是遍历服务提供者列表，选取连接数最小的一个服务实例。如果有相同的最小连接数，那么会调用轮询策略进行选取
>
> RandomRule  随机选择一个可用的服务器。
>
> RetryRule 重试机制的选择逻辑 按照轮询策略来获取服务，如果获取的服务实例为null 或已经失效，则在指定 的时间之内不断地进行重试来获取服务，如果超过指定时间依然没获取到服务实则返回 null

## dubbo篇

> ==负载均衡策略==
> 随(默认) : 随机来
> 轮询:一个一个来
> 活跃度: 机器活跃度来负 同活跃数的随机 慢的提供者收到更少请求
> 一致性 hash: 落到同一台机器上

> ==容错策略==
>
> **Failover Cluster** 失败自动切换，当出现失败，重试其它服务器。通常用于读操作，但重试会带来更长延迟。可通过 retries="2" 来设置重试次数(不含第一次)。
>
> ***\*Failfast Cluster\****快速失败，只发起一次调用，失败立即报错。通常用于非幂等性的写操作，比如新增记录。
>
> ***\*Failsafe Cluster\**** 失败安全，出现异常时，直接忽略。通常用于写入审计日志等操作。
>
> ***\*Failback Cluster\**** 失败自动恢复，后台记录失败请求，定时重发。通常用于消息通知操作。
>
> ***\*Forking Cluster\**** 并行调用多个服务器，只要一个成功即返回。通常用于实时性要求较高的读操作，但需要浪费更多服务资源。可通过 forks="2" 来设置最大并行数。
>
> ***\*Broadcast Cluster\**** 广播调用所有提供者，逐个调用，任意一台报错则报错 [2]。通常用于通知所有提供者更新缓存或日志等本地资源信息。

> ==Dubbo的总体的调用过程吗==
>
> 1**.Proxy持有一个Invoker对象，使用Invoker调用**
> 2.之后通过**Cluster进行负载容错**，失败重试
> 3.调用**Directory获取远程服务的Invoker列表**
> 4.负载均衡用户配置了路由规则，则根据路由规则过滤获取到的Invoker列表用户没有配置路由规则或
> 配置路由后还有很多节点，则使用LoadBalance方法做**负载均衡，选用一个可以调用的Invoker**
> 5.经过一个一个**过滤器链，通常是处理上下文、限流、计数**等。
> 6.会使用**Client做数据传输**
>
> 7.私有化协议的构造(Codec)
> 8.进行序列化
>
> 9.服务端收到这个Request请求，将其**分配到ThreadPool中进行处理**
> 10.Server来处理这些Request
> 11.根据**请求查找对应的Exporter**
> 12.之后**经过一个服务提供者端的过滤器链**
> 13.然后**找到接口实现并真正的调用，将请求结果返回**

> ==Dubbo 服务注册与发现的流程？==
>
> Provider(提供者)绑定指定端口并启动服务
> 指供者连接注册中心，并发本机IP、端口、应用信息和提供服务信息发送至注册中心存储
> Consumer(消费者），连接注册中心 ，并发送应用信息、所求服务信息至注册中心
> 注册中心根据 消费 者所求服务信息匹配对应的提供者列表发送至Consumer 应用缓存。
> Consumer 在发起远程调用时基于缓存的消费者列表择其一发起调用。
> Provider 状态变更会实时通知注册中心、在由注册中心实时推送至Consumer

> ==工作原理/十层架构==
>
> 第一层：service 层，接口层，给服务提供者和消费者来实现的（留给开发人员来实现）；
> 第二层：config 层，配置层，主要是对 Dubbo 进行各种配置的，Dubbo 相关配置；
> 第三层：proxy 层，服务代理层，透明生成客户端的 stub 和服务单的 skeleton，调用的是接口，实现
> 类没有，所以得生成代理，代理之间再进行网络通讯、负责均衡等；
> 第四层：registry 层，服务注册层，负责服务的注册与发现；
> 第五层：cluster 层，集群层，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服
> 务；
> 第六层：monitor 层，监控层，对 rpc 接口的调用次数和调用时间进行监控；第七层：protocol 层，远
> 程调用层，封装 rpc 调用；
> 第八层：exchange 层，信息交换层，封装请求响应模式，同步转异步；
> 第九层：transport 层，网络传输层，抽象 mina 和 netty 为统一接口；
>
> 第十层：serialize 层，数据序列化层。

> ==怎么实现动态感知服务下线的呢？==
>
> Dubbo ZooKeeper 注册中心采用是**事件通知与客户端拉取方式**
>
> 服务第一次订阅的时候将会拉取对应目录下全量数据，然后在订阅的节点注册一个 watcher。
> 一旦目录节点下发生任何数据变化， ZooKeeper 将会通过 watcher 通知客户端。
> 客户端接到通知，将会重新拉取该目录下全量数据，并重新注册 watcher。

> ==Dubbo的服务暴露流程==
>
> 1.通过**ServiceConfig对象解析标签**，并创建dubbo的标签解析器对象来解析dubbo标签，随后通过**触发ContextRefreshEvent事件的回调方法开始暴露服务的动作**。
> 2.通过调用proxyFactory对象的getInvoker方法，并用javassist或DdkProxyFactory来进行动态代理，把**服务暴露接口封装成invoker对象**，在该对象里包含需要执行的方法名、参数和对应的URL地址。
> 3.通过**DubboProtocol的实现类，把包装后的invoker转换成exporter对象**。随后**启动服务器端的server来监听端口，等待服务调用的到来**。
> 4.通过**RegistryProtocol对象，保存URL地址和invoker之间的映射关系，同时把这层映射关系注册到服务中心**，比如Zookeeper里。

> ==Dubbo的服务引用的流程==
>
> 1.Dubbo客户端根据config文件里的信息从注册中心里订阅服务，并缓存到本地，后续的服务相关信息
> 的会动态更新到本地。
> 2.DubboProtocol根据provider的地址和接口连接到服务端server，开启客户端client，再创建
> invoker。
> 3.用invoker为服务接口生成代理对象，这个代理对象是用来远程调用。

> ==Dubbo SPI机制==
>
> SPI(Service Provider Interface)，是**一种服务发现机制**，其实就是**将结构的实现类写入配置当中，在服务加载的时候将配置文件读取，加载实现类，这样就可以在运行的时候，动态的帮助接口替换实现类。**
> Dubbo的SPI其实是对java的SPI进行了一种增强,可以**按需加载实现类之外**，增加了 IOC 和 AOP 的特性，还有自适应扩展机制。
>
> ==Java Spi==
> Java SPI 在查找扩展实现类的时候，遍历 SPI 的配置文件，并且将**实现类全部实例化**
> ==Dubbo Spi==
> 1，对 Dubbo 进行扩展，不需要改动 Dubbo 的源码
> 2，可以选择性的加载，**可以一次只加载自己想要加载的扩展实现**。`k=v`的形式放了实现类的名字和实现类的类别
> 3，**增加了对扩展点 IOC 和 AOP 的支持**，一个扩展点可以直接 setter 注入其它扩展点。
>
> 4，Dubbo 的**自适应扩展机制**能很好的支持第三方 IoC 容器，默认支持 Spring Bean。  **基于参数，在运行时动态选择到具体的目标类，然后执行**  @Adaptive

```java
public class RoundRobinLoadBalance implements LoadBalance {
 
    private LoadBalance loadBalance;
    
    public void setLoadBalance(LoadBalance loadBalance) {  // setter 方式注入  注入的对象默认就是上面提到的自适应的对象
        this.loadBalance = loadBalance;
    }
 
}

public class RoundRobinLoadBalance implements LoadBalance {
 
    private final LoadBalance loadBalance;
 
    public RoundRobinLoadBalance(LoadBalance loadBalance) { //Wrapper类，这个类的作用就是来实现AOP的。
        this.loadBalance = loadBalance;
    }
 
}
！！！！判断Wrapper类的唯一标准就是这个类中必须要有这么一个构造参数，这个构造方法的参数只有一个，并且参数类型就是接口的类型
此时RoundRobinLoadBalance就是一个Wrapper类。
当通过random获取RandomLoadBalance目标对象时，那么默认情况下就会对RandomLoadBalance进行包装，真正获取到的其实是RoundRobinLoadBalance对象，RoundRobinLoadBalance内部引用的对象是RandomLoadBalance。
```



## tomcat篇

> ==tomcat监控==
>
> tomcat 的关键指标有吞吐量、响应时间、错误数、线程池、CPU 以及 JVM 内存
>
> Tomcat 可以通过 JMX 将上述指标暴露出来的,然后通过JConsole 监控 Tomcat
>
> **命令行查看指标**
>
> 1. ps -ef|grep tomcat
> 2. 查看进程状态的大致信 cat/proc/<pid>/status
> 3. 查看监控进程的 CPU 和内存资源使用情况 top -p 30943
> 4. 查看 Tomcat 的网络连接，比如 Tomcat 在 8080 端口上监听连接请求  netstat -na |grep 8080  还可以分别统计处在“已连接”状态和“TIME_WAIT”状态的连接数  netstat -na |grep ESTAB| grep 8080 |wc -l 12   netstat -na |grep TIME_WAIT| grep 8080 |wc -l 43
> 5. 通过 ifstat 来查看网络流量  ifstat

> ==tomcat IO调优==
>
> 所谓的 I/O 调优指的是选择 NIO、NIO.2 还是 APR
>
> - 默认都是 NIO  Linux 平台上，建议使用 NIO   Linux 内核没有很完善地支持异步 I/O 模型，因此 JVM 并没有采用原生的 Linux 异步 I/O，而是在应用层面通过epoll 模拟了异步 I/O 模型
> - Web 应用用到了 TLS 加密传输，而且对性能要求极高 考虑 APR APR 通过 OpenSSL 来处理 TLS 握手和加 / 解密。OpenSSL 本身用 C 语言实现，它还对 TLS 通信做了优化，所以性能比 Java 要高。
> - Tomcat 跑在 Windows平台上，并且 HTTP 请求的数据量比较大，可以考虑 NIO.2  Windows 从操作系统层面实现了真正意义上的异步 I/O
>
> ==tomcat线程池优化==
>
> 核心的就是如何确定 maxThreads 的值
>
> 小了，Tomcat 会发生线程饥饿，并且请求的处理会在队列中排队等待，导致响应时间变长
>
> 过大，服务器的 CPU 的核数有限，线程数太多会导致线程在 CPU 上来回切换，耗费大量的切换开销
>
> **依照公式**，一般来说，如果系统的 TPS 要求足够大，用第一个公式算出来的线程数往往会比公式二算出来的要大。我建议选取这两个值中间更靠近公式二的值。也就是先设置一个较小的线程数，然后进行压测
>
> 线程池大小 = 每秒请求数 × 平均请求处理时间
>
> 线程池大小 = （线程 I/O 阻塞时间 + 线程 CPU 时间 ）/ 线程 CPU 时间

> ==Tomcat内存溢出的原因分析及调优==
>
> **java.lang.OutOfMemoryError: Java heap space**
>
> - 内存泄漏  比如对象池和内存池中的对象无法被 GC 回收
>
> - 配置问题 通过 JVM 参数加大堆的大小
>
> - finalize 方法的过度使用
>
>   如果我们想在 Java 类实例被 GC 之前执行一些逻辑，比如清理对象持有的资源，可以在 Java 类中定义 finalize 方法，这样 JVM GC 不会立即回收这些对象实例，而是将对象实例添加到一个叫“java.lang.ref.Finalizer.ReferenceQueue”的队列中，执行对象的 finalize 方法，之后才会回收这些对象。Finalizer 线程会和主线程竞争 CPU 资源，但由于优先级低，所以处理速度跟不上主线程创建对象的速度，因此ReferenceQueue 队列中的对象就越来越多，最终会抛出 OutOfMemoryError。解决办法是尽量不要给 Java 类定义 finalize 方法。
>
> **java.lang.OutOfMemoryError: GC overhead limit exceeded**
>
> 垃圾收集器一直在运行，但是 GC 效率很低，比如 Java 进程花费超过 98％的 CPU 时间来进行一次 GC，但是回收的内存少于 2％的 JVM堆，并且连续 5 次 GC 都是这种情况，就会抛出 OutOfMemoryError
>
> 查看 GC 日志或者生成 Heap Dump，确认一下是不是内存泄漏，如果不是内存泄漏可以考虑增加 Java 堆的大小。当然你还可以通过参数配置来告诉 JVM 无论如何也不要抛出这个异常，方法是配置-XX:-UseGCOverheadLimit（不推荐）
>
> **java.lang.OutOfMemoryError: Requested array size exceeds VM limit**
>
> “请求的数组大小超过 JVM 限制 
>
> 配置问题（JVM 堆太小）
>
> **java.lang.OutOfMemoryError: MetaSpace**
>
> JVM 的元空间用尽，则会抛出这个异常
>
> 加大 MaxMetaSpaceSize 参数的值。
>
> **java.lang.OutOfMemoryError: Request size bytes for reason. Out of swap space**
>
> 当本地堆内存分配失败或者本地内存快要耗尽时，Java HotSpot VM 代码会抛出这个异常，VM 会触发“致命错误处理机制”，它会生成“致命错误”日志文件，其中包含崩溃时线程、进程和操作系统的有用信息。
>
> 据
> JVM 抛出的错误信息来进行诊断；或者使用操作系统提供的 DTrace 工具来跟踪系统调用，看看是什么样的程序代码在不断地分配本地内存。
>
> **java.lang.OutOfMemoryError: Unable to create native threads**
>
> 操作系统创建新的线程可能会失败
>
> - 内存大小限制 栈空间如果过小，可能会导致 StackOverflowError
> - ulimit 限制，在 Linux 下执行ulimit -a，你会看到 ulimit 对各种资源的限制  max user processes”就是一个进程能创建的最大线程数
> - 参数sys.kernel.threads-max限制 这个参数限制操作系统全局的线程数  在/etc/sysctl.conf配置文件中，加入sys.kernel.threads-max = 999999。
> - 参数sys.kernel.pid_max限制，这个参数表示系统全局的 PID 号数值的限制，每一个线程都有 ID，ID 的值超过这个数，线程就会创建失败 方法是在/etc/sysctl.conf配置
>   文件中，加入sys.kernel.pid_max = 999999

> ==Tomcat拒绝连接原因分析及网络优化==
>
> **java.net.SocketTimeoutException**
>
> 超时错误。超时分为连接超时和读取超时  连接超时往往是由于网络不稳定造成的，但是读取超时不一定是网络延迟造成的，很有可能是下游服务的响应时间过长
>
> **java.net.BindException: Address already in use: JVM_Bind**
>
> 端口被占用  netstat –an命令来查看端口
>
> **java.net.ConnectException: Connection refused: connect**
>
> 连接被拒绝 原因是指定 IP 地址的机器没有找到；或者是机器存在，但这个机器上没有开启指定的监听端口
>
> 从客户端机器 ping 一下服务端 IP，假如 ping 不通，可以看看 IP 是不是写错了；假如能 ping 通，需要确认服务端的服务是不是崩溃了
>
> **java.net.SocketException: Socket is closed**
>
> 通信的一方主动关闭了 Socket 连接（调用了Socket 的 close 方法），接着又对 Socket 连接进行了读写操作，这时操作系统会报“Socket 连接已关闭”的错误。
>
> **java.net.SocketException: Connection reset/Connect reset by peer: Socket write error**
>
> 连接被重置。这里有两种情况，分别对应两种错误：
>
> 第一种情况是通信的一方已经将Socket 关闭，可能是主动关闭或者是因为异常退出，这时如果通信的另一方还在写数据，就会触发这个异常（Connect reset by peer）；
>
> 如果对方还在尝试从 TCP 连接中读数据，则会抛出 Connection reset 异常
>
> 程序退出前要主动关闭所有的网络连接。
> 检测通信的另一方的关闭连接操作，当发现另一方关闭连接后自己也要关闭该连接。
>
> **java.net.SocketException: Broken pipe**
>
> 通信管道已坏。发生这个异常的场景是，通信的一方在收到“Connect reset by peer:Socket write error”后，如果再继续写数据则会抛出 Broken pipe 异常，解决方法同上
>
> **java.net.SocketException: Too many open files**
>
> 进程打开文件句柄数超过限制 并发用户数比较大时，服务器可能会报这个异常
>
> lsof -p pid命令查看进程打开了哪些文件，是不是有资源泄露，也就是说进程打开的这些文件本应该被关闭，但由于程序的 Bug 而没有被关闭
>
> 如果没有资源泄露，可以通过设置增加最大文件句柄数。具体方法是通过ulimit -a来查看系统目前资源限制，通过ulimit -n 10240修改最大文件数。
>
> //
>
> **Tomcat 的最大并发连接数等于maxConnections + acceptCount**。如果acceptCount 设置得过大，请求等待时间会比较长；如果 acceptCount 设置过小，高并发情况下，客户端会立即触发 Connection reset 异常
>
> acceptCount 用来控制内核的 TCP 连接队列长度，maxConnections用于控制 Tomcat 层面的最大连接数

> ==Tomcat进程占用CPU过高怎么办？==
>
> 1. top 命令 查看Java 进程的 CPU 使用率
> 2. top -H -p 4361 查看这个 Java 进程中各线程使用 CPU 的情况
> 3. jstack 命令生成线程快照  jstack 4361  或jstack 4361 > 4361.log  
> 4. 打开 定位 ，或者线程ID转换为16进制  进行查找  看看线程的状态 Block or Waiting 之类
> 5. vmstat 1 100 查看操作系统层面的线程上下文切换活动  cs 那一栏表示线程上下文切换次数，in 表示 CPU 中断次数，我们发现这两个数字非常高，基本证实了我们的猜测，线程上下文切切换消耗了大量 CPU。

> ==tomcat&jetty==
>
> jetty 在吞吐量和响应速度方面稍有优势，并且 Jetty 消耗的线程和内存资源明显比Tomcat 要少，这也恰好说明了 **Jetty 在设计上更加小巧和轻量级的特点**。
> 但是 Jetty 有 2.45% 的错误率，而 Tomcat 没有任何错误，并且我经过多次测试都是这个结果。因此我们可以认为 **Tomcat 比 Jetty 更加成熟和稳定**

## mybatis篇

> ==#{}和${}的区别是什么==
>
> 1）#{}是预编译处理，${}是字符串替换。 
> 2）Mybatis 在处理#{}时，会将 sql 中的#{}替换为?号，调用 PreparedStatement 的 set 方法来赋值； 
> 3）Mybatis 在处理${}时，就是把${}替换成变量的值。 
> 4）使用#{}可以有效的防止 SQL 注入，提高系统安全性

> ==一级、二级缓存==
>
> 1）一级缓存: 基于 PerpetualCache   的 HashMap 本地缓存，其存储作用域为 Session，当 Session flush 或 close 之后，该 Session 中的所有 Cache 就将 清空。 
> 2）二级缓存与一级缓存其机制相同，默认也是采用 PerpetualCache，HashMap 存 储，不同在于其存储作用域为 Mapper(Namespace)，并且可自定义存储源，如Ehcache。要开启二级缓存，你需要在你的 SQL 映射文件中添加一行： 
> 3 ） 对 于 缓 存 数 据 更 新 机 制 ， 当 某 一 个 作 用 域 ( 一 级 缓 存 Session/ 二 级 缓 存 Namespaces)的进行了 C/U/D 操作后，默认该作用域下所有 select 中的缓存将 被 clear。

> ==Mybatis 是否支持延迟加载？如果支持，它的实现原理是什么==
>
> Mybatis 仅支持 association 关联对象和 collection 关联集合对象的延迟加载
>
> ’association 指的就是一对一，collection 指的就是一对多查询。
>
> Mybatis 配置文 件中，可以配置是否启用延迟加载 lazyLoadingEnabled=true|false。 
>
> 它的原理是，使用 **CGLIB 创建目标对象的代理对象**，当调用目标方法时，进入拦截 器方法，比如调用 a.getB().getName()，拦截器 invoke()方法发现 a.getB()是 null 值，
> 那么就会**单独发送事先保存好的查询关联 B 对象的 sql，把 B 查询上**来，然后调 用 a.setB(b)，于是 a 的对象 b 属性就有值了，接着完成 a.getB().getName()方法的 调用。

> ==Mybatis 都有哪些 Executor 执行器？==
> SimpleExecutor、ReuseExecutor、 BatchExecutor。
> 1）SimpleExecutor：每执行一次 update 或 select，就开启一个 Statement 对 象，用完立刻关闭 Statement 对象。
>
> 2）ReuseExecutor：执行 update 或 select，以 sql 作为  key 查找 Statement 对象，存在就使用，不存在就创建，用完后，不关闭 Statement 对象， 而是放置于 Map
> 3）BatchExecutor：完成批处理

> ==工作原理==
>
> mybatis应用程序通过**SqlSessionFactoryBuilder从mybatis-config.xml配置文件**（也可以用Java文件配置的方式，需要添加@Configuration）来构建SqlSessionFactory（SqlSessionFactory是线程安全的）；
>
> 然后，**SqlSessionFactory的实例直接开启一个SqlSession，再通过SqlSession实例获得Mapper对象并运行Mapper映射的SQL语句，完成对数据库的CRUD和事务提交，之后关闭SqlSession。**
> ==详细流程==
>
> 1、加载mybatis全局配置文件（数据源、mapper映射文件等），解析配置文件，MyBatis基于XML配置文件生成Configuration，和一个个MappedStatement（包括了参数映射配置、动态SQL语句、结果映射配置），其对应着<select | update | delete | insert>标签项。
>
> 2、SqlSessionFactoryBuilder通过Configuration对象生成SqlSessionFactory，用来开启SqlSession。
>
> 3、SqlSession对象完成和数据库的交互：
> a、用户程序调用mybatis接口层api（即Mapper接口中的方法）
> b、SqlSession通过调用api的Statement ID找到对应的MappedStatement对象
> c、通过Executor（负责动态SQL的生成和查询缓存的维护）将MappedStatement对象进行解析，sql参数转化、动态sql拼接，生成jdbc Statement对象
> d、JDBC执行sql。
>
> e、借助MappedStatement中的结果映射关系，将返回结果转化成HashMap、JavaBean等存储结构并返回。



## 分布式篇

### cap&base

> ==CAP==
> Consistency(一致性):用户访问分布式系统中的任意节点，得到的数据必须一致。
>
> Availability (可用性):用户访问集群中的任意健康节点，必须能得到响应，而不是超时或拒绝
>
> Partition(分区):因为网络故障或其它原因导致分布式系统中的部分节点与其它节点失去连接，形成独立分区。
> ==BASE==
> Basically Available (基本可用): 分布式系统在出现故障时，允许损失部分可用性，即保证核心可用.
>
> Soft state (软状态)在一定时间内，允许出现中间状态，比如临时的不一致状态。
>
> Eventually Consistent (最终一致性): 虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致

### 分布式事务

> TX协议: 应用或者应用服务器与事务管理器的接口
> XA协议: 全局事务管理器与资源管理器的接口。
> AP: 应用程序，可以理解为使用DTP (Data Tools PLatform) 的程序。
> RM: 资源管理器，这里可以是一个DBMS或者消息服务器管理系统
> TM:事务管理器，负责协调和管理事务，提供给AP编程接口以及管理资源管理器。事务管理器控制着全局事务，管理事务的生命周期，并且协调资源。

> 分布式锁解决的是分布式资源抢占的问题;分布式事务和本地事务是解决流程化提交问题。

> 幻读:在同一事务中，相同条件下，两次查询出来的 记录数 不一样
> 不可重复读:在同一事务中，相同条件下，两次查询出来的 数据 不一样;

> ==事务隔离级别==
>
> 未提交读(READ UNCOMMITTED) : 所有事务都可以看到其他事务未提交的修改。一般很少使用:
> 提交读(READ COMMITTED) : oracle默认隔离级别，事务之间只能看到彼此已提交的变更修改
> 可重复读(REPEATABLE READ): MySOL默认隔离级别，同一事务中的多次查询会看到相同的数据行: 可以解决不可重复读，但可能出现幻读;
> 可串行化(SERIALIZABLE) : 最高的隔离级别，事务串行的执行，前一个事务执行完，后面的事务会执行。读取每条数据都会加锁，会导致大量的超时和锁争用问题;

> ==分布式事务复杂性体现==
> 存储端的多样性
> 事务链路的延展性

> ==定义==
>
> 分布式事务指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上
> 在分布式系统上，一次大的操作由不同的小操作组成，这些小的操作分布在不同的服务节点上，且属于不同的应用，分布式事务需要保证这些小操作要么全部成功，要么全部失败
>
> ==场景==
>
> 1、跨库事务 service 操作两个库
> 2、分库分表 批量插入 路由至不同的库
> 3、微服务化 服务间调用

> ==CAP解读==
>
> c
>
> 操作成功并返回客户端完成后，所有节点在同一时间的数据完全一致，不能存在中间状态。
> 满足上述操作后，客户端看到的数据都是一致的 一 强一致性
> 经过一段时间后，数据最终是一致  一 最终一致性
> 允许存在部分数据不一致 一 弱一致性。
>
> A 
>
> 系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内(合理的RT)返回结果(用户认知的结果)。
>
> P 
>
> 分布式系统在遇到任何网络分区故障时，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障
>
> P不能舍弃，舍弃的话，分区故障时，直接不能对外提供 CA服务， 分区也就不存在意义，也就是扩展不存在意义，无法谈说分布式理念。 (也不是绝对的，银行钱财，C 必须保证。网络发生故障宁可停止服务，这是保证CA，舍弃 P)
> 还有一种是保证 CP，舍弃 A。例如网络故障是只读不写互联网应用的场景 保证 P 和 A，舍弃C (退而求其次保证最终一致性)。虽然某些地方会影响客户体验，但没达到造成用户流程的严重程度。
>
> CA不能同时满足
> 如果保证了一致性(C):对于节点N1和N2，当往N1里写数据时，N2上的操作必须被暂停，只有当N1同步数据至N2时才能对N2进行读写请求，在N2被暂停操作期间客户端提交的请求会收到失败或超时。显然，这与可用性是相悖的。 (就是必须同步完成保证一致性，那其他节点不可用)
> 如果保证了可用性(A):那就不能暂停N2的读写操作，但同时N1在写数据的话，这就违背了一致性的要求(节点都可用的话，数据可能未同步完成)

> ACID里的一致性指的是事务执行前后，数据库完整性，而CAP的一致性，指的是分布式节点的数据的一致性

> BA Basically Available 基本可用是指分布式系统在出现不可预知的故障的时候，允许损失部分可用性(RT增加 或者 降级)，但不等于系统不可用
>
> Soft state 允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。
>
> Eventually consistent (最终一致性)  强调系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态

> **刚性事务**:通常无业务改造，强一致性，原生支持回滚/隔离性，低并发，适合短事务,要使分布式事务，达到像本地式事务一样，具备数据强一致性，从CAP来看，就是说，要达到CP状态
>
> **柔性事务**的特点为:有业务改造，最终一致性，实现补偿接口，实现资源锁定接口，高并发，适合长事务
> 柔性事务分为:
> 补偿型
>
> 异步确保型
> 最大努力通知型。
> 柔型事务: TCC/FMT、Saga (状态机模式、Aop模式) 、本地事务消息、消息事务(半消息)
> 补偿型事务都是同步的，通知型事务都是异步的。

> **XA 协议的实现** 包括 2PC  JTA  JTS
> 3pc是对2pc的扩展
> 。必须要拿到所有数据源，而且数据源还要支持XA协议。目前MySQL中只有InnoDB存储引擎支持XA协议。
> 。性能比较差，要把所有涉及到的数据都要锁定，是强一致性的，会产生长事务

> **java平台上事务规范 JTA (Java Transaction API)**
> JTA是基于XA架构上建模的，在JTA 中，事务管理器抽象为javax.transaction.TransactionManager接口，并通过底层事务服务《即JTS) 实现
> JTA仅仅定义了接口，具体的实现则是由供应商(如J2EE厂商)负责提供，目前JTA的实现主要由以下几种:
>
> 1.J2EE容器所提供的JTA实现(JBoss)
>
> 2.独立的JTA实现:如JOTM，Atomikos
>
> JTA定义了一套接口，其中约定了几种主要的角色: TransactionManager、UserTransactionTransaction、XAResource，并定义了这些角色之间需要遵守的规范，如Transaction的委托给TransactionManager等。
> JTS也是一组规范，上面提到JTA中需要角色之间的交互，那应该如何交互? JTS就是约定了交互细节的规范,**JTA更多的是从框架的角度来约定程序角色的接口，而JTS则是从具体实现的角度来约定程序角色之间的接口**

> **2pc实现**
>
> seata、 atomikos、 Lcn
>
> 两阶段提交在处理分布式事务时分为两个阶段:
>
> voting (投票阶段，有的地方会叫做prepare阶段)和commit阶段
>
> 2pc中存在两个角色，事务协调者 (seata  atomikos、Lcn)和事务参与者，事务参与者通常是指应用的数据库
>
> - 2PC方案比较适合单体应用
> - 最大缺点就在于它的执行过程中间，节点都处于阻塞状态，各个操作数据库的节点此时都占用着数据库资源.性能问题
> - 协调者单点故障问题 一旦事务协调者节点挂掉，会导致参与者收不到提交或回滚的通知，从而导致参与者节点始终处于事务无法完成的中间状态,
> - 丢失消息导致的数据不一致问题 发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就会导致节点间数据的不一致问题

> **3pc**
>
> 三阶段提交协议**在协调者和参与者中都引入 超时机制**，2PC只有协调者才拥有超时机制
> 并且把两阶段提交协议的第一个阶段拆分成了两步: 询问，然后再锁资源，最后真正提交。三阶段提交的三个阶段分别为: can_commit，pre_commit，do_commit。，相较于2PC而言，多设置了一个缓冲阶段保证了在最后提交阶段之前各参与节点的状态是一致的。

### 分布式ID

> 雪花花法
>
> - 1bit 符号位
> - 41bit 时间戳位
> - 10bit 工作进程位以及
> - 12bit 序列号位。
>
> 在同一个进程中，它首先是通过时间位保证不重复，如果时间相同则是通过序列位保证。同时由于时间位是单调逆增的，且各个服务器如果大体做了时间同步，那么生成的主键在分布式环境可以认为是总体有序的，这就保证了对索引字段的播入的高效性。
>
> ==服务器时钟回拨==
>
> 会导致产生重复序列，因此默认分布式主键生成器提供了一个最大容忍的时钟回拨毫秒数。
>
> 如果时钟回拨的时间超过最大容忍的毫秒数阀值，则程序报错;
>
> 如果在可容忍的范围内，默认分布式主键生成器会等待时钟同步到最后一次主键生成的时间后再继续工作。
> 最大容忍的时钟回拨毫秒数的默认值为0 ，可通过属性设置
> ==涉及场景==
>
> 实例停机，时钟回拨>实例重启>计算ID
> 实例运行中，时钟回拨，计算ID
> 造成时钟回拨的原因多种多样，可能是闰秒回拨，可能是NTP同步，还可能是服务器时间手动调整。总之就是时间回到了过去
> ==方案:==
> 1.少量服务器部署ID生成器实例，关闭NTP服务器，严格管理服务器。这种方案不需要从代码层面解决，完全人为管理
> 2.针对回退时间断的情况，如闰秒回拨仅回拨了1s，可以在代码层面通过判断暂停一定时间内的ID生成器使用，虽然少了几秒钟可用时间，但时钟正常后，业务即可恢复正常
> 3.实例启动后，改用内存生成时间。该方案为baidu开源的UidGeneratar使用的方案，由于实例启动后，时间不再从服务器获取，所以不管服务器时钟如何回拔，都影响不了SnowFLake的执行
>
> 4.实例停机)时钟回拨>实例重启计算ID 的情况，可以通过实例启动的时候，采用未使用过的workerId (采分布式存储，存储下来，比如redis zookeeper)

### 分布式缓存

> ==如何保证MySQL 和 Redis 的数据-致性?==
>
> **Cache-Aside Pattern (旁路缓存模式):** 旁路路由策略，在这种模式中，缓存和数据库的操作都是在应用程序中完成。
>
> 此模式是业务系统最常用的缓存策略。
>
> 读缓存:  先读缓存，缓存命中的话，直接返回数据;如果缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应
>
> 写缓存: step 1: 接收用户的数据写入的请求; step 2: 先写入数据库; step 3: 再写入缓存

> ==数据什么时候从数撼库(Mysql集群) 加 到存(如Redis群) 呢?==
> 懒汉模式:使用时临时加载缓存，当需要使用数据时，就从数据库中把它查询出来，然后写入缓存
>
> 饿汉模式，就是提前预加载缓存。在项目启动的时候，预加载数据到缓存

> ==Cache-Aside如何保证双写的数据一致性?==
>
> 策略一:先更数据库，再更缓存
>
> 策略二: 先删缓存，再更新数据库
>
> 策略三: 先更数据库，再删缓存。 
>
> 策略四: 延迟双删策略
>
> 策略五: 逻辑删除策略。 
>
> 策略六:先更数据库，再基于队列删缓存
> 并发场景下，微服务Provider实例A、 B同时进行同一个数据的更新操作，也就是两个线程同时操作。
>
> ==为何不更新缓存而是删除缓存?==
> 除了能够减少脏数据之外，更新缓存相对于删除缓存，还有两点劣势:
> (1)如果写入Cache的值，**是经过复杂计算才得到的话。更新缓存频率高的话，就会大大降低性能**
>
> (2)**及时更新缓存属于饿汉模式，适用于数据读取高频的场景。**在**写多读少的**情况下，数据很多时候还没被读取到，又被更新了，这也**浪费了Cache的空间，也降低了性能**
>
> 策略-: A update db => B update db => B update cache => A update cache  出现脏数据 3 4步骤操作存属于高并发很难保证先后
> 策略二: A delete cache => B select null,load db,update cache =>A update db  db 和数据不一致 ，中间环节刷入的cache过期时间较长的话，脏数据存活时间过长
>
> 策略三: A update db => B load cache => A delete cache  中间短暂不一致 以及 如果了 步出现卡顿或者失败 会出现cache长期不一致
> 策略四: 延迟双删是基于策略二进行改进，就是先删Cache，后写DB，最后延迟一定时间，再次删Cache A delete cache =>B select null,load db,update cache => A update db =》 A delay deletecache 写操作比较频繁，可能会对Redis造成一定的压力,极端情况下，第二次延迟删Cache失败，操作的效果遇化到策略二。DB和Cache存在较长时间的数据不一致，这个时间会一直持续到Cache过期
> 策略五:查询的时候，检查 逻辑过期时间 LogicExpireTme ，如果发现到时间了，另外有一个缓存的重建线程，异步重建。
> 策略六: 针对策略三的改进
> 第1种细分的方案:基于内存队列删除缓存  支持重试、db和cache操作职责解 / 队列任务多，效率低，可以引入多线程，jvm崩溃，队列数据丢失
> 第2种细分的方案: 基于消息队列删除缓存比1种 更可靠，避免丢失 rocketmg 同步发送
>
> 第3种细分的方案: 基于binlog+消息队列删除缓存 完全解耦  canal 采数据写Mysql时生成binlog日志，然后将日志发送到RocketMq队列。在消费端，可以编写一个专门的消费者(Cache DeletenConsumer)完成缓存binlog日志订阅，筛选出其中的更新类型Log，解析之后进行对cache的删除操作并且通过RocketMq队列ACK机制确认处理这条更新Log，保证Cache除能够得到最终的删除

### redis

> ==主从模式==
>
> 全量同步:master将完整内存数据生成RDB，发送RDB到sLave。后续命令则记录在repl_baklog，逐个发送给slave。
>
> 增量同步: sLave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave
>
> ==同步时间点==
>
> **全量同步** 
>
> slave节点第一次连接master节点时
>
> slave节点断开时间太久，repl_baklog中的offset已经被覆盖
>
> **增量同步**
>
> slave节点断开又恢复，并且在repl_baklog中能找到offset时

> ==哨兵模式==
>
> **选举新的master依据**
> 1、首先会判断slave节点(与master节点断开时间长短，如果超过指定值 (down-after-mitliseconds *10)则会排除该slave节点
> 2、判断slave节点的(sLave-priority值，越小优先级越高)，如果是0则永不参与选举。
>
> 3、如果slave-prority一样，则判断slave节点的offset值，越大说明数据越新，优先级越高
>
> 4、判断slave节点的运行id大小，越小优先级越高。
> **选完master后切换**
> 1、sentinel给备选的slave1节点发送slaveof no one命令，让该节点成为master
>
> 2、sentinel给所有其它sLave发送slaveof 192.168.150.101 7002 命令，让这些slave成为新master的从节点，开始从新的master上同步数据
>
> 3、最后，sentinel将故障节点标记为slave，当故障节点恢复后会自动成为新的master的slave节点
>
> **Sentinel的三个作用是什么?**
>
> 监控
>
> 故障转移
>
> 通知
>
> **Sentinel如何判断一个redis实例是否健康?**
>
> 每隔1秒发送一次ping命令，如果超过一定时间没有响应则认为是主观下线，如果大多数sentinel都认为实例主观下线，则判定服务下线

> ==cluster模式==
>
> **解决**
>
> 海量数据存储问题
>
> 高并发写的问题
>
> **存储**
>
> 集群中有多个master，每个master保存不同数据
>
> 每个master都可以有多个slave节点
>
> master之间通过ping监测彼此健康状态
>
> 客户端请求可以访问集群任意节点，最终都会被转发到正确节点
> Redis会把每一个master节点映射到0~16383共16384个插槽 (hash slot)上，
>
> 数据key不是与节点绑定，而是与插槽绑定。redis会根据key的有效部分计算插槽值，分两种情况
>
> key中包含”{}”，且“{}“中至少包含1个字符，“{}“中的部分是有效部分
>
> key中不包含”{}”，整个key都是有效部分
>
> **计算方式**是利用CRC16算法得到一个hash值，然后对16384取余得到的结果就是slot值
>
> **如何将同一类数据固定的保存在同一个Redis实例**? 这一类数据使用相同的有效部分，例如key都以{typeId}为前缀

## mysql篇

> ==bin Log作用是什么?==
>
> 用来记录MySQL中增删改时的记录日志,最大的用处就是进行**主从复制，以及数据库的恢复**
> ==redo Log作用是什么?==
> 用来在MySQL宕机情况下将不完整的事务执行数据纠正。数据库的更新操作会在内存中先执行，最后刷入磁盘,redo log就是(为了恢复更新了内存但是由于宕机等原因没有刷入磁盘中的那部分数据.
> ==undo Log作用是什么?==
> 用来回滚到某一个版本，是一种逻辑日志。记录的是修改之前的数据，
> 当delete一条记录时，undolog中会记录一条对应的insert记录，从而保证能恢复到数据修改之前。在执行 事务回滚的时候，就可以通过undo log中的记录内容并以此进行回滚

> ==主从同步?==
> 1、在从库B上通过change master命令，设置主库A的IP、端口、用户名、密码，以及要从哪个位置开始请求binlog，这个位置包含文件名和日志偏移量
> 2、在从库B上执行start slave命令，这时从库会启动两个线程，就是图中的I/0线程和SQL线程。其中I/0线程负责与主库建立连接
> 3、主库A校验完用户名、密码后，开始按照从库B传过来的位置，从本地读取binlog，发给B
>
> 4、从库B拿到binlog后，写到本地文件，称为中继日志
>
> 5、SQL线程读取中继日志，解析出日志里的命令，并执行
>
> ==Mysql主从同步延时产生原因?怎么优化?==
>
> 主节点如果**执行一个很大的事务**，那么就会对主从延迟产生较大的影响
> **网络延迟**，日志较大，slave数量过多
> **主上多线程写入，从节点只有单线程同步**
> 机器性能问题，从节点是否使用了“烂机器"
> **锁冲突问题**也可能导致从机的SQL线程执行慢
>
> 1)大事务: 将大事务分为小事务，分批更新数据
> 2)减少slave的数量，不要超过5个，减少单次事务的大小
> 3)Mysql 5.7之后，可以使用多线程复制，使用MGR复制架构
> 4)在磁盘、raid卡、调度策略有问题的情况下可能会出现单个IO延迟很高的情况，可用iostat命令查看 DB数据盘的I0情况，再进一步判断
> 5)针对锁问题可以通过抓去processlist以及查看information_schema下面和锁以及事务相关的表来查 看
> 主机与从机之间的物理延迟是无法避免的，既然无法避免就可以考虑尝试**通过缓存等方式，降低新修改 数据被立即读取的概率**
>
> ==Mysql主从复制同步方式有哪些?==
>
> (1)异步复制 是主库写入binlg日志后即可成功返回客户端，无须等待binlog日志传递给从库的过程
> (2)同步复制 Master主机将事件发送给SLave主机后会触发一个等待，直到所有SLave节点(如果有多个sLave)返回数据复制成功的信息给Master
> (3)半同步复制 言，Master主机将事件发送给SLave主机后会触发一个等待，直到其中一个SLave节点(如果有多个slave) 返回数据复制成功的信息给Master
> 如果因为网络延迟等原因造 成SLave迟迟没有返回复制成功的信息，超过了Master设置的超时时长，半同步复制就降级为异步复制 方式，而后继续数据复制

> ==读写分离架构中经常出现，那就是谈延迟的问题如何解决?==
> 1、mysqL5.7的主从复制是多线程，一般也能满足
>
> 2、业务层面妥协，是否操作完之后马上要进行读取
>
> 3、这类的读取直接走主库，sharding jdbc 提HintManager.getInstance().setMasterRouteOnly();

> ==MVCC机制如何解决幻读?==
> **幻读:** : 事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次 搜索发现有N+M条数据了，就产生了幻读。(针对insert)
> **MVCC只在读提交 RC /可重复读 RR两种隔离级别下工作**
> 在**RR的隔离级别下，Innodb使用MVCC和 next-key Locks(行锁和间锁的组合)解决幻读**
> 1、MVCC解决的是普通读(快照读)的幻读，
> 2、next-key Locks解决的是当前读情况下的幻读
> ==mvcc 工作流流程==
> 1.首先获取事务自己的版本号，也就是事务 ID;
> 2.获取 ReadView 读试图;
> 3.查询得到的数据，然后与 Readview 中的事务版本号进行比较;
> 4.如果不符合 Readview 规则，就需要从 Undo Log 中获取历史快照
> 5.最后返回符合规则的数据。
>
> ==MVCC解决的问题==
>
> 1.读写之间阻塞的问题。
> 通过MVcc可以让读写互相不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务并发处理能力。
> 2.降低了死锁的概率。
> 这是因为MVCC采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行。
> 3.解次快照读的问题。
> 当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。

> ==readview读取场景==
>
> RC 读已提交(Read Committed) 时，一个事务中的每一次 SELECT 查询都会重新获取一次Read View
>
> RR 可重复读的时候，就避免了不可重复读，这是因为一个事务只在第一次 SELECT 的时会 获取一次 ReadView，而后面所有的 SELECT 都会复用这个 Read View

> ==mysql间锁是如何解决幻读?==
> **MySQL间隙锁+记录锁 ，组合起来，解决的是当前读情况下的幻读**
> 1.记录锁(Record Lock) : 直接加在索记录上面
>
> 2.间隙锁 Gaps Lock  当我们使用范围条件而不是相等条件检索数据，并请求共享或者排他锁时，InnoDb会符合条件的数据记录的索引项加锁；对于键值在条件范围内但不存在的记录叫做间隙 GAP，InnoDB也会对这个间隙加锁，这种机制就叫做间隙锁
> 3.Next-Key Lock: 记录锁与间隙锁组合起来用就叫做Next-Key Lock

> ==快照(历史数据) - mvcc==
> mvcc基于版本的控制协议。该技术不仅可以保证innodb的可重复读，而且可以防止幻读
> 但是它防止的是快照读，也就是读取的数据虽然是一致的，但是数据是历史数据。
> 快照读对应的sql 语法: 简单的select操作(不包括 select . lock in share mode，select .. forupdate)
> ==当前读(最新数据) - next-key Lock==
> 一个事务，其内部读取对应某一个数据的时候，数据都是一样的，同时读取的数据是最新的数据.
> innodb提供了next - key Lock，也就是结合gap锁与行锁，达到最终目的。
> select * from table where ? lock in share mode ;
>
> select * from table where ? for update;
>
> insert into table walues (..) ;
>
> update table set ? where ?;
>
> delete from table where ?;

> 表级锁 :开销小，加锁快，不会出现死锁;锁定粒度大，发生锁冲突的概率最高，并发度最低;MyISAM,MEMORY，CSV等一些非事务性存储引擎。
> 行级锁 :开销大，加锁慢;会出现死锁;锁定粒度最小，发生锁冲突的概率最低，并发度也最高: InnoDB存储引擎
> 页面锁 : 开销和加锁时间界于表锁和行锁之间;会出现死锁;锁定粒度界于表锁和行锁之间，并发度一般。BerkeLeyDB存储引擎

> 共享锁: 阻塞写(X)，但是不会阻塞读(S) select.. in share mode 获得共享锁,
> 排他锁: 读(S)和写(X)都阻塞  select... for update 获得排他锁

> ==**记录锁:**== 对表中的记录加锁，叫做记录锁，简称(行锁。**要锁的列没有索引，进行全表记录加锁**。 也是排它(X)锁，所以会阻塞其他事务对其插入、更新、删除
>
> ==**临键锁(Next-Key Locks** :== Next-key锁是**记录锁和间隙锁的组合**，它指的是加在某条记录以及这条记录前面间隙上的锁。一种特殊的间隙锁。
> 每个数据行上的(非唯一索引列上都会存在一把临健锁，当某个事务持有该数据行的临键锁时，会锁住一段左开右闭区间的数据
> ==**意向锁**==
> 意向共享(IS)锁: 事务有向对表中的某些行加共享锁(S锁)
> 意向排他(IX)锁: 事务有意向对表中的某些行加排他锁(X锁)
>
> 意向共锁 (IS)和 意向排他锁 (IX) 都是锁表。
> **意向锁是一种 不与行级锁冲突的表级锁**，这一点非常重要。
> 意向锁是 InnoDB 自动加的， 不需用户干预。
> 意向锁是在 InnoDB 下存在的内部锁，对于MyISAM 而言 没有意向锁之说。
> 意向锁类似于一种全局性的许可，可以直接查看全局是否存在锁有没有释放，比如事务A获取了表行锁，事务B想要获取表锁，就得挨个判断。有了意向锁就不需要了。它的存在是为难 表级 排他(X)/共享(X)锁。
>
> ==**插入意向锁:**==
> 1、插入意向锁是一种特殊的间隙锁 -- 间隙锁可以锁定开区间内的部分记录
> 2、插入意向锁之间互不排斥，所以即使多个事务在同一区间插入多条记录，只要记录本身 (主键、唯一索引)不冲突，那么事务之间就不会出现冲突等待。
> 3、RR的事务隔离级别下，使用插入意向锁来控制和解决并发插入

> ==什么是索引下推?==
> 索引下推 也被称为索引条件下推 (Index Condition Pushdown) ICP
> 5.6之前通过**非主键索引查询时**，存储引擎通过索引查询数据，然后将结果返回给MySQL server层，在server层判断是否符合条件，
>
> 在以后的版本可以使用索引下推，当存在索引列作为判断条件时，Mysql server 将这一部分判断条件传递给存储引擎，
> 然后存储引擎会筛选出符合传递传递条件的素引项，即**在存储引擎层根据索引条件过滤掉不符合条件的索引项，然后回表查询得到结果，将结果再返回给Mysql server**
> **某些场景下，可以减少回表次数。**

> ==什么是MRR优化?==
>
> MRR，全称 [Multi-Range Read 0ptimization]。
> 在不使用 MRR 时，优化器需要根据二级索引返回的记录来进行“回表”，这个过程一般会有较多的随机 I0,使用MRR 时，SQL 语句的执行过程是这样的:
> 1、先把通过二级索引取出的值缓存在缓冲区中,
> 这个缓冲区叫做 read_rnd_buffer ，简称 rowid buffer。
> 2、再把这部分缓冲区中的数据按照ID进行排序。
> 如果二级索引扫描到索引文件的末尾或者缓冲区已满，则使用快速排序对缓冲区中的内容按照主键进行排序;
> 3、然后再依次根据ID去聚集索引中获取整个数据行。
> 线程调用 MRR 接口取 rowId，然后根据rowId 取行数据;
> 当根据冲区中的 rowId 完数，则继续调用过程 2) 3)，直至扫描结束
> ==MRR 的本质:==
> 是**在回表的过程中， 把分散的无序回表， 变成排序后有序的回表**， 从而**实现 随机磁盘读 尽可能变成 顺序读**。**借助 空间的局部性原理和磁盘预读取等底层机制完成的**.、
> MRR 适用于range、ref、eq_ref的查询

## 分库分表篇

> ==常见分片算法？==
>
> **range 分片**:每个片，一段连续的数据，这个一般是按比如时间范围/数据范围(15 51~100)来的，容易发生数据倾斜，大量的流量都打在最新的数据上了.
>
> **ID取模分片**:此种分片规则将数据分成n份(通常dn节点也为n)，从而将数据均的分布于各个表中，或者各节点
> ==hash 哈希分布==
> **哈希取余分片**:每个数字进行哈希运算，然后对每个数的哈希结果除以节点数进行取余，余数为节点下标 对数据进行哈希，然后取余
> 数据节点伸缩时，导致数据迁移/迁移数量和添加节点数据有关，建议翻倍扩容(可以少迁移部分数据)
>
> **一致性哈希分片**: 将所有的数据当做一个token环，token环中的数据范围是0到2的32次方。然后为每一个数据节点分配一个token范围值，这个节点就负责保存这个范围内的数据。对每一个key进行hash运算，被哈后的结果在哪个token的范围内，则按顺时针去找最近的节点，这个key将会被保存在这个节点上
>
> 哈希结果一般情况下比较均匀/节点伸缩时，只影响邻近节点，但是还是有数据迁移/数据规模小的场景下，会出现单位时间内某个节点完全空闲的情况出现。 
>
> **虚拟槽分片:** 可以理解为范围分片的变种，预设虚拟槽，每个槽为一个hash值，每个node负责一定槽范围

> ==shardingjdbc分片策略?==
> **标准分片策略**
> 1.支持 PreciseShardingAlgorithm 和 RangeShardingAlgorithm 两个分片算法
>
> 2.其中 PreciseShardingAgorithm 是必选的，用于处理 =和 IN 的分片。
>
> 3.RangeShardingAlgorithm 用于处理BETWEEN AND， ，<，，s 条件分片，
>
> 4.RangeShardingAlgorithm 是可选的, 如果不配置RangeShardingAlgorithm，SQL中的条件等将按照全库路由处理
> **复合分片策略**
> 1.对应 ComplexShardingStrategy.。同样支持对 SQL语句中的，>，《， ， ，IN和 BETWEEN AND 的分片操作
> 2.支持多分片键
> **表达式分片策略 (inline内联分片策略)**
> 1.支持对 SQL语句中的 = 和 IN 的分片操作，但只支持单分片键。 
>
> 2.简单的分片，直接在配置文件中接着写规则，t_order_$-t_order_id % 43
> **强制分片略 (Hint 暗示分片策略)**
> 1.通过指定分片健而非SQL 中提取分片健的方式进行分片的策略。。 
>
> 2.HintShardingAlgorithm算法

> ==分库的join怎么解决?==
> 1、两个表用相同的分片建，
> 2、并且进行表绑定，防止产生数据源实例内的笛卡尔积路由。t1*t2

## 消息队列篇

> ==**优点**==
> **异步处理** - 相比于传统的串行、并行方式，减少了RT,提高了系统吞吐量。
>
> **应用解耦** - 系统间通过消息通信，不用关心其他系统的处理。一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，通过MQ解耦
> **流量削锋** - 可以通过消息队列长度控制请求量;可以缓解短时间内的高并发请求
> 日志处理  解决大量日志传输。
> 消息通讯  消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点息队列，或者聊天室等
>
> ==缺点==
>
> 系统可用性降低  那消息队列挂了，系统受影响
> 系统复杂度提高 一致性问题、可靠性传输、避免消息被重复消费等

> ==MQ选用==
> activeMQ 高并发、高负载以及高吞吐的复杂场景国内落地较少。
> rabbitMQ 落地的案例较多、社区活跃，但是基于erlang语言，定制和改造费事
> rocketMQ 阿里系，性能、场景经过实际验证，java语言，源码定制方便
> kafka 主要应用场景 实时日志采集、实时数据同步、实时数据计算，大数据领域

> ==选择依据==
>
> 1.协议: AMQP、STOMP、MQTT、私有协议等
>
> 2.消息是否需要持久化。
> 3.吞吐量。
> 4.高可用支持，是否单点。
>
> 5.分布式扩展能力。
>
> 6.消息堆积能力和重放能力。
>
> 7.开发便捷，易于维护。8.社区成熟度

> ==消息可靠性/一致性保证？==
>
> **rabbitMq**
>
> producer端
>
> - 事务机制
>
> - confirm确认机制，rabbitMq收到消息会给producer发送ack 或nck确认
>
> rabbitMq自身
>
> - 队列和消息设置持久化
>
> consumer
>
> - 手动ACK

> ==消息有序性保证？==
>
> **rabbitMq**
>
> - 拆分queue，使得一个queue只对应一个消费者
> - 多线程消费一个队列，使用重试机制判断顺序

> ==消息堆积处理？==
>
> **rabbitMq**
>
> - 解决consumer消费问题
> - 临时扩容，写一个临时分发数据的消费者程序，写入临时建立好的 N 倍数量的 queue中，临时征用 N 倍的机器来部署 consumer，每个 consumer 消费一个临时 queue 的数据。

> ==恢复队列中丢失的数据：？==
>
> **rabbitMQ**
>
> -  rabbitMQ，并且设置了过期时间，消息在 queue 里积压超过一定的时间会被 rabbitmq 清理掉，导致数据丢失
> -  流量低峰期，写一个程序，手动去查询丢失的那部分数据，然后将消息重新发送到mq里面，把丢失的数据重新补回来。

> ==MQ长时间未处理导致MQ写满的情况如何处理?==
>
> 丢弃+批量重导
>
> 临时写个程序，连接到mq里面消费数据，消费一个丢弃一个，快速消费掉积压的消息，降低MQ的压力，然后在流量低峰期时去手动查询重导丢失的这部分数据。

> ==高可用保证？==
>
> **rabbitMq**
>
> - 单机模式
> - 普通集群模式  队列 queue 的消息只会存放在其中一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据（元数据是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）
> - **镜像模式**  每个 RabbitMQ 节点都有这个 queue 的完整镜像，任何一个机器宕机了，其它机器节点还包含了这个 queue 的完整数据，其他消费者都可以到其它节点上去消费数据

## ES篇

> ==ELasticsearch 中素引在设计阶段如何调优?==
>
> 1)根据业务增量需求，采取基于日期模板创建索引，通过roll over- API滚动索引;
> 2)使用别名进行索引管理;
> 3)每天凌晨定时对索引做force_merge操作，以释放空间;
> 4)采取冷热分离机制，热数据存储到SSD，提高检索效率; 冷数据定期进行shrink操作，以缩减存储;
> 5)采取curator进行索引的生命周期管理;
> 6)仅针对需要分词的字段，合理的设置分词器;
> 7)Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。

> ==es master选举==
> **前提**
> 1、只有候选主节点 (master: true) 的节点才能成为主节点
> 2、最小主节点数(min_master_nodes)的目的是防止脑裂。
> 首先确认候选主节点数达标，也就是discovery.zen,minimum_master_nodes
>
> 选主
> 1、ELasticsearch 的选主是 ZenDiscovery 模块负责的，主要包含 Ping (节点之间通过这RPC 来发 现彼此)和 Unicast (单播模块包含一个机列表以控制哪些节点需要 ping 通)这两部分
> 2、对所有可以成为 master 的节点 (**node.master: true) 根据 nodeId 字典排序**，每次选每个节 点都把自己所知道节点排一次序，然后选出第一个 (第0  位)节点，暂且认为它是 mastel
> 节 点。
>
> ​    3、如果**对某个节点的投票数达到一定的值 (可以成为 master 节点数 n/2+1)** 并且该节点自己选 举自己，那这个节点就是 master。否则重新选举一直到满足上述条件。
>
> ​    4、master 节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理;data 节点可以 关闭 http功能。

> ==脑裂问题==
> 其实 就是选举master的 配置导致 7.4版本后已被移除  这个配置就是说 当前node想要成为master，得多个node同意才行。
>
> 脑裂问题 就是比如 master slave slave 一主两从 主机后 两从之间选取一个master 而原先故障master重启后 ，按选举配置 自己给自己投一票成为master 就形成脑裂现象。
>
> 简单描述就是 多个master共存的 现象。
>
> 脑裂”问题可能的成因: (有两个master)
> 网络问题: **集群间的网络延迟导致一些节点访问不到 master，认为 master 挂掉了**从而选举出新 的master，并对 master 上的分片和副本标红，分配新的主分片
>
> 节点负载: **主节点的角色为 master 又为 data**，**访问量较大时可能会导致 ES 停止响应造成大面积延迟，**此时其他节点得不到主节点的响应认为主节点挂掉了，会重新选取主节点.
> 内存回收: **data 节点上的 ES 进程占用的内存较大，引发 JVM 的大规模内存回收**，造成 ES 进程 失去响应。
> 脑裂问题解决方案
> **减少误判**: discovery.zen.ping_timeout 节点状态的响应时间 (超过这个时间就会重新选举master)，默认为 3s，可以适当调大，如果 **master在该响应时间的范围内没有做出响应应答**， 判该节点已经挂掉了。**调大参数** (如 6 s，discovery,zen,ping_timeout:6)，可适当减少误判
> 选举触发: discovery.zen.minimum_master_nodes:1 该参数是用于控制选举行为发生的最小集主节点数量。当备选主节点的个数大于等于该参数的值， 且备选主节点中有该参数个节点认为主节点挂了，进行选举。官方建议为 **(n/2) +1，n 为主节点个数(即有资格成为主节点的节点个数)**
> 角色分离: 即 master 节点与 data 节点分离，限制角色 主节点配置为: node.master: true node.data: false 从节点配置为: node.master: false node.data: true

> ==全文索引/倒排索引==
> 简单来说 就是针对 搜索的关键词建立索引 然后根据这个索引 查找文档的过程 ，存的时候，对关键词进行分词 建立索引，一同建立的还有这个索引 和文档的 映射关系。

> tf term frequency 描述的是关键词在文档中出现的次数 越大 权重越高
> df document frequency 有多少文档包含此关键词 越大说明越普遍，说明权重越低不重要。

> ==写入过程==
> 客户端选择node发送，这个节点属于协调节点。
>
> 协调节点根据文档ID进行路由，hash 取模 获取数据应该存在在哪个node，转发至实际node处理
>
> 实际的节点主分片primary shard 复制处理请求，然后将数据同步的副本节点上 replcia node
>
> 协调节点等主分片和副本分片都执行成功后，返回响应给客户端

> ==主分片写入过程分析==
> 先写入memory buffer 内存缓冲区
> 然后 每隔1s从缓冲区读取并写入segment文件中(这个文件存储的就是索引集合)，同时进入filesystem cahe，完事后清空内存缓冲区。这个叫refresh 也就是 es 1s 延迟的由来

> ==保证memory buffer filesystem cache 可靠性==
> **es通过transLog保证**。写入缓冲区同时，会进行translog日志记录，用于岩机重启恢复。translog也是先写入filesystem cache然后 5s后刷到磁盘 ，其实也会有丢失问题。强制每次写操作都刷，会有性能问题
>
> ==translog过大问题==
> 采用flush操作 文件过大超过值，会将内存中所有数据落盘后，清空translog日志。

> ==es 搜索过程==
> **query+fetch过程**
>
> 1、搜索被执行成一个两阶段过程，我们称之为Query Then Fetch;
>
> 2、在初始查询阶段时，查询会广播到索引中每一个分片拷贝 (主分片或者副本分片)。 每个分片在本地执行搜索并构建一个匹配文档的大小为from + sze的优先队列、PS:在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在MemoryBuffer，所以搜索是近 实时的.
> 3、每个分片返回各自优先队列中 所有文档的ID和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表
> 4、接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个GET请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。。一旦所有的文档都披取回了，协调节点返回结果给客户端
> 5、补充: Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term 和Document frequency，这个评分更准确，但是性能会变差。

> ==ELasticsearch更新和删除文档的过 程==
>
> 磁盘上的每个段都有一个相应的del文件
> 当删除请求发送后，文档并没有真的被删除，而是在**deL 文件中被标记为删除**。该文档依然能匹配查询但是会在结果中被过滤掉。当段合并时，在del文件中 被标记为删除的文档将不会被写入新段。
>
> 当执行更新时，旧版本的文档在 del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在 结果中被过滤掉

> ==ELasticsearch 如果保证读写一致==
>
> 可以通过**版本号使用乐观锁并发控制**，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突
> **对于写操作:**一致性级别支持 quorum/one/alL，默认为 quorum,quorum: 即只**有当大多数(一半以上)分片可用时才允许写操作**。但即使大多数可用，也 可能存在因为网络等原因导致写入本失败，这样该副本被认为故障，分片将会在一个不同 的节点上重建。 one: 即只要主分片数据保存成功，那么客户端就可以进行查询操作了。 al1: 是最高的一致性级别，要求所有分片的数据要部保存成功，才可以继续进行。
> 对于读操作:可以设置 replication 为 sync(默认为同步)，这使得提作在主**分片和副本分片都完成 后才会返回;** 设置 replication 为 async (异步)时，也可以通过**设置搜索请求参数_preference 为 primary 来查询主分片，确保文档是最新版本。**

> ==ELasticsearch索引文档的过程==
>
> 首先客户端向集群发出索引文档的请求，它会选择任何一个节点，这个节点当接收到请求后会根据路由算法找到应该放的那个主分片的位置，从而索引数据
> shard = hash(document_id) % (num_of_primary_shards)
> 1，当**分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer**，然后**定时(默认是每隔1秒)写入到 Filesystem Cache**，这个从MomeryBuffer到Filesystem Cache的过程就做 refresh
> 2、当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，**ES是通过translog的机制来保证数据的可靠性的**。其实现机制是**接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做fLush**;
> 3、在 fush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。
>
> 4、flush触发的时机是定时触发(默认30分钟)或者translog变得太大(默认为512M) 时



## docker篇

> **虚拟机**（virtual machine）是在操作系统中**模拟**硬件设备，然后运行另一个操作系统    操作系统中的操作系统
>
> **Docker**仅仅是封装函数库，并没有模拟完整的操作系统    系统进程

> **镜像（Image）**：Docker将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。
>
> **容器（Container）**：镜像中的应用程序运行后形成的进程就是**容器**，只是Docker会给容器进程做隔离，对外不可见。

> - docker run：创建并运行一个容器，处于运行状态
> - docker pause：让一个运行的容器暂停
> - docker unpause：让一个容器从暂停状态恢复运行
> - docker stop：停止一个运行的容器
> - docker start：让一个停止的容器再次运行
> - docker rm：删除一个容器
> - docker pull 拉取镜像
> - docker push 推送镜像
> - docker build 构建镜像
> - docker images 查看
> - docker rmi 删除镜像
> - docker save 保存镜像为压缩包
> - docker load 加载压缩包为镜像
> - docker volume命令是数据卷操作，根据命令后跟随的command来确定下一步的操作：
>
>   - create 创建一个volume
>   - inspect 显示一个或多个volume的信息
>   - ls 列出所有的volume
>   - prune 删除未使用的volume
>   - rm 删除一个或多个指定的volume

> **Dockerfile**就是一个文本文件，其中包含一个个的**指令(Instruction)**，用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层Layer。
>
> Compose文件是一个文本文件，通过指令定义集群中的每个容器如何运行  看做是将多个docker run命令写到一个文件

## 响应式编程篇

### RxJava

> 与传统的观察者模式不同：
>
> - RxJava中，在**主题内部有一个弹射器的角色**；而经典的观察者模式，主题所发送的是单个的消息，并不是一个消息序列
>
> - Observable 主题**还会负责消息序列缓存，这一点像经典的生产者消费者模式**

> 基于观察者模式设计
>
> **Observable类  等价于  观察者模式中的Subject（抽象主题）**
>
> **Subscriber类   等价于  观察者模式中的Observer（抽象观察者）**
>
> - Observable和Subscriber通过**subscribe()方法实现订阅关系**
> - Observable和Subscriber之间通过emitter.**onNext(…)弹射的方式实现主题的消息发布**
> - RxJava中主题的消息发布方式之一是通过内部的弹射器（Emitter）完成。弹射器除了调用
>   onNext()方法弹射消息之外，还定义了两个特殊的通知方法：onCompleted()和onError()
> - Subscriber有3个回调方法。其中，onNext(String s)回调方法用于响应
>   Observable主题的正常的弹射消息；onCompleted()回调方法用于响应Observable主题的结束消息；
>   onError(Throwable e)回调方法用于响应Observable主题的异常消息

> RxJava支持函数式编程，就是对subscribe()方法进行了重载，重载版本里对函数式接口进行了封装。实际上最终订阅者还是Subscriber。
>
> Hystrix大量使用RxJava里的函数式方式

> **背压问题**
>
> **当上下游的流操作处于不同的线程时**，如果**上游弹射数据的速度快于下游接收处理数据的速度**，这样对于那些没来得及处理的数据就会造成积压，这些**数据**既不会丢失，也不会被垃圾回收机制回收，而是**存放在一个异步缓存池中**，如果缓存池中的数据一直得不到处理，越积越多，最后就会造成**内存溢出**，这便是响应式编程中的背压问题。
>
> - Emitter.BackpressureMode.LATEST  **最近模式** 如果消费跟不上，则`仅缓存最近弹射出来的数据，将老旧一点的数据直接丢弃`
> - BackpressureMode.NONE和BackpressureMode.ERROR  **不使用背压模式**  在这两种模式中发送的数据，不使用背压。当上游Observable主题弹射数据的速度大于下游通
>   过Subscriber接收的速度，造成上游数据积压时，会抛出MissingBackpressureException异常
> - BackpressureMode.BUFFER  **缓冲模式**  在这种模式下，有一个无限的缓冲区（初始化时是128）。下游消费不了的元素，统统都会放
>   到缓冲区中。如果缓冲区中持续地积累，会导致内存耗尽，最终抛出OutOfMemoryException异常
> - BackpressureMode.DROP **固定缓冲区模式(丢弃模式)** 这种模式下Observable主题使用固定大小为1的缓冲区。如果下游订阅者无法处理，则流的第
>   一个元素会缓存下来，后续的会被丢弃

## 网络编程篇

> ==三次握手过程==
> TCP连接的建立时，双方需要经过三次握手，具体过程如下
> (1)第一次握手: **CLient进入SYN_SENT状态**，发送一个SYN来主动打开传输通道，该的SYN标志位被设置为1，同时会带上Client分配好的SN序列号，该SN是根据时间产生的一个随机值，通常情况下每间隔4ms会加1。除此之外，SYN还会带一个MSS(最大报文段长度)可选项的值，表示客户端发 送去的最大数据块的长度。
> (2)第二次握手: **Server端在收到SYN帧之后，会进入SYN_RCVD状态，**同时返回SYN+ACK顿给client，主要目的在于通知cLient，Server端已经收到SYN消息，现在需要进行确认。Server端发出的 SYN+ACK顿的ACK标志位被设置为1，其确认序号AN (Acknowledgment Number) 值被设置为Client的SN+1; SYN+ACK的SYN标志位被设置为1，SN值为Server端生成的 SN序号:SYN+ACK的MSS (最大报文段长度)表示的是Server端的最大数据块长度
> (3)第三次握手: **cLient在收到Server的第二次握手SYN+ACK确认顿之后，首先将自己的状态会从SYN_SENT变成ESTABLISHED**，表示自己方向的连接通道已经建立成功，CLent可以发送数据给Serve端了。然后，cLient发ACK给Server端，该ACK帧的ACK标志位被设置为1，其确认序号 AN(Acknowledqment Number) 值被设置为Server端的SN序列号+1。还有一种情况，client可能会将ACK城和第一怖要发送 的数据，合并到一起发送给Server端
> (4)**Server端在收到client的ACK帧之后，会从SYN_RCVD状态会进入ESTABLISHED状态**，至此Server方向的通道连接建立成功，Server可以发送数据给CLient，TCP的全双工连接建立完成。

> ==四次挥手具体过程，具体如下==
> (1)第一次挥手:**主动断开方(可以是客户端，也可以是服务器端)，向对方发送一个FIN结束请求报文**，此报文的FIN位被设置为1，并目正确设置Sequence Number (序列号) 和AcknowledqmentNumber (确认号)。发送完成后，主动断开方进入FIN_WAIT_1状态，这表示主动断开方没有业务数据要发送给对方，准备关闭S0CKET连接了。
> (2)第二次挥手:正常情况下，在收到了主动断开方发送的FIN断开请求报文后，**被动断开方会发送-个ACK响应报文**，报文的Acknowledament Number (确认号) 值为断开请求报文的Sequence Numb(序列号)加1，该ACK确认报文的含义是:“我同意你的连接断开请求"。之后，被动断开方就进入了CLOSE-WAIT(关闭等待)状态，TCP协议服务会通知高层的应用进程，对方向本地方向的连接已经关闭，对方已经没有数据要发送了，
> 若本地还要发送数据给对方，对方依然会接受。被动断开方的 CLOSE-WAIT (关闭等待)还要持续一段主动断开方在收到了ACK报文后，由FIN_WAIT_1转换成间，也就是整个CLOSE-WAIT状态持续的时间。FIN_WAIT_2状态。
> (3)第三次挥手:在发送完成ACK报文后，被动断开方还可以继续完成业务数据的发送，待剩余数据发送完成后，或者CLOSE-WAIT(关闭等待)截止后，被动断开方会向主动断开方发送一个FIN+ACK结 束响应报文，表示被动断开方的数据都发送完了，然后，被动断开方进入LAST_ACK状态。
>
> (4)第四次挥手:主动断开方收在到FIN+ACK断开响应报文后，还需要进行最后的确认，向被动断开 方发送一个ACK确认报文，然后，自己就进入TIME_WAIT状态，等待超时后最终关闭连接。处于TIME_WAIT状态的主动断开方，在等待完成2MSL的时间后，如果期间没有收到其他报文，则证明对方 已正常关闭，主动断开方的连接最终关闭。 被动断开方在收到主动断开方的最后的ACK报文以后，最终关闭了连接，自己啥也不管了

> `IO 多路复用  IO Multiplexing `  **是一种IO模型**
>
> 操作系统引入了一类**新的系统调用，专门用于查询IO文件描述符的（含socket连接）的就绪状态**
>
> Linux系统中，**通过select/epoll系统调用**，**一个用户进程（或者线程）可以监视多个文件描述符**，一旦某个描述符就绪（一般是内核缓冲区可读/可写），**内核能够将文件描述符的就绪状态返回给用户进程（或者线程），用户空间可以根据文件描述符的就绪状态，进行相应的IO系统调用**

> **Channel（通道）怎么理解？**
>
> NIO中的TCP传输通道，实际上就是对**底层的传输链路所对应的文件描述符（file descriptor）的一种封装**

> **通道类型？**
>
> （1）FileChannel文件通道，用于文件的数据读写；
> （2）**SocketChannel**套接字通道，用于Socket套接字**TCP连接的数据读写**；
> （3）**ServerSocketChannel**服务器套接字通道（或服务器监听通道），允许我们**监听TCP连接请求**，为每个监听到的请求，创建一个SocketChannel套接字通道；
> （4）DatagramChannel数据报通道，用于UDP协议的数据读写。

> **通道IO事件？**
>
> （1）可读：SelectionKey.OP_READ   
> （2）可写：SelectionKey.OP_WRITE
> （3）连接：SelectionKey.OP_CONNECT   完成了和对端的三次握手过程
> （4）接收：SelectionKey.OP_ACCEPT  监听到一个新连接的到来时  **接收就绪**
>
> 一条通道若能被选择，必须继承SelectableChannel类  ，它提供了实现通道的可选择性所需要的公共方法
>
> **FileChannel文件通道就不能被选择器复用**

> **selector** 
>
> Selector 选择器可以理解为一个**IO事件的监听与查询器**。通过选择器，一个线程可以查询多个通道的IO事件的就绪状态。**选择器和通道的关系，是监控和被监控的关系**  `它的使命是完成IO的多路复用`
>
> `简单来说一旦在通道中发生了某些IO事件（就绪状态达成），这个事件就被记录在SelectionKey的readyOps上，并且这个SelectionKey被记录在Selector内部`
> `的selectedKeys集合中。`

> **缓冲区**
>
> 缓冲区，实际上是一个容器，一个连续数组。Channel提供从文件、网络读取数据的渠道，但是**读写的数据都必须经过Buffer**。本质是为了完成NIO的非阻塞读写操作

> SelectionKey理解？
>
> - Selector并不直接去管理Channel，而是直接管理SelectionKey，通过SelectionKey与Channel发生关系
> - **类似一个中介者，同时拥有Selector  以及Channel**  ，也可以认为是一种关联表
> - Channel最多能向Selector注册一次，**注册之后就形成了唯一的SelectionKey**，然后**被Selector管理起来**
> - SelectionKey**是IO事件的记录者（或存储者**），SelectionKey 有两个核心成员，存储着自己关联的Channel上的感兴趣IO事件和已经发生的IO事件

> ==IO分类==
>
> 阻塞IO  blocking io
>
> 非阻塞IO non blocking io 
>
> IO多路复用  io multiplexing
>
> 信号驱动IO   signal driven io
>
> 异步IO  asynchronous  io 

> ==BIO==
>
> 两阶段等待  用户空间-内核空间
>
> 1、**用户进程尝试读取数据，内核数据没有，等待直至数据来了，内核将数据拷贝至用户缓冲区，用户进程解除阻塞，读取数据**
>
> ==NIO==
>
> 一节点非阻塞，二阶段阻塞
>
> **1、用户进程尝试读取数据，内核数据未到达，返回error给用户进程。**
>
> **2、用户进程再次循环读取。**
>
> **3、内核数据来了，拷贝至用户空间缓冲区，用户进程解除阻塞，读取数据。   拷贝过程中，用户进程阻塞。**
>
> ==IO多路复用==
>
> **文件描述符FD** file descriptor ,从0开始的无符号整数，用来关联linux的一个文件。包括socket
>
> **利用单个线程来监控FD,并在FD可读、可写时，得到通知**，进行处理。
>
> 监听FD 通知FD的方式 包括 **select  poll epoll**
>
> select  和poll 只是通知用户进程FD就绪，但是不确定是哪个FD，需要用户遍历确认
>
> epoll 则会在通知用户进程FD就绪同时，将就绪的FD写入用户空间

> ==select==
>
> 1、创建FD集合
>
> 2、将FD集合拷贝至内核态
>
> 3、内核态循环遍历，将有事件响应的FD集合返回
>
> 4、将FD集合拷贝至用户态
>
> 5、用户态再针对这个FD集合遍历，找到对应可读、可写的FD处理。
>
> ==poll==
>
> 本质上和select没有区别  最本质区别就是**它没有最大连接数的限制**，因为它基于链表存储的。
>
> ==epoll==
>
> 1、构建epoll对象
>
> 2、有连接接入时，会插入至epoll对象中。这个对象包含 红黑树和双向链表，fd插入至红黑树中。
>
> 3、一旦fd就绪，就会触发回调，将就绪的fd插入至就绪链表中，并唤醒用户进程
>
> 4、用户进程调用epoll_wait只需要检查就绪列表是否存在数据，有则返回给用户程序，否则进入等待队列。

基于epoll实例中的**红黑树保存**要监听的FD，**理论上无上限**，而且增删改查效率都非常高

每个**FD只需要执行一次epoll_ctl添加到红黑树**，以后每次epol_wait，**无需重复拷贝FD到内核空间**

利用ep_po无需传递任何参数ll_**callback机制来监听FD状态，无需遍历所有FD**，因此性能不会随监听的FD数量增多而下降

**事件通知模式**

LevelTriggered：简称LT，也叫做水平触发。只要某个FD中有数据可读，每次调用epoll_wait都会得到通知。

EdgeTriggered：简称ET，也叫做边沿触发。只有在某个FD有状态变化时，调用epoll_wait才会被通知。

<img src="img/6cadb9bca18b9745152d708b2ae431de.png" alt="img" style="zoom:50%;" />



### 

> ==信号驱动IO==
>
> 阶段一
>
> ①用户进程调用sigaction，注册信号处理函数
>
> ②内核返回成功，开始监听FD
>
> ③用户进程不阻塞等待，可以执行其它业务
>
> ④当内核数据就绪后，回调用户进程的SIGIO处理函数
>
> 阶段二：
>
> ①**收到SIGIO回调信号**
>
> ②调用recvfrom，**读取**
>
> ③**内核将数据拷贝到用户空间**
>
> ④**用户进程处理数据**

> ==异步IO  AIO==
>
> 整个过程都是非阻塞的，用户进程调用完异步API后就可以去做其它事情，内核等待数据就绪并拷贝到用户空间后才会递交信号，通知用户进程.
>
> 阶段一
>
> ①用户进程调用aio_read，**创建信号回调函数**
>
> ②**内核等待数据就绪**
>
> ③用户进程**无需阻塞，可以做任何事情**
>
> 阶段二：
>
> ①内核数据**就绪**
>
> ②内核数据**拷贝到用户缓冲区**
>
> ③拷贝完成，内核递交信号**触发aio_read中的回调函数**
>
> ④**用户进程处理数据**

## 反应器模式 Reactor

> Reactor反应器模式**由Reactor反应器线程、Handlers处理器两大角色组成**，也叫Dispatcher模式  **`是一种线程模型`**
> （1）Reactor反应器线程的职责：负责响应IO事件，并且分发到Handlers处理器。
> （2）Handlers处理器的职责：非阻塞的执行业务处理逻辑

> 单线程Reactor反应器模式的缺点
>
> 单线程反应器模式中，**Reactor反应器和Handler处理器都执行在同一条线程上**  容易造成阻塞问题

> 多线程版本的反应器模式
>
> （1）将负责**数据传输处理的IOHandler处理器的执行，放入独立的线程池中**。这样，**业务处理线程与负责新连接监听的反应器线程就能相互隔离**，避免服务器的连接监听受到阻塞。
> （2）**如果服务器为多核的CPU**，可以将反应器线程拆分为多个子反应器（SubReactor）线程；同时，引入多个选择器，并且**为每一个SubReactor引入一个线程，一个线程负责一个选择器的事件轮询**。

> 1. 反应器模式和生产者消费者模式对比
>
>    一定程度上，反应器模式有点类似生产者消费者模式。但是**反应器模式没有专门的队列去缓冲存储IO事件**，是直接分发的。
>
> 2. 反应器模式和观察者模式（Observer Pattern）对比
>
>    相似之处在于分发的思想，不同之处在于反应器一个事件只能被一个Handler处理，观察者模式中，同一个主题可以被订阅过的多个观察者处理。

## netty

> **netty的反应器模式**
>
> - **通道注册** 封装了NIO的Selector组件和Thread线程实例，设计了自己的Reactor角色，名称叫做EventLoop（事件循环），封装了NIO的Channel组件也叫Channel，所以所谓通道注册就是将Netty的Channel注册到EventLoop上
> - **查询事件** EventLoop内部Thread不断地轮询(**一个线程会负责一个反应器**)，查询选择器Selector中的IO事件
> - **事件内部分发、数据读取和发射**  传统反应器模式是将分发和数据读取分开，netty这里有点不一样。反应器EventLoop这两个操作都接管了。**EventLoop能访问到通道的Unsafe成员，当IO事件发生时，直接通过Unsafe成员完成NIO底层的数据读取**。EventLoop**读取到的数据后，会把数据发射到Channel内部的Pipeline流水线通道**
> - **流水线传播和业务处理**  Netty通过责任链模式将多个业务处理器组织起来，成为一个pipeline（流水线）。由通道负责管理，属于通道的一部分。

> **netty中的通道**
>
> NioSocketChannel：异步非阻塞TCP Socket传输通道。
> NioServerSocketChannel：异步非阻塞TCP Socket服务器端监听通道。  。。。其他不说明了
>
> 比如 Netty的NioSocketChannel**内部封装了一个Java NIO的SelectableChannel**成员，通过对该内部的Java NIO通道的封装，对Netty的NioSocketChannel通道上的**所有IO操作**，**最终会落地到Java NIO的SelectableChannel底层通道**。

> **Netty中的Reactor 反应器**
>
> 1. Netty中的**反应器组件有多个实现类，这些实现类与其Channel通道类型相互匹配**
>
>    对应于**NioSocketChannel**通道，Netty的反应器类为**NioEventLoop ** 一个NioEventLoop拥有一个Thread线程，负责一个Java NIO Selector选择器的IO事件、轮询。

> **Netty中的Handler处理器**
>
> 第一类是**ChannelInboundHandler入站处理器**；负责接收（或者执行）
>
> 第二类**是ChannelOutboundHandler出站处理器 **指的是从**ChannelOutboundHandler处理器到通道的某次IO操作**

> **ChannelPipeline**（通道流水线）的默认实现，实际上被设计成一个**双向链表**。所有的Handler处理器实例被包装成了双向链表的节点，被加入到了ChannelPipeline（通道流水线）中。

> Bootstrap类是Netty提供的一个便利的工厂类，可以通过它来完成Netty的客户端或服务器端的Netty组件的组装，以及Netty程序的初始化和启动执行。

> **父子通道**
>
> 在Netty中，**将有接收关系的监听通道和传输通道，叫做父子通道**。
>
> 其中，**负责服务器连接监听和接收的监听通道**（如NioServerSocketChannel），也叫父通道（Parent Channel）。
> 对应于**每一个接收到的传输类通道**（如NioSocketChannel），也叫子通道（Child Channel）

> **EventLoopGroup  就是多线程版本的反应器模式**
>
> EventLoopGroup轮询组就是一个**多线程版本的反应器**，其中的**单个EventLoop线程对应于一个子反应器（SubReactor**）。
>
> EventLoopGroup的构造函数有一个参数，用于指定内部的线程数。在构造器初始化时，会按照传入的线程数量，在**内部构造多个Thread线程和多个EventLoop子反应器（一个线程对应一个EventLoop子反应器），进行多线程的IO事件查询和分发。**
>
> 如果使用EventLoopGroup的无参数的构造函数，默认的EventLoopGroup内部线程数量为最大可用的CPU处理器数量的2倍
>
> Boss）轮询组： 新连接的监听和接收
>
> Worker）轮询组：  查询所有子通道的IO事件，并且执行对应的Handler处理器完成IO处理

> Netty零拷贝实现方式？  `注意和操作系统的零拷贝区别`
>
> （1）Netty提供**CompositeByteBuf组合缓冲区类**, 可以**将多个ByteBuf合并为一个逻辑上的ByteBuf**, 避免了各个ByteBuf之间的拷贝。
> （2）Netty提供了ByteBuf的**浅层复制操作（slice、duplicate**），可以将ByteBuf**分解为多个共享同一个存储区域的ByteBuf,** 避免内存的拷贝。
> （3）在使用Netty进行**文件传输时**，可以调用**FileRegion包装的transferTo**方法，**直接将文件缓冲区的数据发送到目标Channel**，避免普通的循环读取文件数据和写入通道所导致的内存拷贝问题。
> （4）在将一个**byte数组转换为一个ByteBuf对象的场景**，Netty**提供了一系列的包装类，避免了转换过程中的内存拷贝。**(Unpooled了提供了一系列的wrap包装方法，帮助大家方便快速包装出CompositeByteBuf
> 实例或者ByteBuf实例，而不用进行内存的拷贝)
> （5）如果**Channel接收和发送ByteBuf都使用direct直接内存进行Socket读写，不需要进行缓冲区的二次拷贝**。

> ByteBuf 核心优势
>
> **池化机制**
> 可以重用池中 ByteBuf 实例，减少内存分配与释放的开销，减少内存溢出的机会。
> **读写指针分离**
> 读取和写入索引分开，不需要像 ByteBuffer 一样，调用flip()方法去切换读/写模式，使用起来更加便捷。
> **可以自动扩容**
> ByteBuffer的内部数组大小是固定的，初始化之后，不支持动态扩容。ByteBuf 实例可以自动进行扩容。
> **支持零拷贝**
> ByteBuffer所提供零拷贝机制更好的提高性能，例如 slice切片、duplicate浅层复制、CompositeByteBuf等等

> **池化**
>
> 创建一个缓冲区对象池，将没有被引用的 ByteBuf 对象，放入对象缓存池中；当需要时，则重新从对象缓存池中取出，而不需要重新创建
>
> **扩容**
>
> 写入后新的数据规模未超过64，则选择则扩容后 capacity 是 64；
> 写入后新的数据规模超过 64，则选择64的下一个 2^n，例如128/256/512等，一直到满足需要为止；
> 扩容不能超过 max capacity ，超过会报错。
>
> Netty的**ByteBuf的内存回收工作是**通过引用计数的方式管理的。（引用计数的一系列方法定义在ReferenceCounted 接口中，每个 ByteBuf 都实现了
> ReferenceCounted 接口）
>
> 在默认情况下，当创建完一个ByteBuf时，它的引用为1；每次调用retain()方法，它的引用就加1；每次调用release()方法，就是将引用计数减1；
> 如果引用为0，再次访问这个ByteBuf对象，将会抛出异常；如果引用为0，表示这个ByteBuf没有哪个进程引用它，它占用的内存需要回收
>
> **（这里的回收分为）**
>
> - 属于Pooled池化的ByteBuf内存，放入可以重新分配的ByteBuf池子，等待下一次分配
> - 未池化的ByteBuf缓冲区，如果是堆（Heap）结构缓冲，会被JVM的垃圾回收机制回收；如果是Direct直接内存的类型，则会调用本地方法释
>   放外部内存（unsafe.freeMemory）。

> (1) 粘包，指Receiver ((接收端) 收到一个BteBuf，包含了Sender (发送端)的多个ByteBuf)，发送端的多个ByteBuf在接收端“粘”在了一起。
>
> (2)半包，就是Receiver将Sender的一个ByteBuf“拆”开了收，收到多个破碎的包。换句话说，Receiver收到了Sender的一个ByteBuf的一小部分。

> ==拆分阶段(粘包、半包,原因)==
> DMA复制阶段，DMA设备会把内核缓冲区(Socket发送缓冲区) 中的数据复制到网卡设备中，会进行二进制数据的合并或者拆分
> TCP协议报文的有效数(净数据) 大小是有限制的，MSS,也会合并或者拆分

> ==解决方式==
> 将读取到的进程缓冲区ByteBuf，在应用层进行二次组装，重新组装我们应用层的数据包
> (1)**可以自定义解码器分包器:** 基于ByteToMessageDecoder或者ReplayingDecoder，定义自己的用户缓冲区分包器。
> (2)**使用Netty内置的解码器。**如可以使用Netty内置的(LengthFieldBasedFrameDecoder) 自定义长度敬据包解码器。对用户缓冲区ByteBuf进行正确的分包。
>
> FixedLengthFrameDecoder  LengthFiedBasedFrameDecoder ，固定长度是消息头指定消息长度的一种形式，进行粘包拆包处理的。
> LineBasedFrameDecoder 、DelimiterBasedFrameDecoder ，换行是于指定消息边界方式的-种形式，进行消息粘

> ==ByteToMessageDecoder(抽象类)解码的流程==
> 首先，它将上一站传过来的输入到Bytebuf中的数据进行解码，解码出一个List对象列表(这个List来源于子类解码后，添加到父类的集合中):
> 然后，迭代List列表，逐个将Java POJ0对象传入下一站Inbound入站处理器

> ==解码器有ByteToMessageDecoder和MessageToMessageDecoder两大基类==。
> 如果要从ByteBuf到POJ0解码，则可继承ByteToMessageDecoder基类; 如果要从某一种POJ0到另一种POJO解码，则可继承MessageToMessageDecoder基类。
> Netty提供了不少开箱即用的Decoder解码器，能满足很多解码的场景需求，几个比较基础的解码器如下:
> 1、固定长度数据包解码器-FixedLengthFrameDecoder
> 2、行分割数据包解码器-LineBasedFrameDecoder
> 3、自定义分隔符数据包解码器-DeLimiterBasedFrameDecoder
> 4、自定义长度数据包解码器-LengthFieldBasedFrameDecoder

> ==Netty 如何实现心跳机制?==
> 所谓心跳，即在 TCP 长连接中，客户端和服务器之间定期发送的一种特殊的数据包，通知对方自己还在线，以确保 TCP 连接的有效性
> 在 Netty 中，实现心跳机制的关键是 IdLeStateHandler,构造配置
> readerIdleTimeSeconds: 读超时，即当在指定的时间间隔内没有从 Channel 读取到数据时，会触发 一个 READER_IDLE 的 IdleStateEvent 事件.
> writerIdleTimeSeconds: 写超时，即当在指定的时间间隔内没有数据写入到 Channel 时，会触发- 个 WRITER_IDLE 的 IdleStateEvent 事件。
> allIdleTimeSeconds: 读/写超时。即当在指定的时间间隔内没有读或写操作时，会触发一个ALL_IDLE 的 IdleStateEvent 事件.

> ==Netty如何实现断线重连?==
> 1、检测断开 重写ChannelInboundHandler#channelInactive来实现，当连 接不可用，该方法会被触发
> 2、重试策略 使用指定的重连策略进行 重连操作，直到重新建立连接或重试次数耗尽

> ==Netty如何解决SeLector空轮询BUG==
> 1.对Selector的s**elect操作周期进行统计**，每完成一次空的select操作进行一次计数.
> 2。若在某个周期内连续发生N次空轮询，则触发了epoll死循环bug。
> 3，**重建SeLector**，判断是否是其他线程发起的重建请求，若不是则将原SocketChannel从旧的Selector上去除注册，重新注册到新的Selector上，并将原来的SeLector关闭。



##  